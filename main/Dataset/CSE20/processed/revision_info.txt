arguments: src\align_dataset_mtcnn.py Dataset\CSE20\raw Dataset\CSE20\processed --image_size 160 --margin 32 --random_order --gpu_memory_fraction 0.25
--------------------
tensorflow version: 1.13.1
--------------------
git hash: b'3d0f9267137d67e77a29f907665b38c8bb4dcd1d'
--------------------
b'diff --git a/main/Dataset/CSE20/processed/B160760CS_Vatsala/B160760CS_1.png b/main/Dataset/CSE20/processed/B160760CS_Vatsala/B160760CS_1.png\ndeleted file mode 100644\nindex 6db8c65..0000000\nBinary files a/main/Dataset/CSE20/processed/B160760CS_Vatsala/B160760CS_1.png and /dev/null differ\ndiff --git a/main/Dataset/CSE20/processed/B160760CS_Vatsala/B160760CS_2.png b/main/Dataset/CSE20/processed/B160760CS_Vatsala/B160760CS_2.png\ndeleted file mode 100644\nindex af039a9..0000000\nBinary files a/main/Dataset/CSE20/processed/B160760CS_Vatsala/B160760CS_2.png and /dev/null differ\ndiff --git a/main/Dataset/CSE20/processed/B160760CS_Vatsala/B160760CS_3.png b/main/Dataset/CSE20/processed/B160760CS_Vatsala/B160760CS_3.png\ndeleted file mode 100644\nindex bb157bf..0000000\nBinary files a/main/Dataset/CSE20/processed/B160760CS_Vatsala/B160760CS_3.png and /dev/null differ\ndiff --git a/main/Dataset/CSE20/processed/revision_info.txt b/main/Dataset/CSE20/processed/revision_info.txt\nindex 3f5e408..d3dc567 100644\n--- a/main/Dataset/CSE20/processed/revision_info.txt\n+++ b/main/Dataset/CSE20/processed/revision_info.txt\n@@ -1,287 +1,7 @@\n-arguments: src/align_dataset_mtcnn.py ./Dataset/CSE20/raw/ ./Dataset/CSE20/processed --image_size 160 --margin 32 --random_order --gpu_memory_fraction 0.25\n+arguments: src\\align_dataset_mtcnn.py Dataset\\CSE20\\raw Dataset\\CSE20\\processed --image_size 160 --margin 32 --random_order --gpu_memory_fraction 0.25\n --------------------\n-tensorflow version: 1.7.0\n+tensorflow version: 1.13.1\n --------------------\n-git hash: e5ea2411c6d8091a0c3ca0d6fe3c8be74790c9ab\n+git hash: b\'3d0f9267137d67e77a29f907665b38c8bb4dcd1d\'\n --------------------\n-diff --git a/main/Dataset/CSE20/processed/B160116CS_Aparna/B160116CS_1.png b/main/Dataset/CSE20/processed/B160116CS_Aparna/B160116CS_1.png\n-deleted file mode 100644\n-index f1db83f..0000000\n-Binary files a/main/Dataset/CSE20/processed/B160116CS_Aparna/B160116CS_1.png and /dev/null differ\n-diff --git a/main/Dataset/CSE20/processed/B160116CS_Aparna/B160116CS_2.png b/main/Dataset/CSE20/processed/B160116CS_Aparna/B160116CS_2.png\n-deleted file mode 100644\n-index 45449c3..0000000\n-Binary files a/main/Dataset/CSE20/processed/B160116CS_Aparna/B160116CS_2.png and /dev/null differ\n-diff --git a/main/Dataset/CSE20/processed/B160116CS_Aparna/B160116CS_3.png b/main/Dataset/CSE20/processed/B160116CS_Aparna/B160116CS_3.png\n-deleted file mode 100644\n-index 9813f9f..0000000\n-Binary files a/main/Dataset/CSE20/processed/B160116CS_Aparna/B160116CS_3.png and /dev/null differ\n-diff --git a/main/Dataset/CSE20/processed/B160118CS_Neeraja/B160118CS_1.png b/main/Dataset/CSE20/processed/B160118CS_Neeraja/B160118CS_1.png\n-deleted file mode 100644\n-index fb52346..0000000\n-Binary files a/main/Dataset/CSE20/processed/B160118CS_Neeraja/B160118CS_1.png and /dev/null differ\n-diff --git a/main/Dataset/CSE20/processed/B160118CS_Neeraja/B160118CS_2.png b/main/Dataset/CSE20/processed/B160118CS_Neeraja/B160118CS_2.png\n-deleted file mode 100644\n-index 3a04b13..0000000\n-Binary files a/main/Dataset/CSE20/processed/B160118CS_Neeraja/B160118CS_2.png and /dev/null differ\n-diff --git a/main/Dataset/CSE20/processed/B160118CS_Neeraja/B160118CS_3.png b/main/Dataset/CSE20/processed/B160118CS_Neeraja/B160118CS_3.png\n-deleted file mode 100644\n-index f7c2d61..0000000\n-Binary files a/main/Dataset/CSE20/processed/B160118CS_Neeraja/B160118CS_3.png and /dev/null differ\n-diff --git a/main/Dataset/CSE20/processed/B160213CS_Nileena/B160213CS_1.png b/main/Dataset/CSE20/processed/B160213CS_Nileena/B160213CS_1.png\n-deleted file mode 100644\n-index 5affd0e..0000000\n-Binary files a/main/Dataset/CSE20/processed/B160213CS_Nileena/B160213CS_1.png and /dev/null differ\n-diff --git a/main/Dataset/CSE20/processed/B160213CS_Nileena/B160213CS_2.png b/main/Dataset/CSE20/processed/B160213CS_Nileena/B160213CS_2.png\n-deleted file mode 100644\n-index 6bf453c..0000000\n-Binary files a/main/Dataset/CSE20/processed/B160213CS_Nileena/B160213CS_2.png and /dev/null differ\n-diff --git a/main/Dataset/CSE20/processed/B160213CS_Nileena/B160213CS_3.png b/main/Dataset/CSE20/processed/B160213CS_Nileena/B160213CS_3.png\n-deleted file mode 100644\n-index c40a062..0000000\n-Binary files a/main/Dataset/CSE20/processed/B160213CS_Nileena/B160213CS_3.png and /dev/null differ\n-diff --git a/main/Dataset/CSE20/processed/B160228CS_Vrindha/B160226CS_1.png b/main/Dataset/CSE20/processed/B160228CS_Vrindha/B160226CS_1.png\n-deleted file mode 100644\n-index 598febb..0000000\n-Binary files a/main/Dataset/CSE20/processed/B160228CS_Vrindha/B160226CS_1.png and /dev/null differ\n-diff --git a/main/Dataset/CSE20/processed/B160228CS_Vrindha/B160226CS_2.png b/main/Dataset/CSE20/processed/B160228CS_Vrindha/B160226CS_2.png\n-deleted file mode 100644\n-index 90186c5..0000000\n-Binary files a/main/Dataset/CSE20/processed/B160228CS_Vrindha/B160226CS_2.png and /dev/null differ\n-diff --git a/main/Dataset/CSE20/processed/B160228CS_Vrindha/B160226CS_3.png b/main/Dataset/CSE20/processed/B160228CS_Vrindha/B160226CS_3.png\n-deleted file mode 100644\n-index 11e9bc8..0000000\n-Binary files a/main/Dataset/CSE20/processed/B160228CS_Vrindha/B160226CS_3.png and /dev/null differ\n-diff --git a/main/Dataset/CSE20/processed/B160229CS_Reema/B160229CS_1.png b/main/Dataset/CSE20/processed/B160229CS_Reema/B160229CS_1.png\n-deleted file mode 100644\n-index 078771e..0000000\n-Binary files a/main/Dataset/CSE20/processed/B160229CS_Reema/B160229CS_1.png and /dev/null differ\n-diff --git a/main/Dataset/CSE20/processed/B160229CS_Reema/B160229CS_2.png b/main/Dataset/CSE20/processed/B160229CS_Reema/B160229CS_2.png\n-deleted file mode 100644\n-index b4aee42..0000000\n-Binary files a/main/Dataset/CSE20/processed/B160229CS_Reema/B160229CS_2.png and /dev/null differ\n-diff --git a/main/Dataset/CSE20/processed/B160229CS_Reema/B160229CS_3.png b/main/Dataset/CSE20/processed/B160229CS_Reema/B160229CS_3.png\n-deleted file mode 100644\n-index 406508e..0000000\n-Binary files a/main/Dataset/CSE20/processed/B160229CS_Reema/B160229CS_3.png and /dev/null differ\n-diff --git a/main/Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_1.png b/main/Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_1.png\n-deleted file mode 100644\n-index cb05c38..0000000\n-Binary files a/main/Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_1.png and /dev/null differ\n-diff --git a/main/Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_2.png b/main/Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_2.png\n-deleted file mode 100644\n-index ebef29c..0000000\n-Binary files a/main/Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_2.png and /dev/null differ\n-diff --git a/main/Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_3.png b/main/Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_3.png\n-deleted file mode 100644\n-index 5b409b0..0000000\n-Binary files a/main/Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_3.png and /dev/null differ\n-diff --git a/main/Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_4.png b/main/Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_4.png\n-deleted file mode 100644\n-index 63291a9..0000000\n-Binary files a/main/Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_4.png and /dev/null differ\n-diff --git a/main/Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_5.png b/main/Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_5.png\n-deleted file mode 100644\n-index 35bb01f..0000000\n-Binary files a/main/Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_5.png and /dev/null differ\n-diff --git a/main/Dataset/CSE20/processed/B160320ME_Shebin/B160320ME_1.png b/main/Dataset/CSE20/processed/B160320ME_Shebin/B160320ME_1.png\n-deleted file mode 100644\n-index fa0c503..0000000\n-Binary files a/main/Dataset/CSE20/processed/B160320ME_Shebin/B160320ME_1.png and /dev/null differ\n-diff --git a/main/Dataset/CSE20/processed/B160320ME_Shebin/B160320ME_2.png b/main/Dataset/CSE20/processed/B160320ME_Shebin/B160320ME_2.png\n-deleted file mode 100644\n-index 79a0e5d..0000000\n-Binary files a/main/Dataset/CSE20/processed/B160320ME_Shebin/B160320ME_2.png and /dev/null differ\n-diff --git a/main/Dataset/CSE20/processed/B160320ME_Shebin/B160320ME_3.png b/main/Dataset/CSE20/processed/B160320ME_Shebin/B160320ME_3.png\n-deleted file mode 100644\n-index c03da94..0000000\n-Binary files a/main/Dataset/CSE20/processed/B160320ME_Shebin/B160320ME_3.png and /dev/null differ\n-diff --git a/main/Dataset/CSE20/processed/B160408CS_Ameen/B160408CS_1.png b/main/Dataset/CSE20/processed/B160408CS_Ameen/B160408CS_1.png\n-deleted file mode 100644\n-index 16a46a2..0000000\n-Binary files a/main/Dataset/CSE20/processed/B160408CS_Ameen/B160408CS_1.png and /dev/null differ\n-diff --git a/main/Dataset/CSE20/processed/B160408CS_Ameen/B160408CS_2.png b/main/Dataset/CSE20/processed/B160408CS_Ameen/B160408CS_2.png\n-deleted file mode 100644\n-index 7d933ff..0000000\n-Binary files a/main/Dataset/CSE20/processed/B160408CS_Ameen/B160408CS_2.png and /dev/null differ\n-diff --git a/main/Dataset/CSE20/processed/B160408CS_Ameen/B160408CS_3.png b/main/Dataset/CSE20/processed/B160408CS_Ameen/B160408CS_3.png\n-deleted file mode 100644\n-index ce20835..0000000\n-Binary files a/main/Dataset/CSE20/processed/B160408CS_Ameen/B160408CS_3.png and /dev/null differ\n-diff --git a/main/Dataset/CSE20/processed/B160445CS_Sumalatha/B160445CS_1.png b/main/Dataset/CSE20/processed/B160445CS_Sumalatha/B160445CS_1.png\n-deleted file mode 100644\n-index fd9ed6f..0000000\n-Binary files a/main/Dataset/CSE20/processed/B160445CS_Sumalatha/B160445CS_1.png and /dev/null differ\n-diff --git a/main/Dataset/CSE20/processed/B160445CS_Sumalatha/B160445CS_2.png b/main/Dataset/CSE20/processed/B160445CS_Sumalatha/B160445CS_2.png\n-deleted file mode 100644\n-index ad52a1d..0000000\n-Binary files a/main/Dataset/CSE20/processed/B160445CS_Sumalatha/B160445CS_2.png and /dev/null differ\n-diff --git a/main/Dataset/CSE20/processed/B160471CS_Dheeraj/B160471CS_1.png b/main/Dataset/CSE20/processed/B160471CS_Dheeraj/B160471CS_1.png\n-deleted file mode 100644\n-index 78a1983..0000000\n-Binary files a/main/Dataset/CSE20/processed/B160471CS_Dheeraj/B160471CS_1.png and /dev/null differ\n-diff --git a/main/Dataset/CSE20/processed/B160688CS_Vishnu/B160688CS_1.png b/main/Dataset/CSE20/processed/B160688CS_Vishnu/B160688CS_1.png\n-deleted file mode 100644\n-index f43b308..0000000\n-Binary files a/main/Dataset/CSE20/processed/B160688CS_Vishnu/B160688CS_1.png and /dev/null differ\n-diff --git a/main/Dataset/CSE20/processed/B160688CS_Vishnu/B160688CS_2.png b/main/Dataset/CSE20/processed/B160688CS_Vishnu/B160688CS_2.png\n-deleted file mode 100644\n-index 5654243..0000000\n-Binary files a/main/Dataset/CSE20/processed/B160688CS_Vishnu/B160688CS_2.png and /dev/null differ\n-diff --git a/main/Dataset/CSE20/processed/B160688CS_Vishnu/B160688CS_3.png b/main/Dataset/CSE20/processed/B160688CS_Vishnu/B160688CS_3.png\n-deleted file mode 100644\n-index 4db5286..0000000\n-Binary files a/main/Dataset/CSE20/processed/B160688CS_Vishnu/B160688CS_3.png and /dev/null differ\n-diff --git a/main/Dataset/CSE20/processed/B160760CS_Vatsala/B160760CS_1.png b/main/Dataset/CSE20/processed/B160760CS_Vatsala/B160760CS_1.png\n-deleted file mode 100644\n-index 80f206e..0000000\n-Binary files a/main/Dataset/CSE20/processed/B160760CS_Vatsala/B160760CS_1.png and /dev/null differ\n-diff --git a/main/Dataset/CSE20/processed/B160760CS_Vatsala/B160760CS_2.png b/main/Dataset/CSE20/processed/B160760CS_Vatsala/B160760CS_2.png\n-deleted file mode 100644\n-index fbdeadf..0000000\n-Binary files a/main/Dataset/CSE20/processed/B160760CS_Vatsala/B160760CS_2.png and /dev/null differ\n-diff --git a/main/Dataset/CSE20/processed/B160760CS_Vatsala/B160760CS_3.png b/main/Dataset/CSE20/processed/B160760CS_Vatsala/B160760CS_3.png\n-deleted file mode 100644\n-index b7bb5e8..0000000\n-Binary files a/main/Dataset/CSE20/processed/B160760CS_Vatsala/B160760CS_3.png and /dev/null differ\n-diff --git a/main/Dataset/CSE20/processed/B160873CS_Naina/B160873CS_1.png b/main/Dataset/CSE20/processed/B160873CS_Naina/B160873CS_1.png\n-deleted file mode 100644\n-index 71d405b..0000000\n-Binary files a/main/Dataset/CSE20/processed/B160873CS_Naina/B160873CS_1.png and /dev/null differ\n-diff --git a/main/Dataset/CSE20/processed/B160873CS_Naina/B160873CS_2.png b/main/Dataset/CSE20/processed/B160873CS_Naina/B160873CS_2.png\n-deleted file mode 100644\n-index 2018b5c..0000000\n-Binary files a/main/Dataset/CSE20/processed/B160873CS_Naina/B160873CS_2.png and /dev/null differ\n-diff --git a/main/Dataset/CSE20/processed/B160873CS_Naina/B160873CS_3.png b/main/Dataset/CSE20/processed/B160873CS_Naina/B160873CS_3.png\n-deleted file mode 100644\n-index 6f1ae5c..0000000\n-Binary files a/main/Dataset/CSE20/processed/B160873CS_Naina/B160873CS_3.png and /dev/null differ\n-diff --git a/main/Dataset/CSE20/processed/bounding_boxes_09361.txt b/main/Dataset/CSE20/processed/bounding_boxes_09361.txt\n-deleted file mode 100644\n-index da52b30..0000000\n---- a/main/Dataset/CSE20/processed/bounding_boxes_09361.txt\n-+++ /dev/null\n-@@ -1,35 +0,0 @@\n--Dataset/CSE20/processed/B160760CS_Vatsala/B160760CS_3.png 737 316 933 556\n--Dataset/CSE20/processed/B160760CS_Vatsala/B160760CS_2.png 153 385 552 891\n--Dataset/CSE20/processed/B160760CS_Vatsala/B160760CS_1.png 468 264 572 389\n--Dataset/CSE20/processed/B160320ME_Shebin/B160320ME_1.png 330 315 631 688\n--Dataset/CSE20/processed/B160320ME_Shebin/B160320ME_3.png 191 285 646 892\n--Dataset/CSE20/processed/B160320ME_Shebin/B160320ME_2.png 440 427 806 846\n--Dataset/CSE20/processed/B160688CS_Vishnu/B160688CS_3.png 725 1044 1618 2214\n--Dataset/CSE20/processed/B160688CS_Vishnu/B160688CS_2.png 973 426 1711 1363\n--Dataset/CSE20/processed/B160688CS_Vishnu/B160688CS_1.png 544 396 1107 1123\n--Dataset/CSE20/processed/B160116CS_Aparna/B160116CS_3.png 152 200 367 450\n--Dataset/CSE20/processed/B160116CS_Aparna/B160116CS_2.png 229 63 386 249\n--Dataset/CSE20/processed/B160116CS_Aparna/B160116CS_1.png 284 560 332 614\n--Dataset/CSE20/processed/B160229CS_Reema/B160229CS_3.png 313 266 494 511\n--Dataset/CSE20/processed/B160229CS_Reema/B160229CS_2.png 144 216 315 427\n--Dataset/CSE20/processed/B160229CS_Reema/B160229CS_1.png 234 384 322 495\n--Dataset/CSE20/processed/B160118CS_Neeraja/B160118CS_1.png 130 170 396 484\n--Dataset/CSE20/processed/B160118CS_Neeraja/B160118CS_3.png 429 535 561 696\n--Dataset/CSE20/processed/B160118CS_Neeraja/B160118CS_2.png 262 59 490 329\n--Dataset/CSE20/processed/B160213CS_Nileena/B160213CS_1.png 137 160 397 472\n--Dataset/CSE20/processed/B160213CS_Nileena/B160213CS_2.png 265 271 455 492\n--Dataset/CSE20/processed/B160213CS_Nileena/B160213CS_3.png 89 336 272 568\n--Dataset/CSE20/processed/B160873CS_Naina/B160873CS_1.png 133 145 299 358\n--Dataset/CSE20/processed/B160873CS_Naina/B160873CS_2.png 451 407 544 518\n--Dataset/CSE20/processed/B160873CS_Naina/B160873CS_3.png 81 58 278 310\n--Dataset/CSE20/processed/B160228CS_Vrindha/B160226CS_2.png 69 259 255 491\n--Dataset/CSE20/processed/B160228CS_Vrindha/B160226CS_1.png 516 60 868 528\n--Dataset/CSE20/processed/B160228CS_Vrindha/B160226CS_3.png 297 232 727 812\n--Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_4.png 221 361 404 600\n--Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_1.png 277 240 512 537\n--Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_3.png 532 299 622 407\n--Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_2.png 195 53 286 160\n--Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_5.png 169 348 584 922\n--Dataset/CSE20/processed/B160445CS_Sumalatha/B160445CS_1.png 219 73 363 261\n--Dataset/CSE20/processed/B160445CS_Sumalatha/B160445CS_2.png 406 272 546 443\n--Dataset/CSE20/processed/B160445CS_Sumalatha/B160445CS_3.png 433 616 484 674\n-diff --git a/main/Dataset/CSE20/processed/bounding_boxes_19737.txt b/main/Dataset/CSE20/processed/bounding_boxes_19737.txt\n-deleted file mode 100644\n-index e69de29..0000000\n-diff --git a/main/Dataset/CSE20/processed/bounding_boxes_20330.txt b/main/Dataset/CSE20/processed/bounding_boxes_20330.txt\n-deleted file mode 100644\n-index e69de29..0000000\n-diff --git a/main/Dataset/CSE20/processed/bounding_boxes_28104.txt b/main/Dataset/CSE20/processed/bounding_boxes_28104.txt\n-deleted file mode 100644\n-index dc58fca..0000000\n---- a/main/Dataset/CSE20/processed/bounding_boxes_28104.txt\n-+++ /dev/null\n-@@ -1,3 +0,0 @@\n--Dataset/CSE20/processed/Naina/naina2.png 451 407 544 518\n--Dataset/CSE20/processed/Naina/naina3.png 81 58 278 310\n--Dataset/CSE20/processed/Naina/naina1.png 133 145 299 358\n-diff --git a/main/Dataset/CSE20/processed/bounding_boxes_30925.txt b/main/Dataset/CSE20/processed/bounding_boxes_30925.txt\n-deleted file mode 100644\n-index e69de29..0000000\n-diff --git a/main/Dataset/CSE20/processed/bounding_boxes_38733.txt b/main/Dataset/CSE20/processed/bounding_boxes_38733.txt\n-deleted file mode 100644\n-index e69de29..0000000\n-diff --git a/main/Dataset/CSE20/processed/bounding_boxes_40979.txt b/main/Dataset/CSE20/processed/bounding_boxes_40979.txt\n-deleted file mode 100644\n-index e69de29..0000000\n-diff --git a/main/Dataset/CSE20/processed/bounding_boxes_50376.txt b/main/Dataset/CSE20/processed/bounding_boxes_50376.txt\n-deleted file mode 100644\n-index 746e69e..0000000\n---- a/main/Dataset/CSE20/processed/bounding_boxes_50376.txt\n-+++ /dev/null\n-@@ -1,3 +0,0 @@\n--Dataset/CSE20/processed/Poothery/Poothery1.png 544 396 1107 1123\n--Dataset/CSE20/processed/Poothery/Poothery2.png 973 426 1711 1363\n--Dataset/CSE20/processed/Poothery/Poothery3.png 725 1044 1618 2214\n-diff --git a/main/Dataset/CSE20/processed/bounding_boxes_51760.txt b/main/Dataset/CSE20/processed/bounding_boxes_51760.txt\n-deleted file mode 100644\n-index e69de29..0000000\n-diff --git a/main/Dataset/CSE20/processed/bounding_boxes_78500.txt b/main/Dataset/CSE20/processed/bounding_boxes_78500.txt\n-deleted file mode 100644\n-index e69de29..0000000\n-diff --git a/main/Dataset/CSE20/processed/bounding_boxes_80845.txt b/main/Dataset/CSE20/processed/bounding_boxes_80845.txt\n-deleted file mode 100644\n-index e69de29..0000000\n-diff --git a/main/Dataset/CSE20/processed/bounding_boxes_95936.txt b/main/Dataset/CSE20/processed/bounding_boxes_95936.txt\n-deleted file mode 100644\n-index 5c0564d..0000000\n---- a/main/Dataset/CSE20/processed/bounding_boxes_95936.txt\n-+++ /dev/null\n-@@ -1,4 +0,0 @@\n--Dataset/CSE20/processed/B160471CS_Dheeraj/B160471CS_1.png 227 268 413 483\n--Dataset/CSE20/processed/B160408CS_Ameen/B160408CS_3.png 241 337 448 614\n--Dataset/CSE20/processed/B160408CS_Ameen/B160408CS_1.png 259 306 442 541\n--Dataset/CSE20/processed/B160408CS_Ameen/B160408CS_2.png 312 148 530 417\n-diff --git a/main/Dataset/CSE20/processed/revision_info.txt b/main/Dataset/CSE20/processed/revision_info.txt\n-deleted file mode 100644\n-index 3eaf7fb..0000000\n---- a/main/Dataset/CSE20/processed/revision_info.txt\n-+++ /dev/null\n-@@ -1,7 +0,0 @@\n--arguments: src/align_dataset_mtcnn.py ./Dataset/CSE20/raw/ ./Dataset/CSE20/processed/ --image_size 160 --margin 32 --random_order --gpu_memory_fraction 0.25\n----------------------\n--tensorflow version: 1.7.0\n----------------------\n--git hash: b\'096ed770f163957c1e56efa7feeb194773920f6e\'\n----------------------\n--b\'diff --git a/ /revision_info.txt b/ /revision_info.txt\\nnew file mode 100644\\nindex 0000000..979e188\\n--- /dev/null\\n+++ b/ /revision_info.txt\\t\\n@@ -0,0 +1,8 @@\\n+arguments: src/align/align_dataset_mtcnn.py ./Dataset/CSE20/raw \\\\\\n+./Dataset/CSE20/processed --image_size 160 --margin 32 --random_order  \\n+--------------------\\n+tensorflow version: 1.7.0\\n+--------------------\\n+git hash: b\\\'096ed770f163957c1e56efa7feeb194773920f6e\\\'\\n+--------------------\\n+b\\\'diff --git a/src/align/align_dataset_mtcnn.py b/src/align/align_dataset_mtcnn.py\\\\nindex 7d5e735..21f1457 100644\\\\n--- a/src/align/align_dataset_mtcnn.py\\\\n+++ b/src/align/align_dataset_mtcnn.py\\\\n@@ -31,8 +31,8 @@ import os\\\\n import argparse\\\\n import tensorflow as tf\\\\n import numpy as np\\\\n-import facenet\\\\n-import align.detect_face\\\\n+import facenet.src.facenet as facenet   #changed\\\\n+import detect_face  #changed\\\\n import random\\\\n from time import sleep\\\'\\n\\\\ No newline at end of file\\ndiff --git a/Dataset/CSE20/processed/B160116CS_Aparna/B160116CS_1.png b/Dataset/CSE20/processed/B160116CS_Aparna/B160116CS_1.png\\nnew file mode 100644\\nindex 0000000..f1db83f\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160116CS_Aparna/B160116CS_1.png differ\\ndiff --git a/Dataset/CSE20/processed/B160116CS_Aparna/B160116CS_2.png b/Dataset/CSE20/processed/B160116CS_Aparna/B160116CS_2.png\\nnew file mode 100644\\nindex 0000000..45449c3\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160116CS_Aparna/B160116CS_2.png differ\\ndiff --git a/Dataset/CSE20/processed/B160116CS_Aparna/B160116CS_3.png b/Dataset/CSE20/processed/B160116CS_Aparna/B160116CS_3.png\\nnew file mode 100644\\nindex 0000000..9813f9f\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160116CS_Aparna/B160116CS_3.png differ\\ndiff --git a/Dataset/CSE20/processed/B160118CS_Neeraja/B160118CS_1.png b/Dataset/CSE20/processed/B160118CS_Neeraja/B160118CS_1.png\\nnew file mode 100644\\nindex 0000000..fb52346\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160118CS_Neeraja/B160118CS_1.png differ\\ndiff --git a/Dataset/CSE20/processed/B160118CS_Neeraja/B160118CS_2.png b/Dataset/CSE20/processed/B160118CS_Neeraja/B160118CS_2.png\\nnew file mode 100644\\nindex 0000000..3a04b13\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160118CS_Neeraja/B160118CS_2.png differ\\ndiff --git a/Dataset/CSE20/processed/B160118CS_Neeraja/B160118CS_3.png b/Dataset/CSE20/processed/B160118CS_Neeraja/B160118CS_3.png\\nnew file mode 100644\\nindex 0000000..f7c2d61\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160118CS_Neeraja/B160118CS_3.png differ\\ndiff --git a/Dataset/CSE20/processed/B160213CS_Nileena/B160213CS_1.png b/Dataset/CSE20/processed/B160213CS_Nileena/B160213CS_1.png\\nnew file mode 100644\\nindex 0000000..5affd0e\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160213CS_Nileena/B160213CS_1.png differ\\ndiff --git a/Dataset/CSE20/processed/B160213CS_Nileena/B160213CS_2.png b/Dataset/CSE20/processed/B160213CS_Nileena/B160213CS_2.png\\nnew file mode 100644\\nindex 0000000..6bf453c\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160213CS_Nileena/B160213CS_2.png differ\\ndiff --git a/Dataset/CSE20/processed/B160213CS_Nileena/B160213CS_3.png b/Dataset/CSE20/processed/B160213CS_Nileena/B160213CS_3.png\\nnew file mode 100644\\nindex 0000000..c40a062\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160213CS_Nileena/B160213CS_3.png differ\\ndiff --git a/Dataset/CSE20/processed/B160228CS_Vrindha/B160226CS_1.png b/Dataset/CSE20/processed/B160228CS_Vrindha/B160226CS_1.png\\nnew file mode 100644\\nindex 0000000..598febb\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160228CS_Vrindha/B160226CS_1.png differ\\ndiff --git a/Dataset/CSE20/processed/B160228CS_Vrindha/B160226CS_2.png b/Dataset/CSE20/processed/B160228CS_Vrindha/B160226CS_2.png\\nnew file mode 100644\\nindex 0000000..90186c5\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160228CS_Vrindha/B160226CS_2.png differ\\ndiff --git a/Dataset/CSE20/processed/B160228CS_Vrindha/B160226CS_3.png b/Dataset/CSE20/processed/B160228CS_Vrindha/B160226CS_3.png\\nnew file mode 100644\\nindex 0000000..11e9bc8\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160228CS_Vrindha/B160226CS_3.png differ\\ndiff --git a/Dataset/CSE20/processed/B160229CS_Reema/B160229CS_1.png b/Dataset/CSE20/processed/B160229CS_Reema/B160229CS_1.png\\nnew file mode 100644\\nindex 0000000..078771e\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160229CS_Reema/B160229CS_1.png differ\\ndiff --git a/Dataset/CSE20/processed/B160229CS_Reema/B160229CS_2.png b/Dataset/CSE20/processed/B160229CS_Reema/B160229CS_2.png\\nnew file mode 100644\\nindex 0000000..b4aee42\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160229CS_Reema/B160229CS_2.png differ\\ndiff --git a/Dataset/CSE20/processed/B160229CS_Reema/B160229CS_3.png b/Dataset/CSE20/processed/B160229CS_Reema/B160229CS_3.png\\nnew file mode 100644\\nindex 0000000..406508e\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160229CS_Reema/B160229CS_3.png differ\\ndiff --git a/Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_1.png b/Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_1.png\\nnew file mode 100644\\nindex 0000000..cb05c38\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_1.png differ\\ndiff --git a/Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_2.png b/Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_2.png\\nnew file mode 100644\\nindex 0000000..ebef29c\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_2.png differ\\ndiff --git a/Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_3.png b/Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_3.png\\nnew file mode 100644\\nindex 0000000..5b409b0\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_3.png differ\\ndiff --git a/Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_4.png b/Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_4.png\\nnew file mode 100644\\nindex 0000000..63291a9\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_4.png differ\\ndiff --git a/Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_5.png b/Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_5.png\\nnew file mode 100644\\nindex 0000000..35bb01f\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_5.png differ\\ndiff --git a/Dataset/CSE20/processed/B160320ME_Shebin/B160320ME_1.png b/Dataset/CSE20/processed/B160320ME_Shebin/B160320ME_1.png\\nnew file mode 100644\\nindex 0000000..fa0c503\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160320ME_Shebin/B160320ME_1.png differ\\ndiff --git a/Dataset/CSE20/processed/B160320ME_Shebin/B160320ME_2.png b/Dataset/CSE20/processed/B160320ME_Shebin/B160320ME_2.png\\nnew file mode 100644\\nindex 0000000..79a0e5d\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160320ME_Shebin/B160320ME_2.png differ\\ndiff --git a/Dataset/CSE20/processed/B160320ME_Shebin/B160320ME_3.png b/Dataset/CSE20/processed/B160320ME_Shebin/B160320ME_3.png\\nnew file mode 100644\\nindex 0000000..c03da94\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160320ME_Shebin/B160320ME_3.png differ\\ndiff --git a/Dataset/CSE20/processed/B160408CS_Ameen/B160408CS_1.png b/Dataset/CSE20/processed/B160408CS_Ameen/B160408CS_1.png\\nnew file mode 100644\\nindex 0000000..16a46a2\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160408CS_Ameen/B160408CS_1.png differ\\ndiff --git a/Dataset/CSE20/processed/B160408CS_Ameen/B160408CS_2.png b/Dataset/CSE20/processed/B160408CS_Ameen/B160408CS_2.png\\nnew file mode 100644\\nindex 0000000..7d933ff\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160408CS_Ameen/B160408CS_2.png differ\\ndiff --git a/Dataset/CSE20/processed/B160408CS_Ameen/B160408CS_3.png b/Dataset/CSE20/processed/B160408CS_Ameen/B160408CS_3.png\\nnew file mode 100644\\nindex 0000000..ce20835\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160408CS_Ameen/B160408CS_3.png differ\\ndiff --git a/Dataset/CSE20/processed/B160445CS_Sumalatha/B160445CS_1.png b/Dataset/CSE20/processed/B160445CS_Sumalatha/B160445CS_1.png\\nnew file mode 100644\\nindex 0000000..fd9ed6f\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160445CS_Sumalatha/B160445CS_1.png differ\\ndiff --git a/Dataset/CSE20/processed/B160445CS_Sumalatha/B160445CS_2.png b/Dataset/CSE20/processed/B160445CS_Sumalatha/B160445CS_2.png\\nnew file mode 100644\\nindex 0000000..ad52a1d\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160445CS_Sumalatha/B160445CS_2.png differ\\ndiff --git a/Dataset/CSE20/processed/B160445CS_Sumalatha/B160445CS_3.png b/Dataset/CSE20/processed/B160445CS_Sumalatha/B160445CS_3.png\\nnew file mode 100644\\nindex 0000000..7fc6b80\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160445CS_Sumalatha/B160445CS_3.png differ\\ndiff --git a/Dataset/CSE20/processed/B160471CS_Dheeraj/B160471CS_1.png b/Dataset/CSE20/processed/B160471CS_Dheeraj/B160471CS_1.png\\nnew file mode 100644\\nindex 0000000..78a1983\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160471CS_Dheeraj/B160471CS_1.png differ\\ndiff --git a/Dataset/CSE20/processed/B160688CS_Vishnu/B160688CS_1.png b/Dataset/CSE20/processed/B160688CS_Vishnu/B160688CS_1.png\\nnew file mode 100644\\nindex 0000000..f43b308\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160688CS_Vishnu/B160688CS_1.png differ\\ndiff --git a/Dataset/CSE20/processed/B160688CS_Vishnu/B160688CS_2.png b/Dataset/CSE20/processed/B160688CS_Vishnu/B160688CS_2.png\\nnew file mode 100644\\nindex 0000000..5654243\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160688CS_Vishnu/B160688CS_2.png differ\\ndiff --git a/Dataset/CSE20/processed/B160688CS_Vishnu/B160688CS_3.png b/Dataset/CSE20/processed/B160688CS_Vishnu/B160688CS_3.png\\nnew file mode 100644\\nindex 0000000..4db5286\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160688CS_Vishnu/B160688CS_3.png differ\\ndiff --git a/Dataset/CSE20/processed/B160760CS_Vatsala/B160760CS_1.png b/Dataset/CSE20/processed/B160760CS_Vatsala/B160760CS_1.png\\nnew file mode 100644\\nindex 0000000..80f206e\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160760CS_Vatsala/B160760CS_1.png differ\\ndiff --git a/Dataset/CSE20/processed/B160760CS_Vatsala/B160760CS_2.png b/Dataset/CSE20/processed/B160760CS_Vatsala/B160760CS_2.png\\nnew file mode 100644\\nindex 0000000..fbdeadf\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160760CS_Vatsala/B160760CS_2.png differ\\ndiff --git a/Dataset/CSE20/processed/B160760CS_Vatsala/B160760CS_3.png b/Dataset/CSE20/processed/B160760CS_Vatsala/B160760CS_3.png\\nnew file mode 100644\\nindex 0000000..b7bb5e8\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160760CS_Vatsala/B160760CS_3.png differ\\ndiff --git a/Dataset/CSE20/processed/B160873CS_Naina/B160873CS_1.png b/Dataset/CSE20/processed/B160873CS_Naina/B160873CS_1.png\\nnew file mode 100644\\nindex 0000000..71d405b\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160873CS_Naina/B160873CS_1.png differ\\ndiff --git a/Dataset/CSE20/processed/B160873CS_Naina/B160873CS_2.png b/Dataset/CSE20/processed/B160873CS_Naina/B160873CS_2.png\\nnew file mode 100644\\nindex 0000000..2018b5c\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160873CS_Naina/B160873CS_2.png differ\\ndiff --git a/Dataset/CSE20/processed/B160873CS_Naina/B160873CS_3.png b/Dataset/CSE20/processed/B160873CS_Naina/B160873CS_3.png\\nnew file mode 100644\\nindex 0000000..6f1ae5c\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160873CS_Naina/B160873CS_3.png differ\\ndiff --git a/Dataset/CSE20/processed/Naina/naina1.png b/Dataset/CSE20/processed/Naina/naina1.png\\nnew file mode 100644\\nindex 0000000..71d405b\\nBinary files /dev/null and b/Dataset/CSE20/processed/Naina/naina1.png differ\\ndiff --git a/Dataset/CSE20/processed/Naina/naina2.png b/Dataset/CSE20/processed/Naina/naina2.png\\nnew file mode 100644\\nindex 0000000..2018b5c\\nBinary files /dev/null and b/Dataset/CSE20/processed/Naina/naina2.png differ\\ndiff --git a/Dataset/CSE20/processed/Naina/naina3.png b/Dataset/CSE20/processed/Naina/naina3.png\\nnew file mode 100644\\nindex 0000000..6f1ae5c\\nBinary files /dev/null and b/Dataset/CSE20/processed/Naina/naina3.png differ\\ndiff --git a/Dataset/CSE20/processed/Poothery/Poothery1.png b/Dataset/CSE20/processed/Poothery/Poothery1.png\\nnew file mode 100644\\nindex 0000000..f43b308\\nBinary files /dev/null and b/Dataset/CSE20/processed/Poothery/Poothery1.png differ\\ndiff --git a/Dataset/CSE20/processed/Poothery/Poothery2.png b/Dataset/CSE20/processed/Poothery/Poothery2.png\\nnew file mode 100644\\nindex 0000000..5654243\\nBinary files /dev/null and b/Dataset/CSE20/processed/Poothery/Poothery2.png differ\\ndiff --git a/Dataset/CSE20/processed/Poothery/Poothery3.png b/Dataset/CSE20/processed/Poothery/Poothery3.png\\nnew file mode 100644\\nindex 0000000..4db5286\\nBinary files /dev/null and b/Dataset/CSE20/processed/Poothery/Poothery3.png differ\\ndiff --git a/Dataset/CSE20/processed/bounding_boxes_09361.txt b/Dataset/CSE20/processed/bounding_boxes_09361.txt\\nnew file mode 100644\\nindex 0000000..da52b30\\n--- /dev/null\\n+++ b/Dataset/CSE20/processed/bounding_boxes_09361.txt\\n@@ -0,0 +1,35 @@\\n+Dataset/CSE20/processed/B160760CS_Vatsala/B160760CS_3.png 737 316 933 556\\n+Dataset/CSE20/processed/B160760CS_Vatsala/B160760CS_2.png 153 385 552 891\\n+Dataset/CSE20/processed/B160760CS_Vatsala/B160760CS_1.png 468 264 572 389\\n+Dataset/CSE20/processed/B160320ME_Shebin/B160320ME_1.png 330 315 631 688\\n+Dataset/CSE20/processed/B160320ME_Shebin/B160320ME_3.png 191 285 646 892\\n+Dataset/CSE20/processed/B160320ME_Shebin/B160320ME_2.png 440 427 806 846\\n+Dataset/CSE20/processed/B160688CS_Vishnu/B160688CS_3.png 725 1044 1618 2214\\n+Dataset/CSE20/processed/B160688CS_Vishnu/B160688CS_2.png 973 426 1711 1363\\n+Dataset/CSE20/processed/B160688CS_Vishnu/B160688CS_1.png 544 396 1107 1123\\n+Dataset/CSE20/processed/B160116CS_Aparna/B160116CS_3.png 152 200 367 450\\n+Dataset/CSE20/processed/B160116CS_Aparna/B160116CS_2.png 229 63 386 249\\n+Dataset/CSE20/processed/B160116CS_Aparna/B160116CS_1.png 284 560 332 614\\n+Dataset/CSE20/processed/B160229CS_Reema/B160229CS_3.png 313 266 494 511\\n+Dataset/CSE20/processed/B160229CS_Reema/B160229CS_2.png 144 216 315 427\\n+Dataset/CSE20/processed/B160229CS_Reema/B160229CS_1.png 234 384 322 495\\n+Dataset/CSE20/processed/B160118CS_Neeraja/B160118CS_1.png 130 170 396 484\\n+Dataset/CSE20/processed/B160118CS_Neeraja/B160118CS_3.png 429 535 561 696\\n+Dataset/CSE20/processed/B160118CS_Neeraja/B160118CS_2.png 262 59 490 329\\n+Dataset/CSE20/processed/B160213CS_Nileena/B160213CS_1.png 137 160 397 472\\n+Dataset/CSE20/processed/B160213CS_Nileena/B160213CS_2.png 265 271 455 492\\n+Dataset/CSE20/processed/B160213CS_Nileena/B160213CS_3.png 89 336 272 568\\n+Dataset/CSE20/processed/B160873CS_Naina/B160873CS_1.png 133 145 299 358\\n+Dataset/CSE20/processed/B160873CS_Naina/B160873CS_2.png 451 407 544 518\\n+Dataset/CSE20/processed/B160873CS_Naina/B160873CS_3.png 81 58 278 310\\n+Dataset/CSE20/processed/B160228CS_Vrindha/B160226CS_2.png 69 259 255 491\\n+Dataset/CSE20/processed/B160228CS_Vrindha/B160226CS_1.png 516 60 868 528\\n+Dataset/CSE20/processed/B160228CS_Vrindha/B160226CS_3.png 297 232 727 812\\n+Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_4.png 221 361 404 600\\n+Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_1.png 277 240 512 537\\n+Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_3.png 532 299 622 407\\n+Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_2.png 195 53 286 160\\n+Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_5.png 169 348 584 922\\n+Dataset/CSE20/processed/B160445CS_Sumalatha/B160445CS_1.png 219 73 363 261\\n+Dataset/CSE20/processed/B160445CS_Sumalatha/B160445CS_2.png 406 272 546 443\\n+Dataset/CSE20/processed/B160445CS_Sumalatha/B160445CS_3.png 433 616 484 674\\ndiff --git a/Dataset/CSE20/processed/bounding_boxes_19737.txt b/Dataset/CSE20/processed/bounding_boxes_19737.txt\\nnew file mode 100644\\nindex 0000000..e69de29\\ndiff --git a/Dataset/CSE20/processed/bounding_boxes_20330.txt b/Dataset/CSE20/processed/bounding_boxes_20330.txt\\nnew file mode 100644\\nindex 0000000..e69de29\\ndiff --git a/Dataset/CSE20/processed/bounding_boxes_28104.txt b/Dataset/CSE20/processed/bounding_boxes_28104.txt\\nnew file mode 100644\\nindex 0000000..dc58fca\\n--- /dev/null\\n+++ b/Dataset/CSE20/processed/bounding_boxes_28104.txt\\n@@ -0,0 +1,3 @@\\n+Dataset/CSE20/processed/Naina/naina2.png 451 407 544 518\\n+Dataset/CSE20/processed/Naina/naina3.png 81 58 278 310\\n+Dataset/CSE20/processed/Naina/naina1.png 133 145 299 358\\ndiff --git a/Dataset/CSE20/processed/bounding_boxes_30925.txt b/Dataset/CSE20/processed/bounding_boxes_30925.txt\\nnew file mode 100644\\nindex 0000000..e69de29\\ndiff --git a/Dataset/CSE20/processed/bounding_boxes_38733.txt b/Dataset/CSE20/processed/bounding_boxes_38733.txt\\nnew file mode 100644\\nindex 0000000..e69de29\\ndiff --git a/Dataset/CSE20/processed/bounding_boxes_40979.txt b/Dataset/CSE20/processed/bounding_boxes_40979.txt\\nnew file mode 100644\\nindex 0000000..e69de29\\ndiff --git a/Dataset/CSE20/processed/bounding_boxes_50376.txt b/Dataset/CSE20/processed/bounding_boxes_50376.txt\\nnew file mode 100644\\nindex 0000000..746e69e\\n--- /dev/null\\n+++ b/Dataset/CSE20/processed/bounding_boxes_50376.txt\\n@@ -0,0 +1,3 @@\\n+Dataset/CSE20/processed/Poothery/Poothery1.png 544 396 1107 1123\\n+Dataset/CSE20/processed/Poothery/Poothery2.png 973 426 1711 1363\\n+Dataset/CSE20/processed/Poothery/Poothery3.png 725 1044 1618 2214\\ndiff --git a/Dataset/CSE20/processed/bounding_boxes_51760.txt b/Dataset/CSE20/processed/bounding_boxes_51760.txt\\nnew file mode 100644\\nindex 0000000..e69de29\\ndiff --git a/Dataset/CSE20/processed/bounding_boxes_80845.txt b/Dataset/CSE20/processed/bounding_boxes_80845.txt\\nnew file mode 100644\\nindex 0000000..e69de29\\ndiff --git a/Dataset/CSE20/processed/bounding_boxes_95936.txt b/Dataset/CSE20/processed/bounding_boxes_95936.txt\\nnew file mode 100644\\nindex 0000000..5c0564d\\n--- /dev/null\\n+++ b/Dataset/CSE20/processed/bounding_boxes_95936.txt\\n@@ -0,0 +1,4 @@\\n+Dataset/CSE20/processed/B160471CS_Dheeraj/B160471CS_1.png 227 268 413 483\\n+Dataset/CSE20/processed/B160408CS_Ameen/B160408CS_3.png 241 337 448 614\\n+Dataset/CSE20/processed/B160408CS_Ameen/B160408CS_1.png 259 306 442 541\\n+Dataset/CSE20/processed/B160408CS_Ameen/B160408CS_2.png 312 148 530 417\\ndiff --git a/Dataset/CSE20/processed/revision_info.txt b/Dataset/CSE20/processed/revision_info.txt\\nnew file mode 100644\\nindex 0000000..5373839\\n--- /dev/null\\n+++ b/Dataset/CSE20/processed/revision_info.txt\\n@@ -0,0 +1,7 @@\\n+arguments: src/align_dataset_mtcnn.py Dataset/CSE20/raw/ Dataset/CSE20/processed/ --image_size 160 --margin 32 --random_order --gpu_memory_fraction 0.25\\n+--------------------\\n+tensorflow version: 1.7.0\\n+--------------------\\n+git hash: b\\\'096ed770f163957c1e56efa7feeb194773920f6e\\\'\\n+--------------------\\n+b\\\'diff --git a/src/align/align_dataset_mtcnn.py b/src/align/align_dataset_mtcnn.py\\\\nindex 7d5e735..21f1457 100644\\\\n--- a/src/align/align_dataset_mtcnn.py\\\\n+++ b/src/align/align_dataset_mtcnn.py\\\\n@@ -31,8 +31,8 @@ import os\\\\n import argparse\\\\n import tensorflow as tf\\\\n import numpy as np\\\\n-import facenet\\\\n-import align.detect_face\\\\n+import facenet.src.facenet as facenet   #changed\\\\n+import detect_face  #changed\\\\n import random\\\\n from time import sleep\\\\n \\\\ndiff --git a/src/align/detect_face.py b/src/align/detect_face.py\\\\nindex 7f98ca7..3806b33 100644\\\\n--- a/src/align/detect_face.py\\\\n+++ b/src/align/detect_face.py\\\\n@@ -82,7 +82,10 @@ class Network(object):\\\\n         session: The current TensorFlow session\\\\n         ignore_missing: If true, serialized weights for missing layers are ignored.\\\\n         """\\\\n+        np_load_old = np.load\\\\n+        np.load = lambda *a, **k: np_load_old(*a, allow_pickle=True, **k)\\\\n         data_dict = np.load(data_path, encoding=\\\\\\\'latin1\\\\\\\').item() #pylint: disable=no-member\\\\n+        np.load = np_load_old\\\\n \\\\n         for op_name in data_dict:\\\\n             with tf.variable_scope(op_name, reuse=True):\\\\ndiff --git a/src/facenet.py b/src/facenet.py\\\\nindex 0e05676..538b650 100644\\\\n--- a/src/facenet.py\\\\n+++ b/src/facenet.py\\\\n@@ -32,6 +32,7 @@ from subprocess import Popen, PIPE\\\\n import tensorflow as tf\\\\n import numpy as np\\\\n from scipy import misc\\\\n+import imageio\\\\n from sklearn.model_selection import KFold\\\\n from scipy import interpolate\\\\n from tensorflow.python.training import training\\\\n@@ -244,7 +245,7 @@ def load_data(image_paths, do_random_crop, do_random_flip, image_size, do_prewhi\\\\n     nrof_samples = len(image_paths)\\\\n     images = np.zeros((nrof_samples, image_size, image_size, 3))\\\\n     for i in range(nrof_samples):\\\\n-        img = misc.imread(image_paths[i])\\\\n+        img = imageio.imread(image_paths[i])\\\\n         if img.ndim == 2:\\\\n             img = to_rgb(img)\\\\n         if do_prewhiten:\\\'\\n\\\\ No newline at end of file\\ndiff --git a/Dataset/CSE20/raw/B160116CS_Aparna/B160116CS_1.jpeg b/Dataset/CSE20/raw/B160116CS_Aparna/B160116CS_1.jpeg\\nnew file mode 100644\\nindex 0000000..e23a8fc\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160116CS_Aparna/B160116CS_1.jpeg differ\\ndiff --git a/Dataset/CSE20/raw/B160116CS_Aparna/B160116CS_2.jpeg b/Dataset/CSE20/raw/B160116CS_Aparna/B160116CS_2.jpeg\\nnew file mode 100644\\nindex 0000000..f91beaf\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160116CS_Aparna/B160116CS_2.jpeg differ\\ndiff --git a/Dataset/CSE20/raw/B160116CS_Aparna/B160116CS_3.jpeg b/Dataset/CSE20/raw/B160116CS_Aparna/B160116CS_3.jpeg\\nnew file mode 100644\\nindex 0000000..c0bab07\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160116CS_Aparna/B160116CS_3.jpeg differ\\ndiff --git a/Dataset/CSE20/raw/B160118CS_Neeraja/B160118CS_1.jpeg b/Dataset/CSE20/raw/B160118CS_Neeraja/B160118CS_1.jpeg\\nnew file mode 100644\\nindex 0000000..d7870a6\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160118CS_Neeraja/B160118CS_1.jpeg differ\\ndiff --git a/Dataset/CSE20/raw/B160118CS_Neeraja/B160118CS_2.jpeg b/Dataset/CSE20/raw/B160118CS_Neeraja/B160118CS_2.jpeg\\nnew file mode 100644\\nindex 0000000..0af9819\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160118CS_Neeraja/B160118CS_2.jpeg differ\\ndiff --git a/Dataset/CSE20/raw/B160118CS_Neeraja/B160118CS_3.jpeg b/Dataset/CSE20/raw/B160118CS_Neeraja/B160118CS_3.jpeg\\nnew file mode 100644\\nindex 0000000..1fa8fb3\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160118CS_Neeraja/B160118CS_3.jpeg differ\\ndiff --git a/Dataset/CSE20/raw/B160213CS_Nileena/B160213CS_1.jpeg b/Dataset/CSE20/raw/B160213CS_Nileena/B160213CS_1.jpeg\\nnew file mode 100644\\nindex 0000000..0571099\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160213CS_Nileena/B160213CS_1.jpeg differ\\ndiff --git a/Dataset/CSE20/raw/B160213CS_Nileena/B160213CS_2.jpeg b/Dataset/CSE20/raw/B160213CS_Nileena/B160213CS_2.jpeg\\nnew file mode 100644\\nindex 0000000..b834bd2\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160213CS_Nileena/B160213CS_2.jpeg differ\\ndiff --git a/Dataset/CSE20/raw/B160213CS_Nileena/B160213CS_3.jpeg b/Dataset/CSE20/raw/B160213CS_Nileena/B160213CS_3.jpeg\\nnew file mode 100644\\nindex 0000000..6f90c78\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160213CS_Nileena/B160213CS_3.jpeg differ\\ndiff --git a/Dataset/CSE20/raw/B160228CS_Vrindha/B160226CS_1.jpeg b/Dataset/CSE20/raw/B160228CS_Vrindha/B160226CS_1.jpeg\\nnew file mode 100644\\nindex 0000000..cc17e86\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160228CS_Vrindha/B160226CS_1.jpeg differ\\ndiff --git a/Dataset/CSE20/raw/B160228CS_Vrindha/B160226CS_2.jpeg b/Dataset/CSE20/raw/B160228CS_Vrindha/B160226CS_2.jpeg\\nnew file mode 100644\\nindex 0000000..f05098d\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160228CS_Vrindha/B160226CS_2.jpeg differ\\ndiff --git a/Dataset/CSE20/raw/B160228CS_Vrindha/B160226CS_3.jpeg b/Dataset/CSE20/raw/B160228CS_Vrindha/B160226CS_3.jpeg\\nnew file mode 100644\\nindex 0000000..bd97e68\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160228CS_Vrindha/B160226CS_3.jpeg differ\\ndiff --git a/Dataset/CSE20/raw/B160229CS_Reema/B160229CS_1.jpeg b/Dataset/CSE20/raw/B160229CS_Reema/B160229CS_1.jpeg\\nnew file mode 100644\\nindex 0000000..03232a8\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160229CS_Reema/B160229CS_1.jpeg differ\\ndiff --git a/Dataset/CSE20/raw/B160229CS_Reema/B160229CS_2.jpeg b/Dataset/CSE20/raw/B160229CS_Reema/B160229CS_2.jpeg\\nnew file mode 100644\\nindex 0000000..f2f9a82\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160229CS_Reema/B160229CS_2.jpeg differ\\ndiff --git a/Dataset/CSE20/raw/B160229CS_Reema/B160229CS_3.jpeg b/Dataset/CSE20/raw/B160229CS_Reema/B160229CS_3.jpeg\\nnew file mode 100644\\nindex 0000000..caced02\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160229CS_Reema/B160229CS_3.jpeg differ\\ndiff --git a/Dataset/CSE20/raw/B160270CS_Lakshmi/B160270CS_1.jpeg b/Dataset/CSE20/raw/B160270CS_Lakshmi/B160270CS_1.jpeg\\nnew file mode 100644\\nindex 0000000..b6d3dea\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160270CS_Lakshmi/B160270CS_1.jpeg differ\\ndiff --git a/Dataset/CSE20/raw/B160270CS_Lakshmi/B160270CS_2.jpeg b/Dataset/CSE20/raw/B160270CS_Lakshmi/B160270CS_2.jpeg\\nnew file mode 100644\\nindex 0000000..26ac294\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160270CS_Lakshmi/B160270CS_2.jpeg differ\\ndiff --git a/Dataset/CSE20/raw/B160270CS_Lakshmi/B160270CS_3.jpeg b/Dataset/CSE20/raw/B160270CS_Lakshmi/B160270CS_3.jpeg\\nnew file mode 100644\\nindex 0000000..670eb75\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160270CS_Lakshmi/B160270CS_3.jpeg differ\\ndiff --git a/Dataset/CSE20/raw/B160270CS_Lakshmi/B160270CS_4.jpeg b/Dataset/CSE20/raw/B160270CS_Lakshmi/B160270CS_4.jpeg\\nnew file mode 100644\\nindex 0000000..5fab205\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160270CS_Lakshmi/B160270CS_4.jpeg differ\\ndiff --git a/Dataset/CSE20/raw/B160270CS_Lakshmi/B160270CS_5.jpeg b/Dataset/CSE20/raw/B160270CS_Lakshmi/B160270CS_5.jpeg\\nnew file mode 100644\\nindex 0000000..32abaf3\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160270CS_Lakshmi/B160270CS_5.jpeg differ\\ndiff --git a/Dataset/CSE20/raw/B160320ME_Shebin/B160320ME_1.jpeg b/Dataset/CSE20/raw/B160320ME_Shebin/B160320ME_1.jpeg\\nnew file mode 100644\\nindex 0000000..2fd54a5\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160320ME_Shebin/B160320ME_1.jpeg differ\\ndiff --git a/Dataset/CSE20/raw/B160320ME_Shebin/B160320ME_2.jpeg b/Dataset/CSE20/raw/B160320ME_Shebin/B160320ME_2.jpeg\\nnew file mode 100644\\nindex 0000000..1e896db\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160320ME_Shebin/B160320ME_2.jpeg differ\\ndiff --git a/Dataset/CSE20/raw/B160320ME_Shebin/B160320ME_3.jpeg b/Dataset/CSE20/raw/B160320ME_Shebin/B160320ME_3.jpeg\\nnew file mode 100644\\nindex 0000000..2587d2d\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160320ME_Shebin/B160320ME_3.jpeg differ\\ndiff --git a/Dataset/CSE20/raw/B160408CS_Ameen/B160408CS_1.jpeg b/Dataset/CSE20/raw/B160408CS_Ameen/B160408CS_1.jpeg\\nnew file mode 100644\\nindex 0000000..1fa10aa\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160408CS_Ameen/B160408CS_1.jpeg differ\\ndiff --git a/Dataset/CSE20/raw/B160408CS_Ameen/B160408CS_2.jpeg b/Dataset/CSE20/raw/B160408CS_Ameen/B160408CS_2.jpeg\\nnew file mode 100644\\nindex 0000000..96b4941\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160408CS_Ameen/B160408CS_2.jpeg differ\\ndiff --git a/Dataset/CSE20/raw/B160408CS_Ameen/B160408CS_3.jpeg b/Dataset/CSE20/raw/B160408CS_Ameen/B160408CS_3.jpeg\\nnew file mode 100644\\nindex 0000000..f275bc4\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160408CS_Ameen/B160408CS_3.jpeg differ\\ndiff --git a/Dataset/CSE20/raw/B160445CS_Sumalatha/B160445CS_1.jpeg b/Dataset/CSE20/raw/B160445CS_Sumalatha/B160445CS_1.jpeg\\nnew file mode 100644\\nindex 0000000..c317aa8\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160445CS_Sumalatha/B160445CS_1.jpeg differ\\ndiff --git a/Dataset/CSE20/raw/B160445CS_Sumalatha/B160445CS_2.jpeg b/Dataset/CSE20/raw/B160445CS_Sumalatha/B160445CS_2.jpeg\\nnew file mode 100644\\nindex 0000000..5ab2818\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160445CS_Sumalatha/B160445CS_2.jpeg differ\\ndiff --git a/Dataset/CSE20/raw/B160445CS_Sumalatha/B160445CS_3.jpeg b/Dataset/CSE20/raw/B160445CS_Sumalatha/B160445CS_3.jpeg\\nnew file mode 100644\\nindex 0000000..0159b52\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160445CS_Sumalatha/B160445CS_3.jpeg differ\\ndiff --git a/Dataset/CSE20/raw/B160471CS_Dheeraj/B160471CS_1.jpeg b/Dataset/CSE20/raw/B160471CS_Dheeraj/B160471CS_1.jpeg\\nnew file mode 100644\\nindex 0000000..9d6bec9\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160471CS_Dheeraj/B160471CS_1.jpeg differ\\ndiff --git a/Dataset/CSE20/raw/B160688CS_Vishnu/B160688CS_1.jpg b/Dataset/CSE20/raw/B160688CS_Vishnu/B160688CS_1.jpg\\nnew file mode 100644\\nindex 0000000..537a4c0\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160688CS_Vishnu/B160688CS_1.jpg differ\\ndiff --git a/Dataset/CSE20/raw/B160688CS_Vishnu/B160688CS_2.jpg b/Dataset/CSE20/raw/B160688CS_Vishnu/B160688CS_2.jpg\\nnew file mode 100644\\nindex 0000000..0442b3d\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160688CS_Vishnu/B160688CS_2.jpg differ\\ndiff --git a/Dataset/CSE20/raw/B160688CS_Vishnu/B160688CS_3.jpeg b/Dataset/CSE20/raw/B160688CS_Vishnu/B160688CS_3.jpeg\\nnew file mode 100644\\nindex 0000000..460d134\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160688CS_Vishnu/B160688CS_3.jpeg differ\\ndiff --git a/Dataset/CSE20/raw/B160760CS_Vatsala/B160760CS_1.jpeg b/Dataset/CSE20/raw/B160760CS_Vatsala/B160760CS_1.jpeg\\nnew file mode 100644\\nindex 0000000..2856b8e\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160760CS_Vatsala/B160760CS_1.jpeg differ\\ndiff --git a/Dataset/CSE20/raw/B160760CS_Vatsala/B160760CS_2.jpeg b/Dataset/CSE20/raw/B160760CS_Vatsala/B160760CS_2.jpeg\\nnew file mode 100644\\nindex 0000000..76e5ceb\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160760CS_Vatsala/B160760CS_2.jpeg differ\\ndiff --git a/Dataset/CSE20/raw/B160760CS_Vatsala/B160760CS_3.jpeg b/Dataset/CSE20/raw/B160760CS_Vatsala/B160760CS_3.jpeg\\nnew file mode 100644\\nindex 0000000..f43a8a7\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160760CS_Vatsala/B160760CS_3.jpeg differ\\ndiff --git a/Dataset/CSE20/raw/B160873CS_Naina/B160873CS_1.jpg b/Dataset/CSE20/raw/B160873CS_Naina/B160873CS_1.jpg\\nnew file mode 100644\\nindex 0000000..0c66c88\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160873CS_Naina/B160873CS_1.jpg differ\\ndiff --git a/Dataset/CSE20/raw/B160873CS_Naina/B160873CS_2.jpg b/Dataset/CSE20/raw/B160873CS_Naina/B160873CS_2.jpg\\nnew file mode 100644\\nindex 0000000..ad8c724\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160873CS_Naina/B160873CS_2.jpg differ\\ndiff --git a/Dataset/CSE20/raw/B160873CS_Naina/B160873CS_3.png b/Dataset/CSE20/raw/B160873CS_Naina/B160873CS_3.png\\nnew file mode 100644\\nindex 0000000..361493f\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160873CS_Naina/B160873CS_3.png differ\\ndiff --git a/Models/CSE20/CSE20.pkl b/Models/CSE20/CSE20.pkl\\nnew file mode 100644\\nindex 0000000..3793ef7\\nBinary files /dev/null and b/Models/CSE20/CSE20.pkl differ\\ndiff --git a/Models/facenet/20180402-114759.pb b/Models/facenet/20180402-114759.pb\\nnew file mode 100644\\nindex 0000000..39b4ed7\\nBinary files /dev/null and b/Models/facenet/20180402-114759.pb differ\\ndiff --git a/Models/facenet/model-20180402-114759.ckpt-275.data-00000-of-00001 b/Models/facenet/model-20180402-114759.ckpt-275.data-00000-of-00001\\nnew file mode 100755\\nindex 0000000..6160198\\nBinary files /dev/null and b/Models/facenet/model-20180402-114759.ckpt-275.data-00000-of-00001 differ\\ndiff --git a/Models/facenet/model-20180402-114759.ckpt-275.index b/Models/facenet/model-20180402-114759.ckpt-275.index\\nnew file mode 100755\\nindex 0000000..e2b346c\\nBinary files /dev/null and b/Models/facenet/model-20180402-114759.ckpt-275.index differ\\ndiff --git a/Models/facenet/model-20180402-114759.meta b/Models/facenet/model-20180402-114759.meta\\nnew file mode 100755\\nindex 0000000..abffaef\\nBinary files /dev/null and b/Models/facenet/model-20180402-114759.meta differ\\ndiff --git a/src/align/align_dataset_mtcnn.py b/src/align/align_dataset_mtcnn.py\\nindex 7d5e735..21f1457 100644\\n--- a/src/align/align_dataset_mtcnn.py\\n+++ b/src/align/align_dataset_mtcnn.py\\n@@ -31,8 +31,8 @@ import os\\n import argparse\\n import tensorflow as tf\\n import numpy as np\\n-import facenet\\n-import align.detect_face\\n+import facenet.src.facenet as facenet   #changed\\n+import detect_face  #changed\\n import random\\n from time import sleep\\n \\ndiff --git a/src/align/detect_face.py b/src/align/detect_face.py\\nindex 7f98ca7..3806b33 100644\\n--- a/src/align/detect_face.py\\n+++ b/src/align/detect_face.py\\n@@ -82,7 +82,10 @@ class Network(object):\\n         session: The current TensorFlow session\\n         ignore_missing: If true, serialized weights for missing layers are ignored.\\n         """\\n+        np_load_old = np.load\\n+        np.load = lambda *a, **k: np_load_old(*a, allow_pickle=True, **k)\\n         data_dict = np.load(data_path, encoding=\\\'latin1\\\').item() #pylint: disable=no-member\\n+        np.load = np_load_old\\n \\n         for op_name in data_dict:\\n             with tf.variable_scope(op_name, reuse=True):\\ndiff --git a/src/align_dataset_mtcnn.py b/src/align_dataset_mtcnn.py\\nnew file mode 100644\\nindex 0000000..2c2acc4\\n--- /dev/null\\n+++ b/src/align_dataset_mtcnn.py\\n@@ -0,0 +1,161 @@\\n+"""Performs face alignment and stores face thumbnails in the output directory."""\\n+# MIT License\\n+# \\n+# Copyright (c) 2016 David Sandberg\\n+# \\n+# Permission is hereby granted, free of charge, to any person obtaining a copy\\n+# of this software and associated documentation files (the "Software"), to deal\\n+# in the Software without restriction, including without limitation the rights\\n+# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\n+# copies of the Software, and to permit persons to whom the Software is\\n+# furnished to do so, subject to the following conditions:\\n+# \\n+# The above copyright notice and this permission notice shall be included in all\\n+# copies or substantial portions of the Software.\\n+# \\n+# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\n+# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\n+# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\n+# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\n+# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\n+# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\n+# SOFTWARE.\\n+\\n+from __future__ import absolute_import\\n+from __future__ import division\\n+from __future__ import print_function\\n+\\n+from scipy import misc\\n+import imageio #for imread since it\\\'s depricated in scipy.misc\\n+import skimage #for imresize since it\\\'s depricated in scipy.misc\\n+import sys\\n+import os\\n+import argparse\\n+import tensorflow as tf\\n+import numpy as np\\n+import facenet\\n+import align.detect_face\\n+import random\\n+from time import sleep\\n+\\n+def main(args):\\n+    sleep(random.random())\\n+    output_dir = os.path.expanduser(args.output_dir)\\n+    if not os.path.exists(output_dir):\\n+        os.makedirs(output_dir)\\n+    # Store some git revision info in a text file in the log directory\\n+    src_path,_ = os.path.split(os.path.realpath(__file__))\\n+    facenet.store_revision_info(src_path, output_dir, \\\' \\\'.join(sys.argv))\\n+    dataset = facenet.get_dataset(args.input_dir)\\n+    \\n+    print(\\\'Creating networks and loading parameters\\\')\\n+    \\n+    with tf.Graph().as_default():\\n+        gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=args.gpu_memory_fraction)\\n+        sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options, log_device_placement=False))\\n+        with sess.as_default():\\n+            pnet, rnet, onet = align.detect_face.create_mtcnn(sess, None)\\n+    \\n+    minsize = 20 # minimum size of face\\n+    threshold = [ 0.6, 0.7, 0.7 ]  # three steps\\\'s threshold\\n+    factor = 0.709 # scale factor\\n+\\n+    # Add a random key to the filename to allow alignment using multiple processes\\n+    random_key = np.random.randint(0, high=99999)\\n+    bounding_boxes_filename = os.path.join(output_dir, \\\'bounding_boxes_%05d.txt\\\' % random_key)\\n+    \\n+    with open(bounding_boxes_filename, "w") as text_file:\\n+        nrof_images_total = 0\\n+        nrof_successfully_aligned = 0\\n+        if args.random_order:\\n+            random.shuffle(dataset)\\n+        for cls in dataset:\\n+            output_class_dir = os.path.join(output_dir, cls.name)\\n+            if not os.path.exists(output_class_dir):\\n+                os.makedirs(output_class_dir)\\n+                if args.random_order:\\n+                    random.shuffle(cls.image_paths)\\n+            for image_path in cls.image_paths:\\n+                nrof_images_total += 1\\n+                filename = os.path.splitext(os.path.split(image_path)[1])[0]\\n+                output_filename = os.path.join(output_class_dir, filename+\\\'.png\\\')\\n+                print(image_path)\\n+                if not os.path.exists(output_filename):\\n+                    try:\\n+                        img = imageio.imread(image_path)\\n+                    except (IOError, ValueError, IndexError) as e:\\n+                        errorMessage = \\\'{}: {}\\\'.format(image_path, e)\\n+                        print(errorMessage)\\n+                    else:\\n+                        if img.ndim<2:\\n+                            print(\\\'Unable to align "%s"\\\' % image_path)\\n+                            text_file.write(\\\'%s\\\\n\\\' % (output_filename))\\n+                            continue\\n+                        if img.ndim == 2:\\n+                            img = facenet.to_rgb(img)\\n+                        img = img[:,:,0:3]\\n+    \\n+                        bounding_boxes, _ = align.detect_face.detect_face(img, minsize, pnet, rnet, onet, threshold, factor)\\n+                        nrof_faces = bounding_boxes.shape[0]\\n+                        if nrof_faces>0:\\n+                            det = bounding_boxes[:,0:4]\\n+                            det_arr = []\\n+                            img_size = np.asarray(img.shape)[0:2]\\n+                            if nrof_faces>1:\\n+                                if args.detect_multiple_faces:\\n+                                    for i in range(nrof_faces):\\n+                                        det_arr.append(np.squeeze(det[i]))\\n+                                else:\\n+                                    bounding_box_size = (det[:,2]-det[:,0])*(det[:,3]-det[:,1])\\n+                                    img_center = img_size / 2\\n+                                    offsets = np.vstack([ (det[:,0]+det[:,2])/2-img_center[1], (det[:,1]+det[:,3])/2-img_center[0] ])\\n+                                    offset_dist_squared = np.sum(np.power(offsets,2.0),0)\\n+                                    index = np.argmax(bounding_box_size-offset_dist_squared*2.0) # some extra weight on the centering\\n+                                    det_arr.append(det[index,:])\\n+                            else:\\n+                                det_arr.append(np.squeeze(det))\\n+\\n+                            for i, det in enumerate(det_arr):\\n+                                det = np.squeeze(det)\\n+                                bb = np.zeros(4, dtype=np.int32)\\n+                                bb[0] = np.maximum(det[0]-args.margin/2, 0)\\n+                                bb[1] = np.maximum(det[1]-args.margin/2, 0)\\n+                                bb[2] = np.minimum(det[2]+args.margin/2, img_size[1])\\n+                                bb[3] = np.minimum(det[3]+args.margin/2, img_size[0])\\n+                                cropped = img[bb[1]:bb[3],bb[0]:bb[2],:]\\n+                                scaled = skimage.transform.resize(cropped, (args.image_size, args.image_size))\\n+                                nrof_successfully_aligned += 1\\n+                                filename_base, file_extension = os.path.splitext(output_filename)\\n+                                if args.detect_multiple_faces:\\n+                                    output_filename_n = "{}_{}{}".format(filename_base, i, file_extension)\\n+                                else:\\n+                                    output_filename_n = "{}{}".format(filename_base, file_extension)\\n+                                imageio.imwrite(output_filename_n, scaled)\\n+                                text_file.write(\\\'%s %d %d %d %d\\\\n\\\' % (output_filename_n, bb[0], bb[1], bb[2], bb[3]))\\n+                        else:\\n+                            print(\\\'Unable to align "%s"\\\' % image_path)\\n+                            text_file.write(\\\'%s\\\\n\\\' % (output_filename))\\n+                            \\n+    print(\\\'Total number of images: %d\\\' % nrof_images_total)\\n+    print(\\\'Number of successfully aligned images: %d\\\' % nrof_successfully_aligned)\\n+            \\n+\\n+def parse_arguments(argv):\\n+    parser = argparse.ArgumentParser()\\n+    \\n+    parser.add_argument(\\\'input_dir\\\', type=str, help=\\\'Directory with unaligned images.\\\')\\n+    parser.add_argument(\\\'output_dir\\\', type=str, help=\\\'Directory with aligned face thumbnails.\\\')\\n+    parser.add_argument(\\\'--image_size\\\', type=int,\\n+        help=\\\'Image size (height, width) in pixels.\\\', default=182)\\n+    parser.add_argument(\\\'--margin\\\', type=int,\\n+        help=\\\'Margin for the crop around the bounding box (height, width) in pixels.\\\', default=44)\\n+    parser.add_argument(\\\'--random_order\\\', \\n+        help=\\\'Shuffles the order of images to enable alignment using multiple processes.\\\', action=\\\'store_true\\\')\\n+    parser.add_argument(\\\'--gpu_memory_fraction\\\', type=float,\\n+        help=\\\'Upper bound on the amount of GPU memory that will be used by the process.\\\', default=1.0)\\n+    parser.add_argument(\\\'--detect_multiple_faces\\\', type=bool,\\n+                        help=\\\'Detect and align multiple faces per image.\\\', default=False)\\n+    return parser.parse_args(argv)\\n+\\n+if __name__ == \\\'__main__\\\':\\n+    main(parse_arguments(sys.argv[1:]))\\ndiff --git a/src/faceRec.py b/src/faceRec.py\\nnew file mode 100644\\nindex 0000000..a5531a2\\n--- /dev/null\\n+++ b/src/faceRec.py\\n@@ -0,0 +1,117 @@\\n+from __future__ import absolute_import\\n+from __future__ import division\\n+from __future__ import print_function\\n+\\n+import tensorflow as tf\\n+import argparse\\n+import facenet\\n+import os\\n+import sys\\n+import math\\n+import pickle\\n+import align.detect_face\\n+import numpy as np\\n+import cv2\\n+import collections\\n+from sklearn.svm import SVC\\n+\\n+\\n+def main():\\n+    parser = argparse.ArgumentParser()\\n+    parser.add_argument(\\\'--path\\\', help=\\\'Path of the video you want to test on.\\\', default=0)\\n+    args = parser.parse_args()\\n+\\n+    MINSIZE = 20\\n+    THRESHOLD = [0.6, 0.7, 0.7]\\n+    FACTOR = 0.709\\n+    IMAGE_SIZE = 182\\n+    INPUT_IMAGE_SIZE = 160\\n+    CLASSIFIER_PATH = \\\'Models/CSE20/CSE20.pkl\\\'\\n+    VIDEO_PATH = args.path\\n+    FACENET_MODEL_PATH = \\\'Models/facenet/20180402-114759.pb\\\'\\n+\\n+    # Load The Custom Classifier\\n+    with open(CLASSIFIER_PATH, \\\'rb\\\') as file:\\n+        model, class_names = pickle.load(file)\\n+    print("Custom Classifier, Successfully loaded")\\n+\\n+    with tf.Graph().as_default():\\n+\\n+        gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.6)\\n+        sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options, log_device_placement=False))\\n+\\n+        with sess.as_default():\\n+\\n+            # Load the model\\n+            print(\\\'Loading feature extraction model\\\')\\n+            facenet.load_model(FACENET_MODEL_PATH)\\n+\\n+            # Get input and output tensors\\n+            images_placeholder = tf.get_default_graph().get_tensor_by_name("input:0")\\n+            embeddings = tf.get_default_graph().get_tensor_by_name("embeddings:0")\\n+            phase_train_placeholder = tf.get_default_graph().get_tensor_by_name("phase_train:0")\\n+            embedding_size = embeddings.get_shape()[1]\\n+\\n+            pnet, rnet, onet = align.detect_face.create_mtcnn(sess, "./src/align")\\n+\\n+            people_detected = set()\\n+            person_detected = collections.Counter()\\n+\\n+            cap = cv2.VideoCapture(VIDEO_PATH)\\n+\\n+            while (cap.isOpened()):\\n+                ret, frame = cap.read()\\n+\\n+                bounding_boxes, _ = align.detect_face.detect_face(frame, MINSIZE, pnet, rnet, onet, THRESHOLD, FACTOR)\\n+\\n+                faces_found = bounding_boxes.shape[0]\\n+                try:\\n+                    if faces_found > 0:\\n+                        det = bounding_boxes[:, 0:4]\\n+                        bb = np.zeros((faces_found, 4), dtype=np.int32)\\n+                        for i in range(faces_found):\\n+                            bb[i][0] = det[i][0]\\n+                            bb[i][1] = det[i][1]\\n+                            bb[i][2] = det[i][2]\\n+                            bb[i][3] = det[i][3]\\n+\\n+                            cropped = frame[bb[i][1]:bb[i][3], bb[i][0]:bb[i][2], :]\\n+                            scaled = cv2.resize(cropped, (INPUT_IMAGE_SIZE, INPUT_IMAGE_SIZE),\\n+                                                interpolation=cv2.INTER_CUBIC)\\n+                            scaled = facenet.prewhiten(scaled)\\n+                            scaled_reshape = scaled.reshape(-1, INPUT_IMAGE_SIZE, INPUT_IMAGE_SIZE, 3)\\n+                            feed_dict = {images_placeholder: scaled_reshape, phase_train_placeholder: False}\\n+                            emb_array = sess.run(embeddings, feed_dict=feed_dict)\\n+                            predictions = model.predict_proba(emb_array)\\n+                            best_class_indices = np.argmax(predictions, axis=1)\\n+                            best_class_probabilities = predictions[\\n+                                np.arange(len(best_class_indices)), best_class_indices]\\n+                            best_name = class_names[best_class_indices[0]]\\n+                            print("Name: {}, Probability: {}".format(best_name, best_class_probabilities))\\n+\\n+                            cv2.rectangle(frame, (bb[i][0], bb[i][1]), (bb[i][2], bb[i][3]), (0, 255, 0), 2)\\n+                            text_x = bb[i][0]\\n+                            text_y = bb[i][3] + 20\\n+\\n+                            if best_class_probabilities > 0.15:\\n+                                name = class_names[best_class_indices[0]]\\n+                            else:\\n+                                name = "Unknown"\\n+                            cv2.putText(frame, name, (text_x, text_y), cv2.FONT_HERSHEY_COMPLEX_SMALL,\\n+                                        1, (255, 255, 255), thickness=1, lineType=2)\\n+                            cv2.putText(frame, str(round(best_class_probabilities[0], 3)), (text_x, text_y + 17),\\n+                                        cv2.FONT_HERSHEY_COMPLEX_SMALL,\\n+                                        1, (255, 255, 255), thickness=1, lineType=2)\\n+                            person_detected[best_name] += 1\\n+                except:\\n+                    pass\\n+\\n+                cv2.imshow(\\\'Face Recognition\\\', frame)\\n+                if cv2.waitKey(1) & 0xFF == ord(\\\'q\\\'):\\n+                    break\\n+\\n+            cap.release()\\n+            cv2.destroyAllWindows()\\n+\\n+\\n+main()\\n\\\\ No newline at end of file\\ndiff --git a/src/facenet.py b/src/facenet.py\\nindex 0e05676..538b650 100644\\n--- a/src/facenet.py\\n+++ b/src/facenet.py\\n@@ -32,6 +32,7 @@ from subprocess import Popen, PIPE\\n import tensorflow as tf\\n import numpy as np\\n from scipy import misc\\n+import imageio\\n from sklearn.model_selection import KFold\\n from scipy import interpolate\\n from tensorflow.python.training import training\\n@@ -244,7 +245,7 @@ def load_data(image_paths, do_random_crop, do_random_flip, image_size, do_prewhi\\n     nrof_samples = len(image_paths)\\n     images = np.zeros((nrof_samples, image_size, image_size, 3))\\n     for i in range(nrof_samples):\\n-        img = misc.imread(image_paths[i])\\n+        img = imageio.imread(image_paths[i])\\n         if img.ndim == 2:\\n             img = to_rgb(img)\\n         if do_prewhiten:\'\n-\\ No newline at end of file\n-diff --git a/main/Dataset/CSE20/raw/B160116CS_Aparna/B160116CS_1.jpeg b/main/Dataset/CSE20/raw/B160116CS_Aparna/B160116CS_1.jpeg\n-index e23a8fc..d50e775 100644\n-Binary files a/main/Dataset/CSE20/raw/B160116CS_Aparna/B160116CS_1.jpeg and b/main/Dataset/CSE20/raw/B160116CS_Aparna/B160116CS_1.jpeg differ\n-diff --git a/main/README.md b/main/README.md\n-index 9220d20..baaeced 100644\n---- a/main/README.md\n-+++ b/main/README.md\n-@@ -53,3 +53,4 @@ A couple of pretrained models are provided. They are trained using softmax loss\n- \n- ## Performance\n- The accuracy on LFW for the model [20180402-114759](https://drive.google.com/open?id=1EXPBSXwTaqrSC0OhUdXNmKSh9qJUQ55-) is 0.99650+-0.00252. A description of how to run the test can be found on the page [Validate on LFW](https://github.com/davidsandberg/facenet/wiki/Validate-on-lfw). Note that the input images to the model need to be standardized using fixed image standardization (use the option `--use_fixed_image_standardization` when running e.g. `validate_on_lfw.py`).\n-+\n-diff --git a/main/requirements.txt b/main/requirements.txt\n-index b7418c9..167b725 100644\n---- a/main/requirements.txt\n-+++ b/main/requirements.txt\n-@@ -7,3 +7,5 @@ matplotlib\n- Pillow\n- requests\n- psutil\n-+imageio\n-+scikit-image\n\\ No newline at end of file\n+b\'diff --git a/main/Dataset/CSE20/processed/B160760CS_Vatsala/B160760CS_1.png b/main/Dataset/CSE20/processed/B160760CS_Vatsala/B160760CS_1.png\\ndeleted file mode 100644\\nindex 6db8c65..0000000\\nBinary files a/main/Dataset/CSE20/processed/B160760CS_Vatsala/B160760CS_1.png and /dev/null differ\\ndiff --git a/main/Dataset/CSE20/processed/B160760CS_Vatsala/B160760CS_2.png b/main/Dataset/CSE20/processed/B160760CS_Vatsala/B160760CS_2.png\\ndeleted file mode 100644\\nindex af039a9..0000000\\nBinary files a/main/Dataset/CSE20/processed/B160760CS_Vatsala/B160760CS_2.png and /dev/null differ\\ndiff --git a/main/Dataset/CSE20/processed/B160760CS_Vatsala/B160760CS_3.png b/main/Dataset/CSE20/processed/B160760CS_Vatsala/B160760CS_3.png\\ndeleted file mode 100644\\nindex bb157bf..0000000\\nBinary files a/main/Dataset/CSE20/processed/B160760CS_Vatsala/B160760CS_3.png and /dev/null differ\\ndiff --git a/main/Dataset/CSE20/processed/revision_info.txt b/main/Dataset/CSE20/processed/revision_info.txt\\nindex 3f5e408..433b9eb 100644\\n--- a/main/Dataset/CSE20/processed/revision_info.txt\\n+++ b/main/Dataset/CSE20/processed/revision_info.txt\\n@@ -1,287 +1,7 @@\\n-arguments: src/align_dataset_mtcnn.py ./Dataset/CSE20/raw/ ./Dataset/CSE20/processed --image_size 160 --margin 32 --random_order --gpu_memory_fraction 0.25\\n+arguments: src\\\\align_dataset_mtcnn.py Dataset\\\\CSE20\\\\raw Dataset\\\\CSE20\\\\processed --image_size 160 --margin 32 --random_order --gpu_memory_fraction 0.25\\n --------------------\\n-tensorflow version: 1.7.0\\n+tensorflow version: 1.13.1\\n --------------------\\n-git hash: e5ea2411c6d8091a0c3ca0d6fe3c8be74790c9ab\\n+git hash: b\\\'3d0f9267137d67e77a29f907665b38c8bb4dcd1d\\\'\\n --------------------\\n-diff --git a/main/Dataset/CSE20/processed/B160116CS_Aparna/B160116CS_1.png b/main/Dataset/CSE20/processed/B160116CS_Aparna/B160116CS_1.png\\n-deleted file mode 100644\\n-index f1db83f..0000000\\n-Binary files a/main/Dataset/CSE20/processed/B160116CS_Aparna/B160116CS_1.png and /dev/null differ\\n-diff --git a/main/Dataset/CSE20/processed/B160116CS_Aparna/B160116CS_2.png b/main/Dataset/CSE20/processed/B160116CS_Aparna/B160116CS_2.png\\n-deleted file mode 100644\\n-index 45449c3..0000000\\n-Binary files a/main/Dataset/CSE20/processed/B160116CS_Aparna/B160116CS_2.png and /dev/null differ\\n-diff --git a/main/Dataset/CSE20/processed/B160116CS_Aparna/B160116CS_3.png b/main/Dataset/CSE20/processed/B160116CS_Aparna/B160116CS_3.png\\n-deleted file mode 100644\\n-index 9813f9f..0000000\\n-Binary files a/main/Dataset/CSE20/processed/B160116CS_Aparna/B160116CS_3.png and /dev/null differ\\n-diff --git a/main/Dataset/CSE20/processed/B160118CS_Neeraja/B160118CS_1.png b/main/Dataset/CSE20/processed/B160118CS_Neeraja/B160118CS_1.png\\n-deleted file mode 100644\\n-index fb52346..0000000\\n-Binary files a/main/Dataset/CSE20/processed/B160118CS_Neeraja/B160118CS_1.png and /dev/null differ\\n-diff --git a/main/Dataset/CSE20/processed/B160118CS_Neeraja/B160118CS_2.png b/main/Dataset/CSE20/processed/B160118CS_Neeraja/B160118CS_2.png\\n-deleted file mode 100644\\n-index 3a04b13..0000000\\n-Binary files a/main/Dataset/CSE20/processed/B160118CS_Neeraja/B160118CS_2.png and /dev/null differ\\n-diff --git a/main/Dataset/CSE20/processed/B160118CS_Neeraja/B160118CS_3.png b/main/Dataset/CSE20/processed/B160118CS_Neeraja/B160118CS_3.png\\n-deleted file mode 100644\\n-index f7c2d61..0000000\\n-Binary files a/main/Dataset/CSE20/processed/B160118CS_Neeraja/B160118CS_3.png and /dev/null differ\\n-diff --git a/main/Dataset/CSE20/processed/B160213CS_Nileena/B160213CS_1.png b/main/Dataset/CSE20/processed/B160213CS_Nileena/B160213CS_1.png\\n-deleted file mode 100644\\n-index 5affd0e..0000000\\n-Binary files a/main/Dataset/CSE20/processed/B160213CS_Nileena/B160213CS_1.png and /dev/null differ\\n-diff --git a/main/Dataset/CSE20/processed/B160213CS_Nileena/B160213CS_2.png b/main/Dataset/CSE20/processed/B160213CS_Nileena/B160213CS_2.png\\n-deleted file mode 100644\\n-index 6bf453c..0000000\\n-Binary files a/main/Dataset/CSE20/processed/B160213CS_Nileena/B160213CS_2.png and /dev/null differ\\n-diff --git a/main/Dataset/CSE20/processed/B160213CS_Nileena/B160213CS_3.png b/main/Dataset/CSE20/processed/B160213CS_Nileena/B160213CS_3.png\\n-deleted file mode 100644\\n-index c40a062..0000000\\n-Binary files a/main/Dataset/CSE20/processed/B160213CS_Nileena/B160213CS_3.png and /dev/null differ\\n-diff --git a/main/Dataset/CSE20/processed/B160228CS_Vrindha/B160226CS_1.png b/main/Dataset/CSE20/processed/B160228CS_Vrindha/B160226CS_1.png\\n-deleted file mode 100644\\n-index 598febb..0000000\\n-Binary files a/main/Dataset/CSE20/processed/B160228CS_Vrindha/B160226CS_1.png and /dev/null differ\\n-diff --git a/main/Dataset/CSE20/processed/B160228CS_Vrindha/B160226CS_2.png b/main/Dataset/CSE20/processed/B160228CS_Vrindha/B160226CS_2.png\\n-deleted file mode 100644\\n-index 90186c5..0000000\\n-Binary files a/main/Dataset/CSE20/processed/B160228CS_Vrindha/B160226CS_2.png and /dev/null differ\\n-diff --git a/main/Dataset/CSE20/processed/B160228CS_Vrindha/B160226CS_3.png b/main/Dataset/CSE20/processed/B160228CS_Vrindha/B160226CS_3.png\\n-deleted file mode 100644\\n-index 11e9bc8..0000000\\n-Binary files a/main/Dataset/CSE20/processed/B160228CS_Vrindha/B160226CS_3.png and /dev/null differ\\n-diff --git a/main/Dataset/CSE20/processed/B160229CS_Reema/B160229CS_1.png b/main/Dataset/CSE20/processed/B160229CS_Reema/B160229CS_1.png\\n-deleted file mode 100644\\n-index 078771e..0000000\\n-Binary files a/main/Dataset/CSE20/processed/B160229CS_Reema/B160229CS_1.png and /dev/null differ\\n-diff --git a/main/Dataset/CSE20/processed/B160229CS_Reema/B160229CS_2.png b/main/Dataset/CSE20/processed/B160229CS_Reema/B160229CS_2.png\\n-deleted file mode 100644\\n-index b4aee42..0000000\\n-Binary files a/main/Dataset/CSE20/processed/B160229CS_Reema/B160229CS_2.png and /dev/null differ\\n-diff --git a/main/Dataset/CSE20/processed/B160229CS_Reema/B160229CS_3.png b/main/Dataset/CSE20/processed/B160229CS_Reema/B160229CS_3.png\\n-deleted file mode 100644\\n-index 406508e..0000000\\n-Binary files a/main/Dataset/CSE20/processed/B160229CS_Reema/B160229CS_3.png and /dev/null differ\\n-diff --git a/main/Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_1.png b/main/Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_1.png\\n-deleted file mode 100644\\n-index cb05c38..0000000\\n-Binary files a/main/Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_1.png and /dev/null differ\\n-diff --git a/main/Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_2.png b/main/Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_2.png\\n-deleted file mode 100644\\n-index ebef29c..0000000\\n-Binary files a/main/Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_2.png and /dev/null differ\\n-diff --git a/main/Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_3.png b/main/Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_3.png\\n-deleted file mode 100644\\n-index 5b409b0..0000000\\n-Binary files a/main/Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_3.png and /dev/null differ\\n-diff --git a/main/Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_4.png b/main/Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_4.png\\n-deleted file mode 100644\\n-index 63291a9..0000000\\n-Binary files a/main/Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_4.png and /dev/null differ\\n-diff --git a/main/Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_5.png b/main/Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_5.png\\n-deleted file mode 100644\\n-index 35bb01f..0000000\\n-Binary files a/main/Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_5.png and /dev/null differ\\n-diff --git a/main/Dataset/CSE20/processed/B160320ME_Shebin/B160320ME_1.png b/main/Dataset/CSE20/processed/B160320ME_Shebin/B160320ME_1.png\\n-deleted file mode 100644\\n-index fa0c503..0000000\\n-Binary files a/main/Dataset/CSE20/processed/B160320ME_Shebin/B160320ME_1.png and /dev/null differ\\n-diff --git a/main/Dataset/CSE20/processed/B160320ME_Shebin/B160320ME_2.png b/main/Dataset/CSE20/processed/B160320ME_Shebin/B160320ME_2.png\\n-deleted file mode 100644\\n-index 79a0e5d..0000000\\n-Binary files a/main/Dataset/CSE20/processed/B160320ME_Shebin/B160320ME_2.png and /dev/null differ\\n-diff --git a/main/Dataset/CSE20/processed/B160320ME_Shebin/B160320ME_3.png b/main/Dataset/CSE20/processed/B160320ME_Shebin/B160320ME_3.png\\n-deleted file mode 100644\\n-index c03da94..0000000\\n-Binary files a/main/Dataset/CSE20/processed/B160320ME_Shebin/B160320ME_3.png and /dev/null differ\\n-diff --git a/main/Dataset/CSE20/processed/B160408CS_Ameen/B160408CS_1.png b/main/Dataset/CSE20/processed/B160408CS_Ameen/B160408CS_1.png\\n-deleted file mode 100644\\n-index 16a46a2..0000000\\n-Binary files a/main/Dataset/CSE20/processed/B160408CS_Ameen/B160408CS_1.png and /dev/null differ\\n-diff --git a/main/Dataset/CSE20/processed/B160408CS_Ameen/B160408CS_2.png b/main/Dataset/CSE20/processed/B160408CS_Ameen/B160408CS_2.png\\n-deleted file mode 100644\\n-index 7d933ff..0000000\\n-Binary files a/main/Dataset/CSE20/processed/B160408CS_Ameen/B160408CS_2.png and /dev/null differ\\n-diff --git a/main/Dataset/CSE20/processed/B160408CS_Ameen/B160408CS_3.png b/main/Dataset/CSE20/processed/B160408CS_Ameen/B160408CS_3.png\\n-deleted file mode 100644\\n-index ce20835..0000000\\n-Binary files a/main/Dataset/CSE20/processed/B160408CS_Ameen/B160408CS_3.png and /dev/null differ\\n-diff --git a/main/Dataset/CSE20/processed/B160445CS_Sumalatha/B160445CS_1.png b/main/Dataset/CSE20/processed/B160445CS_Sumalatha/B160445CS_1.png\\n-deleted file mode 100644\\n-index fd9ed6f..0000000\\n-Binary files a/main/Dataset/CSE20/processed/B160445CS_Sumalatha/B160445CS_1.png and /dev/null differ\\n-diff --git a/main/Dataset/CSE20/processed/B160445CS_Sumalatha/B160445CS_2.png b/main/Dataset/CSE20/processed/B160445CS_Sumalatha/B160445CS_2.png\\n-deleted file mode 100644\\n-index ad52a1d..0000000\\n-Binary files a/main/Dataset/CSE20/processed/B160445CS_Sumalatha/B160445CS_2.png and /dev/null differ\\n-diff --git a/main/Dataset/CSE20/processed/B160471CS_Dheeraj/B160471CS_1.png b/main/Dataset/CSE20/processed/B160471CS_Dheeraj/B160471CS_1.png\\n-deleted file mode 100644\\n-index 78a1983..0000000\\n-Binary files a/main/Dataset/CSE20/processed/B160471CS_Dheeraj/B160471CS_1.png and /dev/null differ\\n-diff --git a/main/Dataset/CSE20/processed/B160688CS_Vishnu/B160688CS_1.png b/main/Dataset/CSE20/processed/B160688CS_Vishnu/B160688CS_1.png\\n-deleted file mode 100644\\n-index f43b308..0000000\\n-Binary files a/main/Dataset/CSE20/processed/B160688CS_Vishnu/B160688CS_1.png and /dev/null differ\\n-diff --git a/main/Dataset/CSE20/processed/B160688CS_Vishnu/B160688CS_2.png b/main/Dataset/CSE20/processed/B160688CS_Vishnu/B160688CS_2.png\\n-deleted file mode 100644\\n-index 5654243..0000000\\n-Binary files a/main/Dataset/CSE20/processed/B160688CS_Vishnu/B160688CS_2.png and /dev/null differ\\n-diff --git a/main/Dataset/CSE20/processed/B160688CS_Vishnu/B160688CS_3.png b/main/Dataset/CSE20/processed/B160688CS_Vishnu/B160688CS_3.png\\n-deleted file mode 100644\\n-index 4db5286..0000000\\n-Binary files a/main/Dataset/CSE20/processed/B160688CS_Vishnu/B160688CS_3.png and /dev/null differ\\n-diff --git a/main/Dataset/CSE20/processed/B160760CS_Vatsala/B160760CS_1.png b/main/Dataset/CSE20/processed/B160760CS_Vatsala/B160760CS_1.png\\n-deleted file mode 100644\\n-index 80f206e..0000000\\n-Binary files a/main/Dataset/CSE20/processed/B160760CS_Vatsala/B160760CS_1.png and /dev/null differ\\n-diff --git a/main/Dataset/CSE20/processed/B160760CS_Vatsala/B160760CS_2.png b/main/Dataset/CSE20/processed/B160760CS_Vatsala/B160760CS_2.png\\n-deleted file mode 100644\\n-index fbdeadf..0000000\\n-Binary files a/main/Dataset/CSE20/processed/B160760CS_Vatsala/B160760CS_2.png and /dev/null differ\\n-diff --git a/main/Dataset/CSE20/processed/B160760CS_Vatsala/B160760CS_3.png b/main/Dataset/CSE20/processed/B160760CS_Vatsala/B160760CS_3.png\\n-deleted file mode 100644\\n-index b7bb5e8..0000000\\n-Binary files a/main/Dataset/CSE20/processed/B160760CS_Vatsala/B160760CS_3.png and /dev/null differ\\n-diff --git a/main/Dataset/CSE20/processed/B160873CS_Naina/B160873CS_1.png b/main/Dataset/CSE20/processed/B160873CS_Naina/B160873CS_1.png\\n-deleted file mode 100644\\n-index 71d405b..0000000\\n-Binary files a/main/Dataset/CSE20/processed/B160873CS_Naina/B160873CS_1.png and /dev/null differ\\n-diff --git a/main/Dataset/CSE20/processed/B160873CS_Naina/B160873CS_2.png b/main/Dataset/CSE20/processed/B160873CS_Naina/B160873CS_2.png\\n-deleted file mode 100644\\n-index 2018b5c..0000000\\n-Binary files a/main/Dataset/CSE20/processed/B160873CS_Naina/B160873CS_2.png and /dev/null differ\\n-diff --git a/main/Dataset/CSE20/processed/B160873CS_Naina/B160873CS_3.png b/main/Dataset/CSE20/processed/B160873CS_Naina/B160873CS_3.png\\n-deleted file mode 100644\\n-index 6f1ae5c..0000000\\n-Binary files a/main/Dataset/CSE20/processed/B160873CS_Naina/B160873CS_3.png and /dev/null differ\\n-diff --git a/main/Dataset/CSE20/processed/bounding_boxes_09361.txt b/main/Dataset/CSE20/processed/bounding_boxes_09361.txt\\n-deleted file mode 100644\\n-index da52b30..0000000\\n---- a/main/Dataset/CSE20/processed/bounding_boxes_09361.txt\\n-+++ /dev/null\\n-@@ -1,35 +0,0 @@\\n--Dataset/CSE20/processed/B160760CS_Vatsala/B160760CS_3.png 737 316 933 556\\n--Dataset/CSE20/processed/B160760CS_Vatsala/B160760CS_2.png 153 385 552 891\\n--Dataset/CSE20/processed/B160760CS_Vatsala/B160760CS_1.png 468 264 572 389\\n--Dataset/CSE20/processed/B160320ME_Shebin/B160320ME_1.png 330 315 631 688\\n--Dataset/CSE20/processed/B160320ME_Shebin/B160320ME_3.png 191 285 646 892\\n--Dataset/CSE20/processed/B160320ME_Shebin/B160320ME_2.png 440 427 806 846\\n--Dataset/CSE20/processed/B160688CS_Vishnu/B160688CS_3.png 725 1044 1618 2214\\n--Dataset/CSE20/processed/B160688CS_Vishnu/B160688CS_2.png 973 426 1711 1363\\n--Dataset/CSE20/processed/B160688CS_Vishnu/B160688CS_1.png 544 396 1107 1123\\n--Dataset/CSE20/processed/B160116CS_Aparna/B160116CS_3.png 152 200 367 450\\n--Dataset/CSE20/processed/B160116CS_Aparna/B160116CS_2.png 229 63 386 249\\n--Dataset/CSE20/processed/B160116CS_Aparna/B160116CS_1.png 284 560 332 614\\n--Dataset/CSE20/processed/B160229CS_Reema/B160229CS_3.png 313 266 494 511\\n--Dataset/CSE20/processed/B160229CS_Reema/B160229CS_2.png 144 216 315 427\\n--Dataset/CSE20/processed/B160229CS_Reema/B160229CS_1.png 234 384 322 495\\n--Dataset/CSE20/processed/B160118CS_Neeraja/B160118CS_1.png 130 170 396 484\\n--Dataset/CSE20/processed/B160118CS_Neeraja/B160118CS_3.png 429 535 561 696\\n--Dataset/CSE20/processed/B160118CS_Neeraja/B160118CS_2.png 262 59 490 329\\n--Dataset/CSE20/processed/B160213CS_Nileena/B160213CS_1.png 137 160 397 472\\n--Dataset/CSE20/processed/B160213CS_Nileena/B160213CS_2.png 265 271 455 492\\n--Dataset/CSE20/processed/B160213CS_Nileena/B160213CS_3.png 89 336 272 568\\n--Dataset/CSE20/processed/B160873CS_Naina/B160873CS_1.png 133 145 299 358\\n--Dataset/CSE20/processed/B160873CS_Naina/B160873CS_2.png 451 407 544 518\\n--Dataset/CSE20/processed/B160873CS_Naina/B160873CS_3.png 81 58 278 310\\n--Dataset/CSE20/processed/B160228CS_Vrindha/B160226CS_2.png 69 259 255 491\\n--Dataset/CSE20/processed/B160228CS_Vrindha/B160226CS_1.png 516 60 868 528\\n--Dataset/CSE20/processed/B160228CS_Vrindha/B160226CS_3.png 297 232 727 812\\n--Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_4.png 221 361 404 600\\n--Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_1.png 277 240 512 537\\n--Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_3.png 532 299 622 407\\n--Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_2.png 195 53 286 160\\n--Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_5.png 169 348 584 922\\n--Dataset/CSE20/processed/B160445CS_Sumalatha/B160445CS_1.png 219 73 363 261\\n--Dataset/CSE20/processed/B160445CS_Sumalatha/B160445CS_2.png 406 272 546 443\\n--Dataset/CSE20/processed/B160445CS_Sumalatha/B160445CS_3.png 433 616 484 674\\n-diff --git a/main/Dataset/CSE20/processed/bounding_boxes_19737.txt b/main/Dataset/CSE20/processed/bounding_boxes_19737.txt\\n-deleted file mode 100644\\n-index e69de29..0000000\\n-diff --git a/main/Dataset/CSE20/processed/bounding_boxes_20330.txt b/main/Dataset/CSE20/processed/bounding_boxes_20330.txt\\n-deleted file mode 100644\\n-index e69de29..0000000\\n-diff --git a/main/Dataset/CSE20/processed/bounding_boxes_28104.txt b/main/Dataset/CSE20/processed/bounding_boxes_28104.txt\\n-deleted file mode 100644\\n-index dc58fca..0000000\\n---- a/main/Dataset/CSE20/processed/bounding_boxes_28104.txt\\n-+++ /dev/null\\n-@@ -1,3 +0,0 @@\\n--Dataset/CSE20/processed/Naina/naina2.png 451 407 544 518\\n--Dataset/CSE20/processed/Naina/naina3.png 81 58 278 310\\n--Dataset/CSE20/processed/Naina/naina1.png 133 145 299 358\\n-diff --git a/main/Dataset/CSE20/processed/bounding_boxes_30925.txt b/main/Dataset/CSE20/processed/bounding_boxes_30925.txt\\n-deleted file mode 100644\\n-index e69de29..0000000\\n-diff --git a/main/Dataset/CSE20/processed/bounding_boxes_38733.txt b/main/Dataset/CSE20/processed/bounding_boxes_38733.txt\\n-deleted file mode 100644\\n-index e69de29..0000000\\n-diff --git a/main/Dataset/CSE20/processed/bounding_boxes_40979.txt b/main/Dataset/CSE20/processed/bounding_boxes_40979.txt\\n-deleted file mode 100644\\n-index e69de29..0000000\\n-diff --git a/main/Dataset/CSE20/processed/bounding_boxes_50376.txt b/main/Dataset/CSE20/processed/bounding_boxes_50376.txt\\n-deleted file mode 100644\\n-index 746e69e..0000000\\n---- a/main/Dataset/CSE20/processed/bounding_boxes_50376.txt\\n-+++ /dev/null\\n-@@ -1,3 +0,0 @@\\n--Dataset/CSE20/processed/Poothery/Poothery1.png 544 396 1107 1123\\n--Dataset/CSE20/processed/Poothery/Poothery2.png 973 426 1711 1363\\n--Dataset/CSE20/processed/Poothery/Poothery3.png 725 1044 1618 2214\\n-diff --git a/main/Dataset/CSE20/processed/bounding_boxes_51760.txt b/main/Dataset/CSE20/processed/bounding_boxes_51760.txt\\n-deleted file mode 100644\\n-index e69de29..0000000\\n-diff --git a/main/Dataset/CSE20/processed/bounding_boxes_78500.txt b/main/Dataset/CSE20/processed/bounding_boxes_78500.txt\\n-deleted file mode 100644\\n-index e69de29..0000000\\n-diff --git a/main/Dataset/CSE20/processed/bounding_boxes_80845.txt b/main/Dataset/CSE20/processed/bounding_boxes_80845.txt\\n-deleted file mode 100644\\n-index e69de29..0000000\\n-diff --git a/main/Dataset/CSE20/processed/bounding_boxes_95936.txt b/main/Dataset/CSE20/processed/bounding_boxes_95936.txt\\n-deleted file mode 100644\\n-index 5c0564d..0000000\\n---- a/main/Dataset/CSE20/processed/bounding_boxes_95936.txt\\n-+++ /dev/null\\n-@@ -1,4 +0,0 @@\\n--Dataset/CSE20/processed/B160471CS_Dheeraj/B160471CS_1.png 227 268 413 483\\n--Dataset/CSE20/processed/B160408CS_Ameen/B160408CS_3.png 241 337 448 614\\n--Dataset/CSE20/processed/B160408CS_Ameen/B160408CS_1.png 259 306 442 541\\n--Dataset/CSE20/processed/B160408CS_Ameen/B160408CS_2.png 312 148 530 417\\n-diff --git a/main/Dataset/CSE20/processed/revision_info.txt b/main/Dataset/CSE20/processed/revision_info.txt\\n-deleted file mode 100644\\n-index 3eaf7fb..0000000\\n---- a/main/Dataset/CSE20/processed/revision_info.txt\\n-+++ /dev/null\\n-@@ -1,7 +0,0 @@\\n--arguments: src/align_dataset_mtcnn.py ./Dataset/CSE20/raw/ ./Dataset/CSE20/processed/ --image_size 160 --margin 32 --random_order --gpu_memory_fraction 0.25\\n----------------------\\n--tensorflow version: 1.7.0\\n----------------------\\n--git hash: b\\\'096ed770f163957c1e56efa7feeb194773920f6e\\\'\\n----------------------\\n--b\\\'diff --git a/ /revision_info.txt b/ /revision_info.txt\\\\nnew file mode 100644\\\\nindex 0000000..979e188\\\\n--- /dev/null\\\\n+++ b/ /revision_info.txt\\\\t\\\\n@@ -0,0 +1,8 @@\\\\n+arguments: src/align/align_dataset_mtcnn.py ./Dataset/CSE20/raw \\\\\\\\\\\\n+./Dataset/CSE20/processed --image_size 160 --margin 32 --random_order  \\\\n+--------------------\\\\n+tensorflow version: 1.7.0\\\\n+--------------------\\\\n+git hash: b\\\\\\\'096ed770f163957c1e56efa7feeb194773920f6e\\\\\\\'\\\\n+--------------------\\\\n+b\\\\\\\'diff --git a/src/align/align_dataset_mtcnn.py b/src/align/align_dataset_mtcnn.py\\\\\\\\nindex 7d5e735..21f1457 100644\\\\\\\\n--- a/src/align/align_dataset_mtcnn.py\\\\\\\\n+++ b/src/align/align_dataset_mtcnn.py\\\\\\\\n@@ -31,8 +31,8 @@ import os\\\\\\\\n import argparse\\\\\\\\n import tensorflow as tf\\\\\\\\n import numpy as np\\\\\\\\n-import facenet\\\\\\\\n-import align.detect_face\\\\\\\\n+import facenet.src.facenet as facenet   #changed\\\\\\\\n+import detect_face  #changed\\\\\\\\n import random\\\\\\\\n from time import sleep\\\\\\\'\\\\n\\\\\\\\ No newline at end of file\\\\ndiff --git a/Dataset/CSE20/processed/B160116CS_Aparna/B160116CS_1.png b/Dataset/CSE20/processed/B160116CS_Aparna/B160116CS_1.png\\\\nnew file mode 100644\\\\nindex 0000000..f1db83f\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160116CS_Aparna/B160116CS_1.png differ\\\\ndiff --git a/Dataset/CSE20/processed/B160116CS_Aparna/B160116CS_2.png b/Dataset/CSE20/processed/B160116CS_Aparna/B160116CS_2.png\\\\nnew file mode 100644\\\\nindex 0000000..45449c3\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160116CS_Aparna/B160116CS_2.png differ\\\\ndiff --git a/Dataset/CSE20/processed/B160116CS_Aparna/B160116CS_3.png b/Dataset/CSE20/processed/B160116CS_Aparna/B160116CS_3.png\\\\nnew file mode 100644\\\\nindex 0000000..9813f9f\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160116CS_Aparna/B160116CS_3.png differ\\\\ndiff --git a/Dataset/CSE20/processed/B160118CS_Neeraja/B160118CS_1.png b/Dataset/CSE20/processed/B160118CS_Neeraja/B160118CS_1.png\\\\nnew file mode 100644\\\\nindex 0000000..fb52346\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160118CS_Neeraja/B160118CS_1.png differ\\\\ndiff --git a/Dataset/CSE20/processed/B160118CS_Neeraja/B160118CS_2.png b/Dataset/CSE20/processed/B160118CS_Neeraja/B160118CS_2.png\\\\nnew file mode 100644\\\\nindex 0000000..3a04b13\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160118CS_Neeraja/B160118CS_2.png differ\\\\ndiff --git a/Dataset/CSE20/processed/B160118CS_Neeraja/B160118CS_3.png b/Dataset/CSE20/processed/B160118CS_Neeraja/B160118CS_3.png\\\\nnew file mode 100644\\\\nindex 0000000..f7c2d61\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160118CS_Neeraja/B160118CS_3.png differ\\\\ndiff --git a/Dataset/CSE20/processed/B160213CS_Nileena/B160213CS_1.png b/Dataset/CSE20/processed/B160213CS_Nileena/B160213CS_1.png\\\\nnew file mode 100644\\\\nindex 0000000..5affd0e\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160213CS_Nileena/B160213CS_1.png differ\\\\ndiff --git a/Dataset/CSE20/processed/B160213CS_Nileena/B160213CS_2.png b/Dataset/CSE20/processed/B160213CS_Nileena/B160213CS_2.png\\\\nnew file mode 100644\\\\nindex 0000000..6bf453c\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160213CS_Nileena/B160213CS_2.png differ\\\\ndiff --git a/Dataset/CSE20/processed/B160213CS_Nileena/B160213CS_3.png b/Dataset/CSE20/processed/B160213CS_Nileena/B160213CS_3.png\\\\nnew file mode 100644\\\\nindex 0000000..c40a062\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160213CS_Nileena/B160213CS_3.png differ\\\\ndiff --git a/Dataset/CSE20/processed/B160228CS_Vrindha/B160226CS_1.png b/Dataset/CSE20/processed/B160228CS_Vrindha/B160226CS_1.png\\\\nnew file mode 100644\\\\nindex 0000000..598febb\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160228CS_Vrindha/B160226CS_1.png differ\\\\ndiff --git a/Dataset/CSE20/processed/B160228CS_Vrindha/B160226CS_2.png b/Dataset/CSE20/processed/B160228CS_Vrindha/B160226CS_2.png\\\\nnew file mode 100644\\\\nindex 0000000..90186c5\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160228CS_Vrindha/B160226CS_2.png differ\\\\ndiff --git a/Dataset/CSE20/processed/B160228CS_Vrindha/B160226CS_3.png b/Dataset/CSE20/processed/B160228CS_Vrindha/B160226CS_3.png\\\\nnew file mode 100644\\\\nindex 0000000..11e9bc8\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160228CS_Vrindha/B160226CS_3.png differ\\\\ndiff --git a/Dataset/CSE20/processed/B160229CS_Reema/B160229CS_1.png b/Dataset/CSE20/processed/B160229CS_Reema/B160229CS_1.png\\\\nnew file mode 100644\\\\nindex 0000000..078771e\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160229CS_Reema/B160229CS_1.png differ\\\\ndiff --git a/Dataset/CSE20/processed/B160229CS_Reema/B160229CS_2.png b/Dataset/CSE20/processed/B160229CS_Reema/B160229CS_2.png\\\\nnew file mode 100644\\\\nindex 0000000..b4aee42\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160229CS_Reema/B160229CS_2.png differ\\\\ndiff --git a/Dataset/CSE20/processed/B160229CS_Reema/B160229CS_3.png b/Dataset/CSE20/processed/B160229CS_Reema/B160229CS_3.png\\\\nnew file mode 100644\\\\nindex 0000000..406508e\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160229CS_Reema/B160229CS_3.png differ\\\\ndiff --git a/Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_1.png b/Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_1.png\\\\nnew file mode 100644\\\\nindex 0000000..cb05c38\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_1.png differ\\\\ndiff --git a/Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_2.png b/Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_2.png\\\\nnew file mode 100644\\\\nindex 0000000..ebef29c\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_2.png differ\\\\ndiff --git a/Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_3.png b/Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_3.png\\\\nnew file mode 100644\\\\nindex 0000000..5b409b0\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_3.png differ\\\\ndiff --git a/Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_4.png b/Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_4.png\\\\nnew file mode 100644\\\\nindex 0000000..63291a9\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_4.png differ\\\\ndiff --git a/Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_5.png b/Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_5.png\\\\nnew file mode 100644\\\\nindex 0000000..35bb01f\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_5.png differ\\\\ndiff --git a/Dataset/CSE20/processed/B160320ME_Shebin/B160320ME_1.png b/Dataset/CSE20/processed/B160320ME_Shebin/B160320ME_1.png\\\\nnew file mode 100644\\\\nindex 0000000..fa0c503\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160320ME_Shebin/B160320ME_1.png differ\\\\ndiff --git a/Dataset/CSE20/processed/B160320ME_Shebin/B160320ME_2.png b/Dataset/CSE20/processed/B160320ME_Shebin/B160320ME_2.png\\\\nnew file mode 100644\\\\nindex 0000000..79a0e5d\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160320ME_Shebin/B160320ME_2.png differ\\\\ndiff --git a/Dataset/CSE20/processed/B160320ME_Shebin/B160320ME_3.png b/Dataset/CSE20/processed/B160320ME_Shebin/B160320ME_3.png\\\\nnew file mode 100644\\\\nindex 0000000..c03da94\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160320ME_Shebin/B160320ME_3.png differ\\\\ndiff --git a/Dataset/CSE20/processed/B160408CS_Ameen/B160408CS_1.png b/Dataset/CSE20/processed/B160408CS_Ameen/B160408CS_1.png\\\\nnew file mode 100644\\\\nindex 0000000..16a46a2\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160408CS_Ameen/B160408CS_1.png differ\\\\ndiff --git a/Dataset/CSE20/processed/B160408CS_Ameen/B160408CS_2.png b/Dataset/CSE20/processed/B160408CS_Ameen/B160408CS_2.png\\\\nnew file mode 100644\\\\nindex 0000000..7d933ff\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160408CS_Ameen/B160408CS_2.png differ\\\\ndiff --git a/Dataset/CSE20/processed/B160408CS_Ameen/B160408CS_3.png b/Dataset/CSE20/processed/B160408CS_Ameen/B160408CS_3.png\\\\nnew file mode 100644\\\\nindex 0000000..ce20835\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160408CS_Ameen/B160408CS_3.png differ\\\\ndiff --git a/Dataset/CSE20/processed/B160445CS_Sumalatha/B160445CS_1.png b/Dataset/CSE20/processed/B160445CS_Sumalatha/B160445CS_1.png\\\\nnew file mode 100644\\\\nindex 0000000..fd9ed6f\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160445CS_Sumalatha/B160445CS_1.png differ\\\\ndiff --git a/Dataset/CSE20/processed/B160445CS_Sumalatha/B160445CS_2.png b/Dataset/CSE20/processed/B160445CS_Sumalatha/B160445CS_2.png\\\\nnew file mode 100644\\\\nindex 0000000..ad52a1d\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160445CS_Sumalatha/B160445CS_2.png differ\\\\ndiff --git a/Dataset/CSE20/processed/B160445CS_Sumalatha/B160445CS_3.png b/Dataset/CSE20/processed/B160445CS_Sumalatha/B160445CS_3.png\\\\nnew file mode 100644\\\\nindex 0000000..7fc6b80\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160445CS_Sumalatha/B160445CS_3.png differ\\\\ndiff --git a/Dataset/CSE20/processed/B160471CS_Dheeraj/B160471CS_1.png b/Dataset/CSE20/processed/B160471CS_Dheeraj/B160471CS_1.png\\\\nnew file mode 100644\\\\nindex 0000000..78a1983\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160471CS_Dheeraj/B160471CS_1.png differ\\\\ndiff --git a/Dataset/CSE20/processed/B160688CS_Vishnu/B160688CS_1.png b/Dataset/CSE20/processed/B160688CS_Vishnu/B160688CS_1.png\\\\nnew file mode 100644\\\\nindex 0000000..f43b308\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160688CS_Vishnu/B160688CS_1.png differ\\\\ndiff --git a/Dataset/CSE20/processed/B160688CS_Vishnu/B160688CS_2.png b/Dataset/CSE20/processed/B160688CS_Vishnu/B160688CS_2.png\\\\nnew file mode 100644\\\\nindex 0000000..5654243\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160688CS_Vishnu/B160688CS_2.png differ\\\\ndiff --git a/Dataset/CSE20/processed/B160688CS_Vishnu/B160688CS_3.png b/Dataset/CSE20/processed/B160688CS_Vishnu/B160688CS_3.png\\\\nnew file mode 100644\\\\nindex 0000000..4db5286\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160688CS_Vishnu/B160688CS_3.png differ\\\\ndiff --git a/Dataset/CSE20/processed/B160760CS_Vatsala/B160760CS_1.png b/Dataset/CSE20/processed/B160760CS_Vatsala/B160760CS_1.png\\\\nnew file mode 100644\\\\nindex 0000000..80f206e\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160760CS_Vatsala/B160760CS_1.png differ\\\\ndiff --git a/Dataset/CSE20/processed/B160760CS_Vatsala/B160760CS_2.png b/Dataset/CSE20/processed/B160760CS_Vatsala/B160760CS_2.png\\\\nnew file mode 100644\\\\nindex 0000000..fbdeadf\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160760CS_Vatsala/B160760CS_2.png differ\\\\ndiff --git a/Dataset/CSE20/processed/B160760CS_Vatsala/B160760CS_3.png b/Dataset/CSE20/processed/B160760CS_Vatsala/B160760CS_3.png\\\\nnew file mode 100644\\\\nindex 0000000..b7bb5e8\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160760CS_Vatsala/B160760CS_3.png differ\\\\ndiff --git a/Dataset/CSE20/processed/B160873CS_Naina/B160873CS_1.png b/Dataset/CSE20/processed/B160873CS_Naina/B160873CS_1.png\\\\nnew file mode 100644\\\\nindex 0000000..71d405b\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160873CS_Naina/B160873CS_1.png differ\\\\ndiff --git a/Dataset/CSE20/processed/B160873CS_Naina/B160873CS_2.png b/Dataset/CSE20/processed/B160873CS_Naina/B160873CS_2.png\\\\nnew file mode 100644\\\\nindex 0000000..2018b5c\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160873CS_Naina/B160873CS_2.png differ\\\\ndiff --git a/Dataset/CSE20/processed/B160873CS_Naina/B160873CS_3.png b/Dataset/CSE20/processed/B160873CS_Naina/B160873CS_3.png\\\\nnew file mode 100644\\\\nindex 0000000..6f1ae5c\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160873CS_Naina/B160873CS_3.png differ\\\\ndiff --git a/Dataset/CSE20/processed/Naina/naina1.png b/Dataset/CSE20/processed/Naina/naina1.png\\\\nnew file mode 100644\\\\nindex 0000000..71d405b\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/Naina/naina1.png differ\\\\ndiff --git a/Dataset/CSE20/processed/Naina/naina2.png b/Dataset/CSE20/processed/Naina/naina2.png\\\\nnew file mode 100644\\\\nindex 0000000..2018b5c\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/Naina/naina2.png differ\\\\ndiff --git a/Dataset/CSE20/processed/Naina/naina3.png b/Dataset/CSE20/processed/Naina/naina3.png\\\\nnew file mode 100644\\\\nindex 0000000..6f1ae5c\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/Naina/naina3.png differ\\\\ndiff --git a/Dataset/CSE20/processed/Poothery/Poothery1.png b/Dataset/CSE20/processed/Poothery/Poothery1.png\\\\nnew file mode 100644\\\\nindex 0000000..f43b308\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/Poothery/Poothery1.png differ\\\\ndiff --git a/Dataset/CSE20/processed/Poothery/Poothery2.png b/Dataset/CSE20/processed/Poothery/Poothery2.png\\\\nnew file mode 100644\\\\nindex 0000000..5654243\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/Poothery/Poothery2.png differ\\\\ndiff --git a/Dataset/CSE20/processed/Poothery/Poothery3.png b/Dataset/CSE20/processed/Poothery/Poothery3.png\\\\nnew file mode 100644\\\\nindex 0000000..4db5286\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/Poothery/Poothery3.png differ\\\\ndiff --git a/Dataset/CSE20/processed/bounding_boxes_09361.txt b/Dataset/CSE20/processed/bounding_boxes_09361.txt\\\\nnew file mode 100644\\\\nindex 0000000..da52b30\\\\n--- /dev/null\\\\n+++ b/Dataset/CSE20/processed/bounding_boxes_09361.txt\\\\n@@ -0,0 +1,35 @@\\\\n+Dataset/CSE20/processed/B160760CS_Vatsala/B160760CS_3.png 737 316 933 556\\\\n+Dataset/CSE20/processed/B160760CS_Vatsala/B160760CS_2.png 153 385 552 891\\\\n+Dataset/CSE20/processed/B160760CS_Vatsala/B160760CS_1.png 468 264 572 389\\\\n+Dataset/CSE20/processed/B160320ME_Shebin/B160320ME_1.png 330 315 631 688\\\\n+Dataset/CSE20/processed/B160320ME_Shebin/B160320ME_3.png 191 285 646 892\\\\n+Dataset/CSE20/processed/B160320ME_Shebin/B160320ME_2.png 440 427 806 846\\\\n+Dataset/CSE20/processed/B160688CS_Vishnu/B160688CS_3.png 725 1044 1618 2214\\\\n+Dataset/CSE20/processed/B160688CS_Vishnu/B160688CS_2.png 973 426 1711 1363\\\\n+Dataset/CSE20/processed/B160688CS_Vishnu/B160688CS_1.png 544 396 1107 1123\\\\n+Dataset/CSE20/processed/B160116CS_Aparna/B160116CS_3.png 152 200 367 450\\\\n+Dataset/CSE20/processed/B160116CS_Aparna/B160116CS_2.png 229 63 386 249\\\\n+Dataset/CSE20/processed/B160116CS_Aparna/B160116CS_1.png 284 560 332 614\\\\n+Dataset/CSE20/processed/B160229CS_Reema/B160229CS_3.png 313 266 494 511\\\\n+Dataset/CSE20/processed/B160229CS_Reema/B160229CS_2.png 144 216 315 427\\\\n+Dataset/CSE20/processed/B160229CS_Reema/B160229CS_1.png 234 384 322 495\\\\n+Dataset/CSE20/processed/B160118CS_Neeraja/B160118CS_1.png 130 170 396 484\\\\n+Dataset/CSE20/processed/B160118CS_Neeraja/B160118CS_3.png 429 535 561 696\\\\n+Dataset/CSE20/processed/B160118CS_Neeraja/B160118CS_2.png 262 59 490 329\\\\n+Dataset/CSE20/processed/B160213CS_Nileena/B160213CS_1.png 137 160 397 472\\\\n+Dataset/CSE20/processed/B160213CS_Nileena/B160213CS_2.png 265 271 455 492\\\\n+Dataset/CSE20/processed/B160213CS_Nileena/B160213CS_3.png 89 336 272 568\\\\n+Dataset/CSE20/processed/B160873CS_Naina/B160873CS_1.png 133 145 299 358\\\\n+Dataset/CSE20/processed/B160873CS_Naina/B160873CS_2.png 451 407 544 518\\\\n+Dataset/CSE20/processed/B160873CS_Naina/B160873CS_3.png 81 58 278 310\\\\n+Dataset/CSE20/processed/B160228CS_Vrindha/B160226CS_2.png 69 259 255 491\\\\n+Dataset/CSE20/processed/B160228CS_Vrindha/B160226CS_1.png 516 60 868 528\\\\n+Dataset/CSE20/processed/B160228CS_Vrindha/B160226CS_3.png 297 232 727 812\\\\n+Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_4.png 221 361 404 600\\\\n+Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_1.png 277 240 512 537\\\\n+Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_3.png 532 299 622 407\\\\n+Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_2.png 195 53 286 160\\\\n+Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_5.png 169 348 584 922\\\\n+Dataset/CSE20/processed/B160445CS_Sumalatha/B160445CS_1.png 219 73 363 261\\\\n+Dataset/CSE20/processed/B160445CS_Sumalatha/B160445CS_2.png 406 272 546 443\\\\n+Dataset/CSE20/processed/B160445CS_Sumalatha/B160445CS_3.png 433 616 484 674\\\\ndiff --git a/Dataset/CSE20/processed/bounding_boxes_19737.txt b/Dataset/CSE20/processed/bounding_boxes_19737.txt\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/Dataset/CSE20/processed/bounding_boxes_20330.txt b/Dataset/CSE20/processed/bounding_boxes_20330.txt\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/Dataset/CSE20/processed/bounding_boxes_28104.txt b/Dataset/CSE20/processed/bounding_boxes_28104.txt\\\\nnew file mode 100644\\\\nindex 0000000..dc58fca\\\\n--- /dev/null\\\\n+++ b/Dataset/CSE20/processed/bounding_boxes_28104.txt\\\\n@@ -0,0 +1,3 @@\\\\n+Dataset/CSE20/processed/Naina/naina2.png 451 407 544 518\\\\n+Dataset/CSE20/processed/Naina/naina3.png 81 58 278 310\\\\n+Dataset/CSE20/processed/Naina/naina1.png 133 145 299 358\\\\ndiff --git a/Dataset/CSE20/processed/bounding_boxes_30925.txt b/Dataset/CSE20/processed/bounding_boxes_30925.txt\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/Dataset/CSE20/processed/bounding_boxes_38733.txt b/Dataset/CSE20/processed/bounding_boxes_38733.txt\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/Dataset/CSE20/processed/bounding_boxes_40979.txt b/Dataset/CSE20/processed/bounding_boxes_40979.txt\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/Dataset/CSE20/processed/bounding_boxes_50376.txt b/Dataset/CSE20/processed/bounding_boxes_50376.txt\\\\nnew file mode 100644\\\\nindex 0000000..746e69e\\\\n--- /dev/null\\\\n+++ b/Dataset/CSE20/processed/bounding_boxes_50376.txt\\\\n@@ -0,0 +1,3 @@\\\\n+Dataset/CSE20/processed/Poothery/Poothery1.png 544 396 1107 1123\\\\n+Dataset/CSE20/processed/Poothery/Poothery2.png 973 426 1711 1363\\\\n+Dataset/CSE20/processed/Poothery/Poothery3.png 725 1044 1618 2214\\\\ndiff --git a/Dataset/CSE20/processed/bounding_boxes_51760.txt b/Dataset/CSE20/processed/bounding_boxes_51760.txt\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/Dataset/CSE20/processed/bounding_boxes_80845.txt b/Dataset/CSE20/processed/bounding_boxes_80845.txt\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/Dataset/CSE20/processed/bounding_boxes_95936.txt b/Dataset/CSE20/processed/bounding_boxes_95936.txt\\\\nnew file mode 100644\\\\nindex 0000000..5c0564d\\\\n--- /dev/null\\\\n+++ b/Dataset/CSE20/processed/bounding_boxes_95936.txt\\\\n@@ -0,0 +1,4 @@\\\\n+Dataset/CSE20/processed/B160471CS_Dheeraj/B160471CS_1.png 227 268 413 483\\\\n+Dataset/CSE20/processed/B160408CS_Ameen/B160408CS_3.png 241 337 448 614\\\\n+Dataset/CSE20/processed/B160408CS_Ameen/B160408CS_1.png 259 306 442 541\\\\n+Dataset/CSE20/processed/B160408CS_Ameen/B160408CS_2.png 312 148 530 417\\\\ndiff --git a/Dataset/CSE20/processed/revision_info.txt b/Dataset/CSE20/processed/revision_info.txt\\\\nnew file mode 100644\\\\nindex 0000000..5373839\\\\n--- /dev/null\\\\n+++ b/Dataset/CSE20/processed/revision_info.txt\\\\n@@ -0,0 +1,7 @@\\\\n+arguments: src/align_dataset_mtcnn.py Dataset/CSE20/raw/ Dataset/CSE20/processed/ --image_size 160 --margin 32 --random_order --gpu_memory_fraction 0.25\\\\n+--------------------\\\\n+tensorflow version: 1.7.0\\\\n+--------------------\\\\n+git hash: b\\\\\\\'096ed770f163957c1e56efa7feeb194773920f6e\\\\\\\'\\\\n+--------------------\\\\n+b\\\\\\\'diff --git a/src/align/align_dataset_mtcnn.py b/src/align/align_dataset_mtcnn.py\\\\\\\\nindex 7d5e735..21f1457 100644\\\\\\\\n--- a/src/align/align_dataset_mtcnn.py\\\\\\\\n+++ b/src/align/align_dataset_mtcnn.py\\\\\\\\n@@ -31,8 +31,8 @@ import os\\\\\\\\n import argparse\\\\\\\\n import tensorflow as tf\\\\\\\\n import numpy as np\\\\\\\\n-import facenet\\\\\\\\n-import align.detect_face\\\\\\\\n+import facenet.src.facenet as facenet   #changed\\\\\\\\n+import detect_face  #changed\\\\\\\\n import random\\\\\\\\n from time import sleep\\\\\\\\n \\\\\\\\ndiff --git a/src/align/detect_face.py b/src/align/detect_face.py\\\\\\\\nindex 7f98ca7..3806b33 100644\\\\\\\\n--- a/src/align/detect_face.py\\\\\\\\n+++ b/src/align/detect_face.py\\\\\\\\n@@ -82,7 +82,10 @@ class Network(object):\\\\\\\\n         session: The current TensorFlow session\\\\\\\\n         ignore_missing: If true, serialized weights for missing layers are ignored.\\\\\\\\n         """\\\\\\\\n+        np_load_old = np.load\\\\\\\\n+        np.load = lambda *a, **k: np_load_old(*a, allow_pickle=True, **k)\\\\\\\\n         data_dict = np.load(data_path, encoding=\\\\\\\\\\\\\\\'latin1\\\\\\\\\\\\\\\').item() #pylint: disable=no-member\\\\\\\\n+        np.load = np_load_old\\\\\\\\n \\\\\\\\n         for op_name in data_dict:\\\\\\\\n             with tf.variable_scope(op_name, reuse=True):\\\\\\\\ndiff --git a/src/facenet.py b/src/facenet.py\\\\\\\\nindex 0e05676..538b650 100644\\\\\\\\n--- a/src/facenet.py\\\\\\\\n+++ b/src/facenet.py\\\\\\\\n@@ -32,6 +32,7 @@ from subprocess import Popen, PIPE\\\\\\\\n import tensorflow as tf\\\\\\\\n import numpy as np\\\\\\\\n from scipy import misc\\\\\\\\n+import imageio\\\\\\\\n from sklearn.model_selection import KFold\\\\\\\\n from scipy import interpolate\\\\\\\\n from tensorflow.python.training import training\\\\\\\\n@@ -244,7 +245,7 @@ def load_data(image_paths, do_random_crop, do_random_flip, image_size, do_prewhi\\\\\\\\n     nrof_samples = len(image_paths)\\\\\\\\n     images = np.zeros((nrof_samples, image_size, image_size, 3))\\\\\\\\n     for i in range(nrof_samples):\\\\\\\\n-        img = misc.imread(image_paths[i])\\\\\\\\n+        img = imageio.imread(image_paths[i])\\\\\\\\n         if img.ndim == 2:\\\\\\\\n             img = to_rgb(img)\\\\\\\\n         if do_prewhiten:\\\\\\\'\\\\n\\\\\\\\ No newline at end of file\\\\ndiff --git a/Dataset/CSE20/raw/B160116CS_Aparna/B160116CS_1.jpeg b/Dataset/CSE20/raw/B160116CS_Aparna/B160116CS_1.jpeg\\\\nnew file mode 100644\\\\nindex 0000000..e23a8fc\\\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160116CS_Aparna/B160116CS_1.jpeg differ\\\\ndiff --git a/Dataset/CSE20/raw/B160116CS_Aparna/B160116CS_2.jpeg b/Dataset/CSE20/raw/B160116CS_Aparna/B160116CS_2.jpeg\\\\nnew file mode 100644\\\\nindex 0000000..f91beaf\\\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160116CS_Aparna/B160116CS_2.jpeg differ\\\\ndiff --git a/Dataset/CSE20/raw/B160116CS_Aparna/B160116CS_3.jpeg b/Dataset/CSE20/raw/B160116CS_Aparna/B160116CS_3.jpeg\\\\nnew file mode 100644\\\\nindex 0000000..c0bab07\\\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160116CS_Aparna/B160116CS_3.jpeg differ\\\\ndiff --git a/Dataset/CSE20/raw/B160118CS_Neeraja/B160118CS_1.jpeg b/Dataset/CSE20/raw/B160118CS_Neeraja/B160118CS_1.jpeg\\\\nnew file mode 100644\\\\nindex 0000000..d7870a6\\\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160118CS_Neeraja/B160118CS_1.jpeg differ\\\\ndiff --git a/Dataset/CSE20/raw/B160118CS_Neeraja/B160118CS_2.jpeg b/Dataset/CSE20/raw/B160118CS_Neeraja/B160118CS_2.jpeg\\\\nnew file mode 100644\\\\nindex 0000000..0af9819\\\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160118CS_Neeraja/B160118CS_2.jpeg differ\\\\ndiff --git a/Dataset/CSE20/raw/B160118CS_Neeraja/B160118CS_3.jpeg b/Dataset/CSE20/raw/B160118CS_Neeraja/B160118CS_3.jpeg\\\\nnew file mode 100644\\\\nindex 0000000..1fa8fb3\\\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160118CS_Neeraja/B160118CS_3.jpeg differ\\\\ndiff --git a/Dataset/CSE20/raw/B160213CS_Nileena/B160213CS_1.jpeg b/Dataset/CSE20/raw/B160213CS_Nileena/B160213CS_1.jpeg\\\\nnew file mode 100644\\\\nindex 0000000..0571099\\\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160213CS_Nileena/B160213CS_1.jpeg differ\\\\ndiff --git a/Dataset/CSE20/raw/B160213CS_Nileena/B160213CS_2.jpeg b/Dataset/CSE20/raw/B160213CS_Nileena/B160213CS_2.jpeg\\\\nnew file mode 100644\\\\nindex 0000000..b834bd2\\\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160213CS_Nileena/B160213CS_2.jpeg differ\\\\ndiff --git a/Dataset/CSE20/raw/B160213CS_Nileena/B160213CS_3.jpeg b/Dataset/CSE20/raw/B160213CS_Nileena/B160213CS_3.jpeg\\\\nnew file mode 100644\\\\nindex 0000000..6f90c78\\\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160213CS_Nileena/B160213CS_3.jpeg differ\\\\ndiff --git a/Dataset/CSE20/raw/B160228CS_Vrindha/B160226CS_1.jpeg b/Dataset/CSE20/raw/B160228CS_Vrindha/B160226CS_1.jpeg\\\\nnew file mode 100644\\\\nindex 0000000..cc17e86\\\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160228CS_Vrindha/B160226CS_1.jpeg differ\\\\ndiff --git a/Dataset/CSE20/raw/B160228CS_Vrindha/B160226CS_2.jpeg b/Dataset/CSE20/raw/B160228CS_Vrindha/B160226CS_2.jpeg\\\\nnew file mode 100644\\\\nindex 0000000..f05098d\\\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160228CS_Vrindha/B160226CS_2.jpeg differ\\\\ndiff --git a/Dataset/CSE20/raw/B160228CS_Vrindha/B160226CS_3.jpeg b/Dataset/CSE20/raw/B160228CS_Vrindha/B160226CS_3.jpeg\\\\nnew file mode 100644\\\\nindex 0000000..bd97e68\\\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160228CS_Vrindha/B160226CS_3.jpeg differ\\\\ndiff --git a/Dataset/CSE20/raw/B160229CS_Reema/B160229CS_1.jpeg b/Dataset/CSE20/raw/B160229CS_Reema/B160229CS_1.jpeg\\\\nnew file mode 100644\\\\nindex 0000000..03232a8\\\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160229CS_Reema/B160229CS_1.jpeg differ\\\\ndiff --git a/Dataset/CSE20/raw/B160229CS_Reema/B160229CS_2.jpeg b/Dataset/CSE20/raw/B160229CS_Reema/B160229CS_2.jpeg\\\\nnew file mode 100644\\\\nindex 0000000..f2f9a82\\\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160229CS_Reema/B160229CS_2.jpeg differ\\\\ndiff --git a/Dataset/CSE20/raw/B160229CS_Reema/B160229CS_3.jpeg b/Dataset/CSE20/raw/B160229CS_Reema/B160229CS_3.jpeg\\\\nnew file mode 100644\\\\nindex 0000000..caced02\\\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160229CS_Reema/B160229CS_3.jpeg differ\\\\ndiff --git a/Dataset/CSE20/raw/B160270CS_Lakshmi/B160270CS_1.jpeg b/Dataset/CSE20/raw/B160270CS_Lakshmi/B160270CS_1.jpeg\\\\nnew file mode 100644\\\\nindex 0000000..b6d3dea\\\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160270CS_Lakshmi/B160270CS_1.jpeg differ\\\\ndiff --git a/Dataset/CSE20/raw/B160270CS_Lakshmi/B160270CS_2.jpeg b/Dataset/CSE20/raw/B160270CS_Lakshmi/B160270CS_2.jpeg\\\\nnew file mode 100644\\\\nindex 0000000..26ac294\\\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160270CS_Lakshmi/B160270CS_2.jpeg differ\\\\ndiff --git a/Dataset/CSE20/raw/B160270CS_Lakshmi/B160270CS_3.jpeg b/Dataset/CSE20/raw/B160270CS_Lakshmi/B160270CS_3.jpeg\\\\nnew file mode 100644\\\\nindex 0000000..670eb75\\\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160270CS_Lakshmi/B160270CS_3.jpeg differ\\\\ndiff --git a/Dataset/CSE20/raw/B160270CS_Lakshmi/B160270CS_4.jpeg b/Dataset/CSE20/raw/B160270CS_Lakshmi/B160270CS_4.jpeg\\\\nnew file mode 100644\\\\nindex 0000000..5fab205\\\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160270CS_Lakshmi/B160270CS_4.jpeg differ\\\\ndiff --git a/Dataset/CSE20/raw/B160270CS_Lakshmi/B160270CS_5.jpeg b/Dataset/CSE20/raw/B160270CS_Lakshmi/B160270CS_5.jpeg\\\\nnew file mode 100644\\\\nindex 0000000..32abaf3\\\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160270CS_Lakshmi/B160270CS_5.jpeg differ\\\\ndiff --git a/Dataset/CSE20/raw/B160320ME_Shebin/B160320ME_1.jpeg b/Dataset/CSE20/raw/B160320ME_Shebin/B160320ME_1.jpeg\\\\nnew file mode 100644\\\\nindex 0000000..2fd54a5\\\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160320ME_Shebin/B160320ME_1.jpeg differ\\\\ndiff --git a/Dataset/CSE20/raw/B160320ME_Shebin/B160320ME_2.jpeg b/Dataset/CSE20/raw/B160320ME_Shebin/B160320ME_2.jpeg\\\\nnew file mode 100644\\\\nindex 0000000..1e896db\\\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160320ME_Shebin/B160320ME_2.jpeg differ\\\\ndiff --git a/Dataset/CSE20/raw/B160320ME_Shebin/B160320ME_3.jpeg b/Dataset/CSE20/raw/B160320ME_Shebin/B160320ME_3.jpeg\\\\nnew file mode 100644\\\\nindex 0000000..2587d2d\\\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160320ME_Shebin/B160320ME_3.jpeg differ\\\\ndiff --git a/Dataset/CSE20/raw/B160408CS_Ameen/B160408CS_1.jpeg b/Dataset/CSE20/raw/B160408CS_Ameen/B160408CS_1.jpeg\\\\nnew file mode 100644\\\\nindex 0000000..1fa10aa\\\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160408CS_Ameen/B160408CS_1.jpeg differ\\\\ndiff --git a/Dataset/CSE20/raw/B160408CS_Ameen/B160408CS_2.jpeg b/Dataset/CSE20/raw/B160408CS_Ameen/B160408CS_2.jpeg\\\\nnew file mode 100644\\\\nindex 0000000..96b4941\\\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160408CS_Ameen/B160408CS_2.jpeg differ\\\\ndiff --git a/Dataset/CSE20/raw/B160408CS_Ameen/B160408CS_3.jpeg b/Dataset/CSE20/raw/B160408CS_Ameen/B160408CS_3.jpeg\\\\nnew file mode 100644\\\\nindex 0000000..f275bc4\\\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160408CS_Ameen/B160408CS_3.jpeg differ\\\\ndiff --git a/Dataset/CSE20/raw/B160445CS_Sumalatha/B160445CS_1.jpeg b/Dataset/CSE20/raw/B160445CS_Sumalatha/B160445CS_1.jpeg\\\\nnew file mode 100644\\\\nindex 0000000..c317aa8\\\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160445CS_Sumalatha/B160445CS_1.jpeg differ\\\\ndiff --git a/Dataset/CSE20/raw/B160445CS_Sumalatha/B160445CS_2.jpeg b/Dataset/CSE20/raw/B160445CS_Sumalatha/B160445CS_2.jpeg\\\\nnew file mode 100644\\\\nindex 0000000..5ab2818\\\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160445CS_Sumalatha/B160445CS_2.jpeg differ\\\\ndiff --git a/Dataset/CSE20/raw/B160445CS_Sumalatha/B160445CS_3.jpeg b/Dataset/CSE20/raw/B160445CS_Sumalatha/B160445CS_3.jpeg\\\\nnew file mode 100644\\\\nindex 0000000..0159b52\\\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160445CS_Sumalatha/B160445CS_3.jpeg differ\\\\ndiff --git a/Dataset/CSE20/raw/B160471CS_Dheeraj/B160471CS_1.jpeg b/Dataset/CSE20/raw/B160471CS_Dheeraj/B160471CS_1.jpeg\\\\nnew file mode 100644\\\\nindex 0000000..9d6bec9\\\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160471CS_Dheeraj/B160471CS_1.jpeg differ\\\\ndiff --git a/Dataset/CSE20/raw/B160688CS_Vishnu/B160688CS_1.jpg b/Dataset/CSE20/raw/B160688CS_Vishnu/B160688CS_1.jpg\\\\nnew file mode 100644\\\\nindex 0000000..537a4c0\\\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160688CS_Vishnu/B160688CS_1.jpg differ\\\\ndiff --git a/Dataset/CSE20/raw/B160688CS_Vishnu/B160688CS_2.jpg b/Dataset/CSE20/raw/B160688CS_Vishnu/B160688CS_2.jpg\\\\nnew file mode 100644\\\\nindex 0000000..0442b3d\\\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160688CS_Vishnu/B160688CS_2.jpg differ\\\\ndiff --git a/Dataset/CSE20/raw/B160688CS_Vishnu/B160688CS_3.jpeg b/Dataset/CSE20/raw/B160688CS_Vishnu/B160688CS_3.jpeg\\\\nnew file mode 100644\\\\nindex 0000000..460d134\\\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160688CS_Vishnu/B160688CS_3.jpeg differ\\\\ndiff --git a/Dataset/CSE20/raw/B160760CS_Vatsala/B160760CS_1.jpeg b/Dataset/CSE20/raw/B160760CS_Vatsala/B160760CS_1.jpeg\\\\nnew file mode 100644\\\\nindex 0000000..2856b8e\\\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160760CS_Vatsala/B160760CS_1.jpeg differ\\\\ndiff --git a/Dataset/CSE20/raw/B160760CS_Vatsala/B160760CS_2.jpeg b/Dataset/CSE20/raw/B160760CS_Vatsala/B160760CS_2.jpeg\\\\nnew file mode 100644\\\\nindex 0000000..76e5ceb\\\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160760CS_Vatsala/B160760CS_2.jpeg differ\\\\ndiff --git a/Dataset/CSE20/raw/B160760CS_Vatsala/B160760CS_3.jpeg b/Dataset/CSE20/raw/B160760CS_Vatsala/B160760CS_3.jpeg\\\\nnew file mode 100644\\\\nindex 0000000..f43a8a7\\\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160760CS_Vatsala/B160760CS_3.jpeg differ\\\\ndiff --git a/Dataset/CSE20/raw/B160873CS_Naina/B160873CS_1.jpg b/Dataset/CSE20/raw/B160873CS_Naina/B160873CS_1.jpg\\\\nnew file mode 100644\\\\nindex 0000000..0c66c88\\\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160873CS_Naina/B160873CS_1.jpg differ\\\\ndiff --git a/Dataset/CSE20/raw/B160873CS_Naina/B160873CS_2.jpg b/Dataset/CSE20/raw/B160873CS_Naina/B160873CS_2.jpg\\\\nnew file mode 100644\\\\nindex 0000000..ad8c724\\\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160873CS_Naina/B160873CS_2.jpg differ\\\\ndiff --git a/Dataset/CSE20/raw/B160873CS_Naina/B160873CS_3.png b/Dataset/CSE20/raw/B160873CS_Naina/B160873CS_3.png\\\\nnew file mode 100644\\\\nindex 0000000..361493f\\\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160873CS_Naina/B160873CS_3.png differ\\\\ndiff --git a/Models/CSE20/CSE20.pkl b/Models/CSE20/CSE20.pkl\\\\nnew file mode 100644\\\\nindex 0000000..3793ef7\\\\nBinary files /dev/null and b/Models/CSE20/CSE20.pkl differ\\\\ndiff --git a/Models/facenet/20180402-114759.pb b/Models/facenet/20180402-114759.pb\\\\nnew file mode 100644\\\\nindex 0000000..39b4ed7\\\\nBinary files /dev/null and b/Models/facenet/20180402-114759.pb differ\\\\ndiff --git a/Models/facenet/model-20180402-114759.ckpt-275.data-00000-of-00001 b/Models/facenet/model-20180402-114759.ckpt-275.data-00000-of-00001\\\\nnew file mode 100755\\\\nindex 0000000..6160198\\\\nBinary files /dev/null and b/Models/facenet/model-20180402-114759.ckpt-275.data-00000-of-00001 differ\\\\ndiff --git a/Models/facenet/model-20180402-114759.ckpt-275.index b/Models/facenet/model-20180402-114759.ckpt-275.index\\\\nnew file mode 100755\\\\nindex 0000000..e2b346c\\\\nBinary files /dev/null and b/Models/facenet/model-20180402-114759.ckpt-275.index differ\\\\ndiff --git a/Models/facenet/model-20180402-114759.meta b/Models/facenet/model-20180402-114759.meta\\\\nnew file mode 100755\\\\nindex 0000000..abffaef\\\\nBinary files /dev/null and b/Models/facenet/model-20180402-114759.meta differ\\\\ndiff --git a/src/align/align_dataset_mtcnn.py b/src/align/align_dataset_mtcnn.py\\\\nindex 7d5e735..21f1457 100644\\\\n--- a/src/align/align_dataset_mtcnn.py\\\\n+++ b/src/align/align_dataset_mtcnn.py\\\\n@@ -31,8 +31,8 @@ import os\\\\n import argparse\\\\n import tensorflow as tf\\\\n import numpy as np\\\\n-import facenet\\\\n-import align.detect_face\\\\n+import facenet.src.facenet as facenet   #changed\\\\n+import detect_face  #changed\\\\n import random\\\\n from time import sleep\\\\n \\\\ndiff --git a/src/align/detect_face.py b/src/align/detect_face.py\\\\nindex 7f98ca7..3806b33 100644\\\\n--- a/src/align/detect_face.py\\\\n+++ b/src/align/detect_face.py\\\\n@@ -82,7 +82,10 @@ class Network(object):\\\\n         session: The current TensorFlow session\\\\n         ignore_missing: If true, serialized weights for missing layers are ignored.\\\\n         """\\\\n+        np_load_old = np.load\\\\n+        np.load = lambda *a, **k: np_load_old(*a, allow_pickle=True, **k)\\\\n         data_dict = np.load(data_path, encoding=\\\\\\\'latin1\\\\\\\').item() #pylint: disable=no-member\\\\n+        np.load = np_load_old\\\\n \\\\n         for op_name in data_dict:\\\\n             with tf.variable_scope(op_name, reuse=True):\\\\ndiff --git a/src/align_dataset_mtcnn.py b/src/align_dataset_mtcnn.py\\\\nnew file mode 100644\\\\nindex 0000000..2c2acc4\\\\n--- /dev/null\\\\n+++ b/src/align_dataset_mtcnn.py\\\\n@@ -0,0 +1,161 @@\\\\n+"""Performs face alignment and stores face thumbnails in the output directory."""\\\\n+# MIT License\\\\n+# \\\\n+# Copyright (c) 2016 David Sandberg\\\\n+# \\\\n+# Permission is hereby granted, free of charge, to any person obtaining a copy\\\\n+# of this software and associated documentation files (the "Software"), to deal\\\\n+# in the Software without restriction, including without limitation the rights\\\\n+# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\\\n+# copies of the Software, and to permit persons to whom the Software is\\\\n+# furnished to do so, subject to the following conditions:\\\\n+# \\\\n+# The above copyright notice and this permission notice shall be included in all\\\\n+# copies or substantial portions of the Software.\\\\n+# \\\\n+# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\\\n+# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\\\n+# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\\\n+# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\\\n+# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\\\n+# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\\\n+# SOFTWARE.\\\\n+\\\\n+from __future__ import absolute_import\\\\n+from __future__ import division\\\\n+from __future__ import print_function\\\\n+\\\\n+from scipy import misc\\\\n+import imageio #for imread since it\\\\\\\'s depricated in scipy.misc\\\\n+import skimage #for imresize since it\\\\\\\'s depricated in scipy.misc\\\\n+import sys\\\\n+import os\\\\n+import argparse\\\\n+import tensorflow as tf\\\\n+import numpy as np\\\\n+import facenet\\\\n+import align.detect_face\\\\n+import random\\\\n+from time import sleep\\\\n+\\\\n+def main(args):\\\\n+    sleep(random.random())\\\\n+    output_dir = os.path.expanduser(args.output_dir)\\\\n+    if not os.path.exists(output_dir):\\\\n+        os.makedirs(output_dir)\\\\n+    # Store some git revision info in a text file in the log directory\\\\n+    src_path,_ = os.path.split(os.path.realpath(__file__))\\\\n+    facenet.store_revision_info(src_path, output_dir, \\\\\\\' \\\\\\\'.join(sys.argv))\\\\n+    dataset = facenet.get_dataset(args.input_dir)\\\\n+    \\\\n+    print(\\\\\\\'Creating networks and loading parameters\\\\\\\')\\\\n+    \\\\n+    with tf.Graph().as_default():\\\\n+        gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=args.gpu_memory_fraction)\\\\n+        sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options, log_device_placement=False))\\\\n+        with sess.as_default():\\\\n+            pnet, rnet, onet = align.detect_face.create_mtcnn(sess, None)\\\\n+    \\\\n+    minsize = 20 # minimum size of face\\\\n+    threshold = [ 0.6, 0.7, 0.7 ]  # three steps\\\\\\\'s threshold\\\\n+    factor = 0.709 # scale factor\\\\n+\\\\n+    # Add a random key to the filename to allow alignment using multiple processes\\\\n+    random_key = np.random.randint(0, high=99999)\\\\n+    bounding_boxes_filename = os.path.join(output_dir, \\\\\\\'bounding_boxes_%05d.txt\\\\\\\' % random_key)\\\\n+    \\\\n+    with open(bounding_boxes_filename, "w") as text_file:\\\\n+        nrof_images_total = 0\\\\n+        nrof_successfully_aligned = 0\\\\n+        if args.random_order:\\\\n+            random.shuffle(dataset)\\\\n+        for cls in dataset:\\\\n+            output_class_dir = os.path.join(output_dir, cls.name)\\\\n+            if not os.path.exists(output_class_dir):\\\\n+                os.makedirs(output_class_dir)\\\\n+                if args.random_order:\\\\n+                    random.shuffle(cls.image_paths)\\\\n+            for image_path in cls.image_paths:\\\\n+                nrof_images_total += 1\\\\n+                filename = os.path.splitext(os.path.split(image_path)[1])[0]\\\\n+                output_filename = os.path.join(output_class_dir, filename+\\\\\\\'.png\\\\\\\')\\\\n+                print(image_path)\\\\n+                if not os.path.exists(output_filename):\\\\n+                    try:\\\\n+                        img = imageio.imread(image_path)\\\\n+                    except (IOError, ValueError, IndexError) as e:\\\\n+                        errorMessage = \\\\\\\'{}: {}\\\\\\\'.format(image_path, e)\\\\n+                        print(errorMessage)\\\\n+                    else:\\\\n+                        if img.ndim<2:\\\\n+                            print(\\\\\\\'Unable to align "%s"\\\\\\\' % image_path)\\\\n+                            text_file.write(\\\\\\\'%s\\\\\\\\n\\\\\\\' % (output_filename))\\\\n+                            continue\\\\n+                        if img.ndim == 2:\\\\n+                            img = facenet.to_rgb(img)\\\\n+                        img = img[:,:,0:3]\\\\n+    \\\\n+                        bounding_boxes, _ = align.detect_face.detect_face(img, minsize, pnet, rnet, onet, threshold, factor)\\\\n+                        nrof_faces = bounding_boxes.shape[0]\\\\n+                        if nrof_faces>0:\\\\n+                            det = bounding_boxes[:,0:4]\\\\n+                            det_arr = []\\\\n+                            img_size = np.asarray(img.shape)[0:2]\\\\n+                            if nrof_faces>1:\\\\n+                                if args.detect_multiple_faces:\\\\n+                                    for i in range(nrof_faces):\\\\n+                                        det_arr.append(np.squeeze(det[i]))\\\\n+                                else:\\\\n+                                    bounding_box_size = (det[:,2]-det[:,0])*(det[:,3]-det[:,1])\\\\n+                                    img_center = img_size / 2\\\\n+                                    offsets = np.vstack([ (det[:,0]+det[:,2])/2-img_center[1], (det[:,1]+det[:,3])/2-img_center[0] ])\\\\n+                                    offset_dist_squared = np.sum(np.power(offsets,2.0),0)\\\\n+                                    index = np.argmax(bounding_box_size-offset_dist_squared*2.0) # some extra weight on the centering\\\\n+                                    det_arr.append(det[index,:])\\\\n+                            else:\\\\n+                                det_arr.append(np.squeeze(det))\\\\n+\\\\n+                            for i, det in enumerate(det_arr):\\\\n+                                det = np.squeeze(det)\\\\n+                                bb = np.zeros(4, dtype=np.int32)\\\\n+                                bb[0] = np.maximum(det[0]-args.margin/2, 0)\\\\n+                                bb[1] = np.maximum(det[1]-args.margin/2, 0)\\\\n+                                bb[2] = np.minimum(det[2]+args.margin/2, img_size[1])\\\\n+                                bb[3] = np.minimum(det[3]+args.margin/2, img_size[0])\\\\n+                                cropped = img[bb[1]:bb[3],bb[0]:bb[2],:]\\\\n+                                scaled = skimage.transform.resize(cropped, (args.image_size, args.image_size))\\\\n+                                nrof_successfully_aligned += 1\\\\n+                                filename_base, file_extension = os.path.splitext(output_filename)\\\\n+                                if args.detect_multiple_faces:\\\\n+                                    output_filename_n = "{}_{}{}".format(filename_base, i, file_extension)\\\\n+                                else:\\\\n+                                    output_filename_n = "{}{}".format(filename_base, file_extension)\\\\n+                                imageio.imwrite(output_filename_n, scaled)\\\\n+                                text_file.write(\\\\\\\'%s %d %d %d %d\\\\\\\\n\\\\\\\' % (output_filename_n, bb[0], bb[1], bb[2], bb[3]))\\\\n+                        else:\\\\n+                            print(\\\\\\\'Unable to align "%s"\\\\\\\' % image_path)\\\\n+                            text_file.write(\\\\\\\'%s\\\\\\\\n\\\\\\\' % (output_filename))\\\\n+                            \\\\n+    print(\\\\\\\'Total number of images: %d\\\\\\\' % nrof_images_total)\\\\n+    print(\\\\\\\'Number of successfully aligned images: %d\\\\\\\' % nrof_successfully_aligned)\\\\n+            \\\\n+\\\\n+def parse_arguments(argv):\\\\n+    parser = argparse.ArgumentParser()\\\\n+    \\\\n+    parser.add_argument(\\\\\\\'input_dir\\\\\\\', type=str, help=\\\\\\\'Directory with unaligned images.\\\\\\\')\\\\n+    parser.add_argument(\\\\\\\'output_dir\\\\\\\', type=str, help=\\\\\\\'Directory with aligned face thumbnails.\\\\\\\')\\\\n+    parser.add_argument(\\\\\\\'--image_size\\\\\\\', type=int,\\\\n+        help=\\\\\\\'Image size (height, width) in pixels.\\\\\\\', default=182)\\\\n+    parser.add_argument(\\\\\\\'--margin\\\\\\\', type=int,\\\\n+        help=\\\\\\\'Margin for the crop around the bounding box (height, width) in pixels.\\\\\\\', default=44)\\\\n+    parser.add_argument(\\\\\\\'--random_order\\\\\\\', \\\\n+        help=\\\\\\\'Shuffles the order of images to enable alignment using multiple processes.\\\\\\\', action=\\\\\\\'store_true\\\\\\\')\\\\n+    parser.add_argument(\\\\\\\'--gpu_memory_fraction\\\\\\\', type=float,\\\\n+        help=\\\\\\\'Upper bound on the amount of GPU memory that will be used by the process.\\\\\\\', default=1.0)\\\\n+    parser.add_argument(\\\\\\\'--detect_multiple_faces\\\\\\\', type=bool,\\\\n+                        help=\\\\\\\'Detect and align multiple faces per image.\\\\\\\', default=False)\\\\n+    return parser.parse_args(argv)\\\\n+\\\\n+if __name__ == \\\\\\\'__main__\\\\\\\':\\\\n+    main(parse_arguments(sys.argv[1:]))\\\\ndiff --git a/src/faceRec.py b/src/faceRec.py\\\\nnew file mode 100644\\\\nindex 0000000..a5531a2\\\\n--- /dev/null\\\\n+++ b/src/faceRec.py\\\\n@@ -0,0 +1,117 @@\\\\n+from __future__ import absolute_import\\\\n+from __future__ import division\\\\n+from __future__ import print_function\\\\n+\\\\n+import tensorflow as tf\\\\n+import argparse\\\\n+import facenet\\\\n+import os\\\\n+import sys\\\\n+import math\\\\n+import pickle\\\\n+import align.detect_face\\\\n+import numpy as np\\\\n+import cv2\\\\n+import collections\\\\n+from sklearn.svm import SVC\\\\n+\\\\n+\\\\n+def main():\\\\n+    parser = argparse.ArgumentParser()\\\\n+    parser.add_argument(\\\\\\\'--path\\\\\\\', help=\\\\\\\'Path of the video you want to test on.\\\\\\\', default=0)\\\\n+    args = parser.parse_args()\\\\n+\\\\n+    MINSIZE = 20\\\\n+    THRESHOLD = [0.6, 0.7, 0.7]\\\\n+    FACTOR = 0.709\\\\n+    IMAGE_SIZE = 182\\\\n+    INPUT_IMAGE_SIZE = 160\\\\n+    CLASSIFIER_PATH = \\\\\\\'Models/CSE20/CSE20.pkl\\\\\\\'\\\\n+    VIDEO_PATH = args.path\\\\n+    FACENET_MODEL_PATH = \\\\\\\'Models/facenet/20180402-114759.pb\\\\\\\'\\\\n+\\\\n+    # Load The Custom Classifier\\\\n+    with open(CLASSIFIER_PATH, \\\\\\\'rb\\\\\\\') as file:\\\\n+        model, class_names = pickle.load(file)\\\\n+    print("Custom Classifier, Successfully loaded")\\\\n+\\\\n+    with tf.Graph().as_default():\\\\n+\\\\n+        gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.6)\\\\n+        sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options, log_device_placement=False))\\\\n+\\\\n+        with sess.as_default():\\\\n+\\\\n+            # Load the model\\\\n+            print(\\\\\\\'Loading feature extraction model\\\\\\\')\\\\n+            facenet.load_model(FACENET_MODEL_PATH)\\\\n+\\\\n+            # Get input and output tensors\\\\n+            images_placeholder = tf.get_default_graph().get_tensor_by_name("input:0")\\\\n+            embeddings = tf.get_default_graph().get_tensor_by_name("embeddings:0")\\\\n+            phase_train_placeholder = tf.get_default_graph().get_tensor_by_name("phase_train:0")\\\\n+            embedding_size = embeddings.get_shape()[1]\\\\n+\\\\n+            pnet, rnet, onet = align.detect_face.create_mtcnn(sess, "./src/align")\\\\n+\\\\n+            people_detected = set()\\\\n+            person_detected = collections.Counter()\\\\n+\\\\n+            cap = cv2.VideoCapture(VIDEO_PATH)\\\\n+\\\\n+            while (cap.isOpened()):\\\\n+                ret, frame = cap.read()\\\\n+\\\\n+                bounding_boxes, _ = align.detect_face.detect_face(frame, MINSIZE, pnet, rnet, onet, THRESHOLD, FACTOR)\\\\n+\\\\n+                faces_found = bounding_boxes.shape[0]\\\\n+                try:\\\\n+                    if faces_found > 0:\\\\n+                        det = bounding_boxes[:, 0:4]\\\\n+                        bb = np.zeros((faces_found, 4), dtype=np.int32)\\\\n+                        for i in range(faces_found):\\\\n+                            bb[i][0] = det[i][0]\\\\n+                            bb[i][1] = det[i][1]\\\\n+                            bb[i][2] = det[i][2]\\\\n+                            bb[i][3] = det[i][3]\\\\n+\\\\n+                            cropped = frame[bb[i][1]:bb[i][3], bb[i][0]:bb[i][2], :]\\\\n+                            scaled = cv2.resize(cropped, (INPUT_IMAGE_SIZE, INPUT_IMAGE_SIZE),\\\\n+                                                interpolation=cv2.INTER_CUBIC)\\\\n+                            scaled = facenet.prewhiten(scaled)\\\\n+                            scaled_reshape = scaled.reshape(-1, INPUT_IMAGE_SIZE, INPUT_IMAGE_SIZE, 3)\\\\n+                            feed_dict = {images_placeholder: scaled_reshape, phase_train_placeholder: False}\\\\n+                            emb_array = sess.run(embeddings, feed_dict=feed_dict)\\\\n+                            predictions = model.predict_proba(emb_array)\\\\n+                            best_class_indices = np.argmax(predictions, axis=1)\\\\n+                            best_class_probabilities = predictions[\\\\n+                                np.arange(len(best_class_indices)), best_class_indices]\\\\n+                            best_name = class_names[best_class_indices[0]]\\\\n+                            print("Name: {}, Probability: {}".format(best_name, best_class_probabilities))\\\\n+\\\\n+                            cv2.rectangle(frame, (bb[i][0], bb[i][1]), (bb[i][2], bb[i][3]), (0, 255, 0), 2)\\\\n+                            text_x = bb[i][0]\\\\n+                            text_y = bb[i][3] + 20\\\\n+\\\\n+                            if best_class_probabilities > 0.15:\\\\n+                                name = class_names[best_class_indices[0]]\\\\n+                            else:\\\\n+                                name = "Unknown"\\\\n+                            cv2.putText(frame, name, (text_x, text_y), cv2.FONT_HERSHEY_COMPLEX_SMALL,\\\\n+                                        1, (255, 255, 255), thickness=1, lineType=2)\\\\n+                            cv2.putText(frame, str(round(best_class_probabilities[0], 3)), (text_x, text_y + 17),\\\\n+                                        cv2.FONT_HERSHEY_COMPLEX_SMALL,\\\\n+                                        1, (255, 255, 255), thickness=1, lineType=2)\\\\n+                            person_detected[best_name] += 1\\\\n+                except:\\\\n+                    pass\\\\n+\\\\n+                cv2.imshow(\\\\\\\'Face Recognition\\\\\\\', frame)\\\\n+                if cv2.waitKey(1) & 0xFF == ord(\\\\\\\'q\\\\\\\'):\\\\n+                    break\\\\n+\\\\n+            cap.release()\\\\n+            cv2.destroyAllWindows()\\\\n+\\\\n+\\\\n+main()\\\\n\\\\\\\\ No newline at end of file\\\\ndiff --git a/src/facenet.py b/src/facenet.py\\\\nindex 0e05676..538b650 100644\\\\n--- a/src/facenet.py\\\\n+++ b/src/facenet.py\\\\n@@ -32,6 +32,7 @@ from subprocess import Popen, PIPE\\\\n import tensorflow as tf\\\\n import numpy as np\\\\n from scipy import misc\\\\n+import imageio\\\\n from sklearn.model_selection import KFold\\\\n from scipy import interpolate\\\\n from tensorflow.python.training import training\\\\n@@ -244,7 +245,7 @@ def load_data(image_paths, do_random_crop, do_random_flip, image_size, do_prewhi\\\\n     nrof_samples = len(image_paths)\\\\n     images = np.zeros((nrof_samples, image_size, image_size, 3))\\\\n     for i in range(nrof_samples):\\\\n-        img = misc.imread(image_paths[i])\\\\n+        img = imageio.imread(image_paths[i])\\\\n         if img.ndim == 2:\\\\n             img = to_rgb(img)\\\\n         if do_prewhiten:\\\'\\n-\\\\ No newline at end of file\\n-diff --git a/main/Dataset/CSE20/raw/B160116CS_Aparna/B160116CS_1.jpeg b/main/Dataset/CSE20/raw/B160116CS_Aparna/B160116CS_1.jpeg\\n-index e23a8fc..d50e775 100644\\n-Binary files a/main/Dataset/CSE20/raw/B160116CS_Aparna/B160116CS_1.jpeg and b/main/Dataset/CSE20/raw/B160116CS_Aparna/B160116CS_1.jpeg differ\\n-diff --git a/main/README.md b/main/README.md\\n-index 9220d20..baaeced 100644\\n---- a/main/README.md\\n-+++ b/main/README.md\\n-@@ -53,3 +53,4 @@ A couple of pretrained models are provided. They are trained using softmax loss\\n- \\n- ## Performance\\n- The accuracy on LFW for the model [20180402-114759](https://drive.google.com/open?id=1EXPBSXwTaqrSC0OhUdXNmKSh9qJUQ55-) is 0.99650+-0.00252. A description of how to run the test can be found on the page [Validate on LFW](https://github.com/davidsandberg/facenet/wiki/Validate-on-lfw). Note that the input images to the model need to be standardized using fixed image standardization (use the option `--use_fixed_image_standardization` when running e.g. `validate_on_lfw.py`).\\n-+\\n-diff --git a/main/requirements.txt b/main/requirements.txt\\n-index b7418c9..167b725 100644\\n---- a/main/requirements.txt\\n-+++ b/main/requirements.txt\\n-@@ -7,3 +7,5 @@ matplotlib\\n- Pillow\\n- requests\\n- psutil\\n-+imageio\\n-+scikit-image\\n\\\\ No newline at end of file\\n+b\\\'diff --git a/main/Dataset/CSE20/processed/revision_info.txt b/main/Dataset/CSE20/processed/revision_info.txt\\\\nindex 3f5e408..278268d 100644\\\\n--- a/main/Dataset/CSE20/processed/revision_info.txt\\\\n+++ b/main/Dataset/CSE20/processed/revision_info.txt\\\\n@@ -1,287 +1,7 @@\\\\n-arguments: src/align_dataset_mtcnn.py ./Dataset/CSE20/raw/ ./Dataset/CSE20/processed --image_size 160 --margin 32 --random_order --gpu_memory_fraction 0.25\\\\n+arguments: src\\\\\\\\align_dataset_mtcnn.py Dataset\\\\\\\\CSE20\\\\\\\\raw Dataset\\\\\\\\CSE20\\\\\\\\processed --image_size 160 --margin 32 --random_order --gpu_memory_fraction 0.25\\\\n --------------------\\\\n-tensorflow version: 1.7.0\\\\n+tensorflow version: 1.13.1\\\\n --------------------\\\\n-git hash: e5ea2411c6d8091a0c3ca0d6fe3c8be74790c9ab\\\\n+git hash: b\\\\\\\'3d0f9267137d67e77a29f907665b38c8bb4dcd1d\\\\\\\'\\\\n --------------------\\\\n-diff --git a/main/Dataset/CSE20/processed/B160116CS_Aparna/B160116CS_1.png b/main/Dataset/CSE20/processed/B160116CS_Aparna/B160116CS_1.png\\\\n-deleted file mode 100644\\\\n-index f1db83f..0000000\\\\n-Binary files a/main/Dataset/CSE20/processed/B160116CS_Aparna/B160116CS_1.png and /dev/null differ\\\\n-diff --git a/main/Dataset/CSE20/processed/B160116CS_Aparna/B160116CS_2.png b/main/Dataset/CSE20/processed/B160116CS_Aparna/B160116CS_2.png\\\\n-deleted file mode 100644\\\\n-index 45449c3..0000000\\\\n-Binary files a/main/Dataset/CSE20/processed/B160116CS_Aparna/B160116CS_2.png and /dev/null differ\\\\n-diff --git a/main/Dataset/CSE20/processed/B160116CS_Aparna/B160116CS_3.png b/main/Dataset/CSE20/processed/B160116CS_Aparna/B160116CS_3.png\\\\n-deleted file mode 100644\\\\n-index 9813f9f..0000000\\\\n-Binary files a/main/Dataset/CSE20/processed/B160116CS_Aparna/B160116CS_3.png and /dev/null differ\\\\n-diff --git a/main/Dataset/CSE20/processed/B160118CS_Neeraja/B160118CS_1.png b/main/Dataset/CSE20/processed/B160118CS_Neeraja/B160118CS_1.png\\\\n-deleted file mode 100644\\\\n-index fb52346..0000000\\\\n-Binary files a/main/Dataset/CSE20/processed/B160118CS_Neeraja/B160118CS_1.png and /dev/null differ\\\\n-diff --git a/main/Dataset/CSE20/processed/B160118CS_Neeraja/B160118CS_2.png b/main/Dataset/CSE20/processed/B160118CS_Neeraja/B160118CS_2.png\\\\n-deleted file mode 100644\\\\n-index 3a04b13..0000000\\\\n-Binary files a/main/Dataset/CSE20/processed/B160118CS_Neeraja/B160118CS_2.png and /dev/null differ\\\\n-diff --git a/main/Dataset/CSE20/processed/B160118CS_Neeraja/B160118CS_3.png b/main/Dataset/CSE20/processed/B160118CS_Neeraja/B160118CS_3.png\\\\n-deleted file mode 100644\\\\n-index f7c2d61..0000000\\\\n-Binary files a/main/Dataset/CSE20/processed/B160118CS_Neeraja/B160118CS_3.png and /dev/null differ\\\\n-diff --git a/main/Dataset/CSE20/processed/B160213CS_Nileena/B160213CS_1.png b/main/Dataset/CSE20/processed/B160213CS_Nileena/B160213CS_1.png\\\\n-deleted file mode 100644\\\\n-index 5affd0e..0000000\\\\n-Binary files a/main/Dataset/CSE20/processed/B160213CS_Nileena/B160213CS_1.png and /dev/null differ\\\\n-diff --git a/main/Dataset/CSE20/processed/B160213CS_Nileena/B160213CS_2.png b/main/Dataset/CSE20/processed/B160213CS_Nileena/B160213CS_2.png\\\\n-deleted file mode 100644\\\\n-index 6bf453c..0000000\\\\n-Binary files a/main/Dataset/CSE20/processed/B160213CS_Nileena/B160213CS_2.png and /dev/null differ\\\\n-diff --git a/main/Dataset/CSE20/processed/B160213CS_Nileena/B160213CS_3.png b/main/Dataset/CSE20/processed/B160213CS_Nileena/B160213CS_3.png\\\\n-deleted file mode 100644\\\\n-index c40a062..0000000\\\\n-Binary files a/main/Dataset/CSE20/processed/B160213CS_Nileena/B160213CS_3.png and /dev/null differ\\\\n-diff --git a/main/Dataset/CSE20/processed/B160228CS_Vrindha/B160226CS_1.png b/main/Dataset/CSE20/processed/B160228CS_Vrindha/B160226CS_1.png\\\\n-deleted file mode 100644\\\\n-index 598febb..0000000\\\\n-Binary files a/main/Dataset/CSE20/processed/B160228CS_Vrindha/B160226CS_1.png and /dev/null differ\\\\n-diff --git a/main/Dataset/CSE20/processed/B160228CS_Vrindha/B160226CS_2.png b/main/Dataset/CSE20/processed/B160228CS_Vrindha/B160226CS_2.png\\\\n-deleted file mode 100644\\\\n-index 90186c5..0000000\\\\n-Binary files a/main/Dataset/CSE20/processed/B160228CS_Vrindha/B160226CS_2.png and /dev/null differ\\\\n-diff --git a/main/Dataset/CSE20/processed/B160228CS_Vrindha/B160226CS_3.png b/main/Dataset/CSE20/processed/B160228CS_Vrindha/B160226CS_3.png\\\\n-deleted file mode 100644\\\\n-index 11e9bc8..0000000\\\\n-Binary files a/main/Dataset/CSE20/processed/B160228CS_Vrindha/B160226CS_3.png and /dev/null differ\\\\n-diff --git a/main/Dataset/CSE20/processed/B160229CS_Reema/B160229CS_1.png b/main/Dataset/CSE20/processed/B160229CS_Reema/B160229CS_1.png\\\\n-deleted file mode 100644\\\\n-index 078771e..0000000\\\\n-Binary files a/main/Dataset/CSE20/processed/B160229CS_Reema/B160229CS_1.png and /dev/null differ\\\\n-diff --git a/main/Dataset/CSE20/processed/B160229CS_Reema/B160229CS_2.png b/main/Dataset/CSE20/processed/B160229CS_Reema/B160229CS_2.png\\\\n-deleted file mode 100644\\\\n-index b4aee42..0000000\\\\n-Binary files a/main/Dataset/CSE20/processed/B160229CS_Reema/B160229CS_2.png and /dev/null differ\\\\n-diff --git a/main/Dataset/CSE20/processed/B160229CS_Reema/B160229CS_3.png b/main/Dataset/CSE20/processed/B160229CS_Reema/B160229CS_3.png\\\\n-deleted file mode 100644\\\\n-index 406508e..0000000\\\\n-Binary files a/main/Dataset/CSE20/processed/B160229CS_Reema/B160229CS_3.png and /dev/null differ\\\\n-diff --git a/main/Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_1.png b/main/Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_1.png\\\\n-deleted file mode 100644\\\\n-index cb05c38..0000000\\\\n-Binary files a/main/Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_1.png and /dev/null differ\\\\n-diff --git a/main/Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_2.png b/main/Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_2.png\\\\n-deleted file mode 100644\\\\n-index ebef29c..0000000\\\\n-Binary files a/main/Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_2.png and /dev/null differ\\\\n-diff --git a/main/Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_3.png b/main/Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_3.png\\\\n-deleted file mode 100644\\\\n-index 5b409b0..0000000\\\\n-Binary files a/main/Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_3.png and /dev/null differ\\\\n-diff --git a/main/Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_4.png b/main/Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_4.png\\\\n-deleted file mode 100644\\\\n-index 63291a9..0000000\\\\n-Binary files a/main/Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_4.png and /dev/null differ\\\\n-diff --git a/main/Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_5.png b/main/Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_5.png\\\\n-deleted file mode 100644\\\\n-index 35bb01f..0000000\\\\n-Binary files a/main/Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_5.png and /dev/null differ\\\\n-diff --git a/main/Dataset/CSE20/processed/B160320ME_Shebin/B160320ME_1.png b/main/Dataset/CSE20/processed/B160320ME_Shebin/B160320ME_1.png\\\\n-deleted file mode 100644\\\\n-index fa0c503..0000000\\\\n-Binary files a/main/Dataset/CSE20/processed/B160320ME_Shebin/B160320ME_1.png and /dev/null differ\\\\n-diff --git a/main/Dataset/CSE20/processed/B160320ME_Shebin/B160320ME_2.png b/main/Dataset/CSE20/processed/B160320ME_Shebin/B160320ME_2.png\\\\n-deleted file mode 100644\\\\n-index 79a0e5d..0000000\\\\n-Binary files a/main/Dataset/CSE20/processed/B160320ME_Shebin/B160320ME_2.png and /dev/null differ\\\\n-diff --git a/main/Dataset/CSE20/processed/B160320ME_Shebin/B160320ME_3.png b/main/Dataset/CSE20/processed/B160320ME_Shebin/B160320ME_3.png\\\\n-deleted file mode 100644\\\\n-index c03da94..0000000\\\\n-Binary files a/main/Dataset/CSE20/processed/B160320ME_Shebin/B160320ME_3.png and /dev/null differ\\\\n-diff --git a/main/Dataset/CSE20/processed/B160408CS_Ameen/B160408CS_1.png b/main/Dataset/CSE20/processed/B160408CS_Ameen/B160408CS_1.png\\\\n-deleted file mode 100644\\\\n-index 16a46a2..0000000\\\\n-Binary files a/main/Dataset/CSE20/processed/B160408CS_Ameen/B160408CS_1.png and /dev/null differ\\\\n-diff --git a/main/Dataset/CSE20/processed/B160408CS_Ameen/B160408CS_2.png b/main/Dataset/CSE20/processed/B160408CS_Ameen/B160408CS_2.png\\\\n-deleted file mode 100644\\\\n-index 7d933ff..0000000\\\\n-Binary files a/main/Dataset/CSE20/processed/B160408CS_Ameen/B160408CS_2.png and /dev/null differ\\\\n-diff --git a/main/Dataset/CSE20/processed/B160408CS_Ameen/B160408CS_3.png b/main/Dataset/CSE20/processed/B160408CS_Ameen/B160408CS_3.png\\\\n-deleted file mode 100644\\\\n-index ce20835..0000000\\\\n-Binary files a/main/Dataset/CSE20/processed/B160408CS_Ameen/B160408CS_3.png and /dev/null differ\\\\n-diff --git a/main/Dataset/CSE20/processed/B160445CS_Sumalatha/B160445CS_1.png b/main/Dataset/CSE20/processed/B160445CS_Sumalatha/B160445CS_1.png\\\\n-deleted file mode 100644\\\\n-index fd9ed6f..0000000\\\\n-Binary files a/main/Dataset/CSE20/processed/B160445CS_Sumalatha/B160445CS_1.png and /dev/null differ\\\\n-diff --git a/main/Dataset/CSE20/processed/B160445CS_Sumalatha/B160445CS_2.png b/main/Dataset/CSE20/processed/B160445CS_Sumalatha/B160445CS_2.png\\\\n-deleted file mode 100644\\\\n-index ad52a1d..0000000\\\\n-Binary files a/main/Dataset/CSE20/processed/B160445CS_Sumalatha/B160445CS_2.png and /dev/null differ\\\\n-diff --git a/main/Dataset/CSE20/processed/B160471CS_Dheeraj/B160471CS_1.png b/main/Dataset/CSE20/processed/B160471CS_Dheeraj/B160471CS_1.png\\\\n-deleted file mode 100644\\\\n-index 78a1983..0000000\\\\n-Binary files a/main/Dataset/CSE20/processed/B160471CS_Dheeraj/B160471CS_1.png and /dev/null differ\\\\n-diff --git a/main/Dataset/CSE20/processed/B160688CS_Vishnu/B160688CS_1.png b/main/Dataset/CSE20/processed/B160688CS_Vishnu/B160688CS_1.png\\\\n-deleted file mode 100644\\\\n-index f43b308..0000000\\\\n-Binary files a/main/Dataset/CSE20/processed/B160688CS_Vishnu/B160688CS_1.png and /dev/null differ\\\\n-diff --git a/main/Dataset/CSE20/processed/B160688CS_Vishnu/B160688CS_2.png b/main/Dataset/CSE20/processed/B160688CS_Vishnu/B160688CS_2.png\\\\n-deleted file mode 100644\\\\n-index 5654243..0000000\\\\n-Binary files a/main/Dataset/CSE20/processed/B160688CS_Vishnu/B160688CS_2.png and /dev/null differ\\\\n-diff --git a/main/Dataset/CSE20/processed/B160688CS_Vishnu/B160688CS_3.png b/main/Dataset/CSE20/processed/B160688CS_Vishnu/B160688CS_3.png\\\\n-deleted file mode 100644\\\\n-index 4db5286..0000000\\\\n-Binary files a/main/Dataset/CSE20/processed/B160688CS_Vishnu/B160688CS_3.png and /dev/null differ\\\\n-diff --git a/main/Dataset/CSE20/processed/B160760CS_Vatsala/B160760CS_1.png b/main/Dataset/CSE20/processed/B160760CS_Vatsala/B160760CS_1.png\\\\n-deleted file mode 100644\\\\n-index 80f206e..0000000\\\\n-Binary files a/main/Dataset/CSE20/processed/B160760CS_Vatsala/B160760CS_1.png and /dev/null differ\\\\n-diff --git a/main/Dataset/CSE20/processed/B160760CS_Vatsala/B160760CS_2.png b/main/Dataset/CSE20/processed/B160760CS_Vatsala/B160760CS_2.png\\\\n-deleted file mode 100644\\\\n-index fbdeadf..0000000\\\\n-Binary files a/main/Dataset/CSE20/processed/B160760CS_Vatsala/B160760CS_2.png and /dev/null differ\\\\n-diff --git a/main/Dataset/CSE20/processed/B160760CS_Vatsala/B160760CS_3.png b/main/Dataset/CSE20/processed/B160760CS_Vatsala/B160760CS_3.png\\\\n-deleted file mode 100644\\\\n-index b7bb5e8..0000000\\\\n-Binary files a/main/Dataset/CSE20/processed/B160760CS_Vatsala/B160760CS_3.png and /dev/null differ\\\\n-diff --git a/main/Dataset/CSE20/processed/B160873CS_Naina/B160873CS_1.png b/main/Dataset/CSE20/processed/B160873CS_Naina/B160873CS_1.png\\\\n-deleted file mode 100644\\\\n-index 71d405b..0000000\\\\n-Binary files a/main/Dataset/CSE20/processed/B160873CS_Naina/B160873CS_1.png and /dev/null differ\\\\n-diff --git a/main/Dataset/CSE20/processed/B160873CS_Naina/B160873CS_2.png b/main/Dataset/CSE20/processed/B160873CS_Naina/B160873CS_2.png\\\\n-deleted file mode 100644\\\\n-index 2018b5c..0000000\\\\n-Binary files a/main/Dataset/CSE20/processed/B160873CS_Naina/B160873CS_2.png and /dev/null differ\\\\n-diff --git a/main/Dataset/CSE20/processed/B160873CS_Naina/B160873CS_3.png b/main/Dataset/CSE20/processed/B160873CS_Naina/B160873CS_3.png\\\\n-deleted file mode 100644\\\\n-index 6f1ae5c..0000000\\\\n-Binary files a/main/Dataset/CSE20/processed/B160873CS_Naina/B160873CS_3.png and /dev/null differ\\\\n-diff --git a/main/Dataset/CSE20/processed/bounding_boxes_09361.txt b/main/Dataset/CSE20/processed/bounding_boxes_09361.txt\\\\n-deleted file mode 100644\\\\n-index da52b30..0000000\\\\n---- a/main/Dataset/CSE20/processed/bounding_boxes_09361.txt\\\\n-+++ /dev/null\\\\n-@@ -1,35 +0,0 @@\\\\n--Dataset/CSE20/processed/B160760CS_Vatsala/B160760CS_3.png 737 316 933 556\\\\n--Dataset/CSE20/processed/B160760CS_Vatsala/B160760CS_2.png 153 385 552 891\\\\n--Dataset/CSE20/processed/B160760CS_Vatsala/B160760CS_1.png 468 264 572 389\\\\n--Dataset/CSE20/processed/B160320ME_Shebin/B160320ME_1.png 330 315 631 688\\\\n--Dataset/CSE20/processed/B160320ME_Shebin/B160320ME_3.png 191 285 646 892\\\\n--Dataset/CSE20/processed/B160320ME_Shebin/B160320ME_2.png 440 427 806 846\\\\n--Dataset/CSE20/processed/B160688CS_Vishnu/B160688CS_3.png 725 1044 1618 2214\\\\n--Dataset/CSE20/processed/B160688CS_Vishnu/B160688CS_2.png 973 426 1711 1363\\\\n--Dataset/CSE20/processed/B160688CS_Vishnu/B160688CS_1.png 544 396 1107 1123\\\\n--Dataset/CSE20/processed/B160116CS_Aparna/B160116CS_3.png 152 200 367 450\\\\n--Dataset/CSE20/processed/B160116CS_Aparna/B160116CS_2.png 229 63 386 249\\\\n--Dataset/CSE20/processed/B160116CS_Aparna/B160116CS_1.png 284 560 332 614\\\\n--Dataset/CSE20/processed/B160229CS_Reema/B160229CS_3.png 313 266 494 511\\\\n--Dataset/CSE20/processed/B160229CS_Reema/B160229CS_2.png 144 216 315 427\\\\n--Dataset/CSE20/processed/B160229CS_Reema/B160229CS_1.png 234 384 322 495\\\\n--Dataset/CSE20/processed/B160118CS_Neeraja/B160118CS_1.png 130 170 396 484\\\\n--Dataset/CSE20/processed/B160118CS_Neeraja/B160118CS_3.png 429 535 561 696\\\\n--Dataset/CSE20/processed/B160118CS_Neeraja/B160118CS_2.png 262 59 490 329\\\\n--Dataset/CSE20/processed/B160213CS_Nileena/B160213CS_1.png 137 160 397 472\\\\n--Dataset/CSE20/processed/B160213CS_Nileena/B160213CS_2.png 265 271 455 492\\\\n--Dataset/CSE20/processed/B160213CS_Nileena/B160213CS_3.png 89 336 272 568\\\\n--Dataset/CSE20/processed/B160873CS_Naina/B160873CS_1.png 133 145 299 358\\\\n--Dataset/CSE20/processed/B160873CS_Naina/B160873CS_2.png 451 407 544 518\\\\n--Dataset/CSE20/processed/B160873CS_Naina/B160873CS_3.png 81 58 278 310\\\\n--Dataset/CSE20/processed/B160228CS_Vrindha/B160226CS_2.png 69 259 255 491\\\\n--Dataset/CSE20/processed/B160228CS_Vrindha/B160226CS_1.png 516 60 868 528\\\\n--Dataset/CSE20/processed/B160228CS_Vrindha/B160226CS_3.png 297 232 727 812\\\\n--Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_4.png 221 361 404 600\\\\n--Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_1.png 277 240 512 537\\\\n--Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_3.png 532 299 622 407\\\\n--Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_2.png 195 53 286 160\\\\n--Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_5.png 169 348 584 922\\\\n--Dataset/CSE20/processed/B160445CS_Sumalatha/B160445CS_1.png 219 73 363 261\\\\n--Dataset/CSE20/processed/B160445CS_Sumalatha/B160445CS_2.png 406 272 546 443\\\\n--Dataset/CSE20/processed/B160445CS_Sumalatha/B160445CS_3.png 433 616 484 674\\\\n-diff --git a/main/Dataset/CSE20/processed/bounding_boxes_19737.txt b/main/Dataset/CSE20/processed/bounding_boxes_19737.txt\\\\n-deleted file mode 100644\\\\n-index e69de29..0000000\\\\n-diff --git a/main/Dataset/CSE20/processed/bounding_boxes_20330.txt b/main/Dataset/CSE20/processed/bounding_boxes_20330.txt\\\\n-deleted file mode 100644\\\\n-index e69de29..0000000\\\\n-diff --git a/main/Dataset/CSE20/processed/bounding_boxes_28104.txt b/main/Dataset/CSE20/processed/bounding_boxes_28104.txt\\\\n-deleted file mode 100644\\\\n-index dc58fca..0000000\\\\n---- a/main/Dataset/CSE20/processed/bounding_boxes_28104.txt\\\\n-+++ /dev/null\\\\n-@@ -1,3 +0,0 @@\\\\n--Dataset/CSE20/processed/Naina/naina2.png 451 407 544 518\\\\n--Dataset/CSE20/processed/Naina/naina3.png 81 58 278 310\\\\n--Dataset/CSE20/processed/Naina/naina1.png 133 145 299 358\\\\n-diff --git a/main/Dataset/CSE20/processed/bounding_boxes_30925.txt b/main/Dataset/CSE20/processed/bounding_boxes_30925.txt\\\\n-deleted file mode 100644\\\\n-index e69de29..0000000\\\\n-diff --git a/main/Dataset/CSE20/processed/bounding_boxes_38733.txt b/main/Dataset/CSE20/processed/bounding_boxes_38733.txt\\\\n-deleted file mode 100644\\\\n-index e69de29..0000000\\\\n-diff --git a/main/Dataset/CSE20/processed/bounding_boxes_40979.txt b/main/Dataset/CSE20/processed/bounding_boxes_40979.txt\\\\n-deleted file mode 100644\\\\n-index e69de29..0000000\\\\n-diff --git a/main/Dataset/CSE20/processed/bounding_boxes_50376.txt b/main/Dataset/CSE20/processed/bounding_boxes_50376.txt\\\\n-deleted file mode 100644\\\\n-index 746e69e..0000000\\\\n---- a/main/Dataset/CSE20/processed/bounding_boxes_50376.txt\\\\n-+++ /dev/null\\\\n-@@ -1,3 +0,0 @@\\\\n--Dataset/CSE20/processed/Poothery/Poothery1.png 544 396 1107 1123\\\\n--Dataset/CSE20/processed/Poothery/Poothery2.png 973 426 1711 1363\\\\n--Dataset/CSE20/processed/Poothery/Poothery3.png 725 1044 1618 2214\\\\n-diff --git a/main/Dataset/CSE20/processed/bounding_boxes_51760.txt b/main/Dataset/CSE20/processed/bounding_boxes_51760.txt\\\\n-deleted file mode 100644\\\\n-index e69de29..0000000\\\\n-diff --git a/main/Dataset/CSE20/processed/bounding_boxes_78500.txt b/main/Dataset/CSE20/processed/bounding_boxes_78500.txt\\\\n-deleted file mode 100644\\\\n-index e69de29..0000000\\\\n-diff --git a/main/Dataset/CSE20/processed/bounding_boxes_80845.txt b/main/Dataset/CSE20/processed/bounding_boxes_80845.txt\\\\n-deleted file mode 100644\\\\n-index e69de29..0000000\\\\n-diff --git a/main/Dataset/CSE20/processed/bounding_boxes_95936.txt b/main/Dataset/CSE20/processed/bounding_boxes_95936.txt\\\\n-deleted file mode 100644\\\\n-index 5c0564d..0000000\\\\n---- a/main/Dataset/CSE20/processed/bounding_boxes_95936.txt\\\\n-+++ /dev/null\\\\n-@@ -1,4 +0,0 @@\\\\n--Dataset/CSE20/processed/B160471CS_Dheeraj/B160471CS_1.png 227 268 413 483\\\\n--Dataset/CSE20/processed/B160408CS_Ameen/B160408CS_3.png 241 337 448 614\\\\n--Dataset/CSE20/processed/B160408CS_Ameen/B160408CS_1.png 259 306 442 541\\\\n--Dataset/CSE20/processed/B160408CS_Ameen/B160408CS_2.png 312 148 530 417\\\\n-diff --git a/main/Dataset/CSE20/processed/revision_info.txt b/main/Dataset/CSE20/processed/revision_info.txt\\\\n-deleted file mode 100644\\\\n-index 3eaf7fb..0000000\\\\n---- a/main/Dataset/CSE20/processed/revision_info.txt\\\\n-+++ /dev/null\\\\n-@@ -1,7 +0,0 @@\\\\n--arguments: src/align_dataset_mtcnn.py ./Dataset/CSE20/raw/ ./Dataset/CSE20/processed/ --image_size 160 --margin 32 --random_order --gpu_memory_fraction 0.25\\\\n----------------------\\\\n--tensorflow version: 1.7.0\\\\n----------------------\\\\n--git hash: b\\\\\\\'096ed770f163957c1e56efa7feeb194773920f6e\\\\\\\'\\\\n----------------------\\\\n--b\\\\\\\'diff --git a/ /revision_info.txt b/ /revision_info.txt\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..979e188\\\\\\\\n--- /dev/null\\\\\\\\n+++ b/ /revision_info.txt\\\\\\\\t\\\\\\\\n@@ -0,0 +1,8 @@\\\\\\\\n+arguments: src/align/align_dataset_mtcnn.py ./Dataset/CSE20/raw \\\\\\\\\\\\\\\\\\\\\\\\n+./Dataset/CSE20/processed --image_size 160 --margin 32 --random_order  \\\\\\\\n+--------------------\\\\\\\\n+tensorflow version: 1.7.0\\\\\\\\n+--------------------\\\\\\\\n+git hash: b\\\\\\\\\\\\\\\'096ed770f163957c1e56efa7feeb194773920f6e\\\\\\\\\\\\\\\'\\\\\\\\n+--------------------\\\\\\\\n+b\\\\\\\\\\\\\\\'diff --git a/src/align/align_dataset_mtcnn.py b/src/align/align_dataset_mtcnn.py\\\\\\\\\\\\\\\\nindex 7d5e735..21f1457 100644\\\\\\\\\\\\\\\\n--- a/src/align/align_dataset_mtcnn.py\\\\\\\\\\\\\\\\n+++ b/src/align/align_dataset_mtcnn.py\\\\\\\\\\\\\\\\n@@ -31,8 +31,8 @@ import os\\\\\\\\\\\\\\\\n import argparse\\\\\\\\\\\\\\\\n import tensorflow as tf\\\\\\\\\\\\\\\\n import numpy as np\\\\\\\\\\\\\\\\n-import facenet\\\\\\\\\\\\\\\\n-import align.detect_face\\\\\\\\\\\\\\\\n+import facenet.src.facenet as facenet   #changed\\\\\\\\\\\\\\\\n+import detect_face  #changed\\\\\\\\\\\\\\\\n import random\\\\\\\\\\\\\\\\n from time import sleep\\\\\\\\\\\\\\\'\\\\\\\\n\\\\\\\\\\\\\\\\ No newline at end of file\\\\\\\\ndiff --git a/Dataset/CSE20/processed/B160116CS_Aparna/B160116CS_1.png b/Dataset/CSE20/processed/B160116CS_Aparna/B160116CS_1.png\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..f1db83f\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160116CS_Aparna/B160116CS_1.png differ\\\\\\\\ndiff --git a/Dataset/CSE20/processed/B160116CS_Aparna/B160116CS_2.png b/Dataset/CSE20/processed/B160116CS_Aparna/B160116CS_2.png\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..45449c3\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160116CS_Aparna/B160116CS_2.png differ\\\\\\\\ndiff --git a/Dataset/CSE20/processed/B160116CS_Aparna/B160116CS_3.png b/Dataset/CSE20/processed/B160116CS_Aparna/B160116CS_3.png\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..9813f9f\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160116CS_Aparna/B160116CS_3.png differ\\\\\\\\ndiff --git a/Dataset/CSE20/processed/B160118CS_Neeraja/B160118CS_1.png b/Dataset/CSE20/processed/B160118CS_Neeraja/B160118CS_1.png\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..fb52346\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160118CS_Neeraja/B160118CS_1.png differ\\\\\\\\ndiff --git a/Dataset/CSE20/processed/B160118CS_Neeraja/B160118CS_2.png b/Dataset/CSE20/processed/B160118CS_Neeraja/B160118CS_2.png\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..3a04b13\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160118CS_Neeraja/B160118CS_2.png differ\\\\\\\\ndiff --git a/Dataset/CSE20/processed/B160118CS_Neeraja/B160118CS_3.png b/Dataset/CSE20/processed/B160118CS_Neeraja/B160118CS_3.png\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..f7c2d61\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160118CS_Neeraja/B160118CS_3.png differ\\\\\\\\ndiff --git a/Dataset/CSE20/processed/B160213CS_Nileena/B160213CS_1.png b/Dataset/CSE20/processed/B160213CS_Nileena/B160213CS_1.png\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..5affd0e\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160213CS_Nileena/B160213CS_1.png differ\\\\\\\\ndiff --git a/Dataset/CSE20/processed/B160213CS_Nileena/B160213CS_2.png b/Dataset/CSE20/processed/B160213CS_Nileena/B160213CS_2.png\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..6bf453c\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160213CS_Nileena/B160213CS_2.png differ\\\\\\\\ndiff --git a/Dataset/CSE20/processed/B160213CS_Nileena/B160213CS_3.png b/Dataset/CSE20/processed/B160213CS_Nileena/B160213CS_3.png\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..c40a062\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160213CS_Nileena/B160213CS_3.png differ\\\\\\\\ndiff --git a/Dataset/CSE20/processed/B160228CS_Vrindha/B160226CS_1.png b/Dataset/CSE20/processed/B160228CS_Vrindha/B160226CS_1.png\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..598febb\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160228CS_Vrindha/B160226CS_1.png differ\\\\\\\\ndiff --git a/Dataset/CSE20/processed/B160228CS_Vrindha/B160226CS_2.png b/Dataset/CSE20/processed/B160228CS_Vrindha/B160226CS_2.png\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..90186c5\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160228CS_Vrindha/B160226CS_2.png differ\\\\\\\\ndiff --git a/Dataset/CSE20/processed/B160228CS_Vrindha/B160226CS_3.png b/Dataset/CSE20/processed/B160228CS_Vrindha/B160226CS_3.png\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..11e9bc8\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160228CS_Vrindha/B160226CS_3.png differ\\\\\\\\ndiff --git a/Dataset/CSE20/processed/B160229CS_Reema/B160229CS_1.png b/Dataset/CSE20/processed/B160229CS_Reema/B160229CS_1.png\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..078771e\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160229CS_Reema/B160229CS_1.png differ\\\\\\\\ndiff --git a/Dataset/CSE20/processed/B160229CS_Reema/B160229CS_2.png b/Dataset/CSE20/processed/B160229CS_Reema/B160229CS_2.png\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..b4aee42\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160229CS_Reema/B160229CS_2.png differ\\\\\\\\ndiff --git a/Dataset/CSE20/processed/B160229CS_Reema/B160229CS_3.png b/Dataset/CSE20/processed/B160229CS_Reema/B160229CS_3.png\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..406508e\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160229CS_Reema/B160229CS_3.png differ\\\\\\\\ndiff --git a/Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_1.png b/Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_1.png\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..cb05c38\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_1.png differ\\\\\\\\ndiff --git a/Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_2.png b/Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_2.png\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..ebef29c\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_2.png differ\\\\\\\\ndiff --git a/Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_3.png b/Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_3.png\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..5b409b0\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_3.png differ\\\\\\\\ndiff --git a/Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_4.png b/Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_4.png\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..63291a9\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_4.png differ\\\\\\\\ndiff --git a/Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_5.png b/Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_5.png\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..35bb01f\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_5.png differ\\\\\\\\ndiff --git a/Dataset/CSE20/processed/B160320ME_Shebin/B160320ME_1.png b/Dataset/CSE20/processed/B160320ME_Shebin/B160320ME_1.png\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..fa0c503\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160320ME_Shebin/B160320ME_1.png differ\\\\\\\\ndiff --git a/Dataset/CSE20/processed/B160320ME_Shebin/B160320ME_2.png b/Dataset/CSE20/processed/B160320ME_Shebin/B160320ME_2.png\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..79a0e5d\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160320ME_Shebin/B160320ME_2.png differ\\\\\\\\ndiff --git a/Dataset/CSE20/processed/B160320ME_Shebin/B160320ME_3.png b/Dataset/CSE20/processed/B160320ME_Shebin/B160320ME_3.png\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..c03da94\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160320ME_Shebin/B160320ME_3.png differ\\\\\\\\ndiff --git a/Dataset/CSE20/processed/B160408CS_Ameen/B160408CS_1.png b/Dataset/CSE20/processed/B160408CS_Ameen/B160408CS_1.png\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..16a46a2\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160408CS_Ameen/B160408CS_1.png differ\\\\\\\\ndiff --git a/Dataset/CSE20/processed/B160408CS_Ameen/B160408CS_2.png b/Dataset/CSE20/processed/B160408CS_Ameen/B160408CS_2.png\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..7d933ff\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160408CS_Ameen/B160408CS_2.png differ\\\\\\\\ndiff --git a/Dataset/CSE20/processed/B160408CS_Ameen/B160408CS_3.png b/Dataset/CSE20/processed/B160408CS_Ameen/B160408CS_3.png\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..ce20835\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160408CS_Ameen/B160408CS_3.png differ\\\\\\\\ndiff --git a/Dataset/CSE20/processed/B160445CS_Sumalatha/B160445CS_1.png b/Dataset/CSE20/processed/B160445CS_Sumalatha/B160445CS_1.png\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..fd9ed6f\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160445CS_Sumalatha/B160445CS_1.png differ\\\\\\\\ndiff --git a/Dataset/CSE20/processed/B160445CS_Sumalatha/B160445CS_2.png b/Dataset/CSE20/processed/B160445CS_Sumalatha/B160445CS_2.png\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..ad52a1d\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160445CS_Sumalatha/B160445CS_2.png differ\\\\\\\\ndiff --git a/Dataset/CSE20/processed/B160445CS_Sumalatha/B160445CS_3.png b/Dataset/CSE20/processed/B160445CS_Sumalatha/B160445CS_3.png\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..7fc6b80\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160445CS_Sumalatha/B160445CS_3.png differ\\\\\\\\ndiff --git a/Dataset/CSE20/processed/B160471CS_Dheeraj/B160471CS_1.png b/Dataset/CSE20/processed/B160471CS_Dheeraj/B160471CS_1.png\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..78a1983\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160471CS_Dheeraj/B160471CS_1.png differ\\\\\\\\ndiff --git a/Dataset/CSE20/processed/B160688CS_Vishnu/B160688CS_1.png b/Dataset/CSE20/processed/B160688CS_Vishnu/B160688CS_1.png\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..f43b308\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160688CS_Vishnu/B160688CS_1.png differ\\\\\\\\ndiff --git a/Dataset/CSE20/processed/B160688CS_Vishnu/B160688CS_2.png b/Dataset/CSE20/processed/B160688CS_Vishnu/B160688CS_2.png\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..5654243\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160688CS_Vishnu/B160688CS_2.png differ\\\\\\\\ndiff --git a/Dataset/CSE20/processed/B160688CS_Vishnu/B160688CS_3.png b/Dataset/CSE20/processed/B160688CS_Vishnu/B160688CS_3.png\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..4db5286\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160688CS_Vishnu/B160688CS_3.png differ\\\\\\\\ndiff --git a/Dataset/CSE20/processed/B160760CS_Vatsala/B160760CS_1.png b/Dataset/CSE20/processed/B160760CS_Vatsala/B160760CS_1.png\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..80f206e\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160760CS_Vatsala/B160760CS_1.png differ\\\\\\\\ndiff --git a/Dataset/CSE20/processed/B160760CS_Vatsala/B160760CS_2.png b/Dataset/CSE20/processed/B160760CS_Vatsala/B160760CS_2.png\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..fbdeadf\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160760CS_Vatsala/B160760CS_2.png differ\\\\\\\\ndiff --git a/Dataset/CSE20/processed/B160760CS_Vatsala/B160760CS_3.png b/Dataset/CSE20/processed/B160760CS_Vatsala/B160760CS_3.png\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..b7bb5e8\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160760CS_Vatsala/B160760CS_3.png differ\\\\\\\\ndiff --git a/Dataset/CSE20/processed/B160873CS_Naina/B160873CS_1.png b/Dataset/CSE20/processed/B160873CS_Naina/B160873CS_1.png\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..71d405b\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160873CS_Naina/B160873CS_1.png differ\\\\\\\\ndiff --git a/Dataset/CSE20/processed/B160873CS_Naina/B160873CS_2.png b/Dataset/CSE20/processed/B160873CS_Naina/B160873CS_2.png\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..2018b5c\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160873CS_Naina/B160873CS_2.png differ\\\\\\\\ndiff --git a/Dataset/CSE20/processed/B160873CS_Naina/B160873CS_3.png b/Dataset/CSE20/processed/B160873CS_Naina/B160873CS_3.png\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..6f1ae5c\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160873CS_Naina/B160873CS_3.png differ\\\\\\\\ndiff --git a/Dataset/CSE20/processed/Naina/naina1.png b/Dataset/CSE20/processed/Naina/naina1.png\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..71d405b\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/Naina/naina1.png differ\\\\\\\\ndiff --git a/Dataset/CSE20/processed/Naina/naina2.png b/Dataset/CSE20/processed/Naina/naina2.png\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..2018b5c\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/Naina/naina2.png differ\\\\\\\\ndiff --git a/Dataset/CSE20/processed/Naina/naina3.png b/Dataset/CSE20/processed/Naina/naina3.png\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..6f1ae5c\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/Naina/naina3.png differ\\\\\\\\ndiff --git a/Dataset/CSE20/processed/Poothery/Poothery1.png b/Dataset/CSE20/processed/Poothery/Poothery1.png\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..f43b308\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/Poothery/Poothery1.png differ\\\\\\\\ndiff --git a/Dataset/CSE20/processed/Poothery/Poothery2.png b/Dataset/CSE20/processed/Poothery/Poothery2.png\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..5654243\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/Poothery/Poothery2.png differ\\\\\\\\ndiff --git a/Dataset/CSE20/processed/Poothery/Poothery3.png b/Dataset/CSE20/processed/Poothery/Poothery3.png\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..4db5286\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/Poothery/Poothery3.png differ\\\\\\\\ndiff --git a/Dataset/CSE20/processed/bounding_boxes_09361.txt b/Dataset/CSE20/processed/bounding_boxes_09361.txt\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..da52b30\\\\\\\\n--- /dev/null\\\\\\\\n+++ b/Dataset/CSE20/processed/bounding_boxes_09361.txt\\\\\\\\n@@ -0,0 +1,35 @@\\\\\\\\n+Dataset/CSE20/processed/B160760CS_Vatsala/B160760CS_3.png 737 316 933 556\\\\\\\\n+Dataset/CSE20/processed/B160760CS_Vatsala/B160760CS_2.png 153 385 552 891\\\\\\\\n+Dataset/CSE20/processed/B160760CS_Vatsala/B160760CS_1.png 468 264 572 389\\\\\\\\n+Dataset/CSE20/processed/B160320ME_Shebin/B160320ME_1.png 330 315 631 688\\\\\\\\n+Dataset/CSE20/processed/B160320ME_Shebin/B160320ME_3.png 191 285 646 892\\\\\\\\n+Dataset/CSE20/processed/B160320ME_Shebin/B160320ME_2.png 440 427 806 846\\\\\\\\n+Dataset/CSE20/processed/B160688CS_Vishnu/B160688CS_3.png 725 1044 1618 2214\\\\\\\\n+Dataset/CSE20/processed/B160688CS_Vishnu/B160688CS_2.png 973 426 1711 1363\\\\\\\\n+Dataset/CSE20/processed/B160688CS_Vishnu/B160688CS_1.png 544 396 1107 1123\\\\\\\\n+Dataset/CSE20/processed/B160116CS_Aparna/B160116CS_3.png 152 200 367 450\\\\\\\\n+Dataset/CSE20/processed/B160116CS_Aparna/B160116CS_2.png 229 63 386 249\\\\\\\\n+Dataset/CSE20/processed/B160116CS_Aparna/B160116CS_1.png 284 560 332 614\\\\\\\\n+Dataset/CSE20/processed/B160229CS_Reema/B160229CS_3.png 313 266 494 511\\\\\\\\n+Dataset/CSE20/processed/B160229CS_Reema/B160229CS_2.png 144 216 315 427\\\\\\\\n+Dataset/CSE20/processed/B160229CS_Reema/B160229CS_1.png 234 384 322 495\\\\\\\\n+Dataset/CSE20/processed/B160118CS_Neeraja/B160118CS_1.png 130 170 396 484\\\\\\\\n+Dataset/CSE20/processed/B160118CS_Neeraja/B160118CS_3.png 429 535 561 696\\\\\\\\n+Dataset/CSE20/processed/B160118CS_Neeraja/B160118CS_2.png 262 59 490 329\\\\\\\\n+Dataset/CSE20/processed/B160213CS_Nileena/B160213CS_1.png 137 160 397 472\\\\\\\\n+Dataset/CSE20/processed/B160213CS_Nileena/B160213CS_2.png 265 271 455 492\\\\\\\\n+Dataset/CSE20/processed/B160213CS_Nileena/B160213CS_3.png 89 336 272 568\\\\\\\\n+Dataset/CSE20/processed/B160873CS_Naina/B160873CS_1.png 133 145 299 358\\\\\\\\n+Dataset/CSE20/processed/B160873CS_Naina/B160873CS_2.png 451 407 544 518\\\\\\\\n+Dataset/CSE20/processed/B160873CS_Naina/B160873CS_3.png 81 58 278 310\\\\\\\\n+Dataset/CSE20/processed/B160228CS_Vrindha/B160226CS_2.png 69 259 255 491\\\\\\\\n+Dataset/CSE20/processed/B160228CS_Vrindha/B160226CS_1.png 516 60 868 528\\\\\\\\n+Dataset/CSE20/processed/B160228CS_Vrindha/B160226CS_3.png 297 232 727 812\\\\\\\\n+Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_4.png 221 361 404 600\\\\\\\\n+Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_1.png 277 240 512 537\\\\\\\\n+Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_3.png 532 299 622 407\\\\\\\\n+Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_2.png 195 53 286 160\\\\\\\\n+Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_5.png 169 348 584 922\\\\\\\\n+Dataset/CSE20/processed/B160445CS_Sumalatha/B160445CS_1.png 219 73 363 261\\\\\\\\n+Dataset/CSE20/processed/B160445CS_Sumalatha/B160445CS_2.png 406 272 546 443\\\\\\\\n+Dataset/CSE20/processed/B160445CS_Sumalatha/B160445CS_3.png 433 616 484 674\\\\\\\\ndiff --git a/Dataset/CSE20/processed/bounding_boxes_19737.txt b/Dataset/CSE20/processed/bounding_boxes_19737.txt\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..e69de29\\\\\\\\ndiff --git a/Dataset/CSE20/processed/bounding_boxes_20330.txt b/Dataset/CSE20/processed/bounding_boxes_20330.txt\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..e69de29\\\\\\\\ndiff --git a/Dataset/CSE20/processed/bounding_boxes_28104.txt b/Dataset/CSE20/processed/bounding_boxes_28104.txt\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..dc58fca\\\\\\\\n--- /dev/null\\\\\\\\n+++ b/Dataset/CSE20/processed/bounding_boxes_28104.txt\\\\\\\\n@@ -0,0 +1,3 @@\\\\\\\\n+Dataset/CSE20/processed/Naina/naina2.png 451 407 544 518\\\\\\\\n+Dataset/CSE20/processed/Naina/naina3.png 81 58 278 310\\\\\\\\n+Dataset/CSE20/processed/Naina/naina1.png 133 145 299 358\\\\\\\\ndiff --git a/Dataset/CSE20/processed/bounding_boxes_30925.txt b/Dataset/CSE20/processed/bounding_boxes_30925.txt\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..e69de29\\\\\\\\ndiff --git a/Dataset/CSE20/processed/bounding_boxes_38733.txt b/Dataset/CSE20/processed/bounding_boxes_38733.txt\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..e69de29\\\\\\\\ndiff --git a/Dataset/CSE20/processed/bounding_boxes_40979.txt b/Dataset/CSE20/processed/bounding_boxes_40979.txt\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..e69de29\\\\\\\\ndiff --git a/Dataset/CSE20/processed/bounding_boxes_50376.txt b/Dataset/CSE20/processed/bounding_boxes_50376.txt\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..746e69e\\\\\\\\n--- /dev/null\\\\\\\\n+++ b/Dataset/CSE20/processed/bounding_boxes_50376.txt\\\\\\\\n@@ -0,0 +1,3 @@\\\\\\\\n+Dataset/CSE20/processed/Poothery/Poothery1.png 544 396 1107 1123\\\\\\\\n+Dataset/CSE20/processed/Poothery/Poothery2.png 973 426 1711 1363\\\\\\\\n+Dataset/CSE20/processed/Poothery/Poothery3.png 725 1044 1618 2214\\\\\\\\ndiff --git a/Dataset/CSE20/processed/bounding_boxes_51760.txt b/Dataset/CSE20/processed/bounding_boxes_51760.txt\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..e69de29\\\\\\\\ndiff --git a/Dataset/CSE20/processed/bounding_boxes_80845.txt b/Dataset/CSE20/processed/bounding_boxes_80845.txt\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..e69de29\\\\\\\\ndiff --git a/Dataset/CSE20/processed/bounding_boxes_95936.txt b/Dataset/CSE20/processed/bounding_boxes_95936.txt\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..5c0564d\\\\\\\\n--- /dev/null\\\\\\\\n+++ b/Dataset/CSE20/processed/bounding_boxes_95936.txt\\\\\\\\n@@ -0,0 +1,4 @@\\\\\\\\n+Dataset/CSE20/processed/B160471CS_Dheeraj/B160471CS_1.png 227 268 413 483\\\\\\\\n+Dataset/CSE20/processed/B160408CS_Ameen/B160408CS_3.png 241 337 448 614\\\\\\\\n+Dataset/CSE20/processed/B160408CS_Ameen/B160408CS_1.png 259 306 442 541\\\\\\\\n+Dataset/CSE20/processed/B160408CS_Ameen/B160408CS_2.png 312 148 530 417\\\\\\\\ndiff --git a/Dataset/CSE20/processed/revision_info.txt b/Dataset/CSE20/processed/revision_info.txt\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..5373839\\\\\\\\n--- /dev/null\\\\\\\\n+++ b/Dataset/CSE20/processed/revision_info.txt\\\\\\\\n@@ -0,0 +1,7 @@\\\\\\\\n+arguments: src/align_dataset_mtcnn.py Dataset/CSE20/raw/ Dataset/CSE20/processed/ --image_size 160 --margin 32 --random_order --gpu_memory_fraction 0.25\\\\\\\\n+--------------------\\\\\\\\n+tensorflow version: 1.7.0\\\\\\\\n+--------------------\\\\\\\\n+git hash: b\\\\\\\\\\\\\\\'096ed770f163957c1e56efa7feeb194773920f6e\\\\\\\\\\\\\\\'\\\\\\\\n+--------------------\\\\\\\\n+b\\\\\\\\\\\\\\\'diff --git a/src/align/align_dataset_mtcnn.py b/src/align/align_dataset_mtcnn.py\\\\\\\\\\\\\\\\nindex 7d5e735..21f1457 100644\\\\\\\\\\\\\\\\n--- a/src/align/align_dataset_mtcnn.py\\\\\\\\\\\\\\\\n+++ b/src/align/align_dataset_mtcnn.py\\\\\\\\\\\\\\\\n@@ -31,8 +31,8 @@ import os\\\\\\\\\\\\\\\\n import argparse\\\\\\\\\\\\\\\\n import tensorflow as tf\\\\\\\\\\\\\\\\n import numpy as np\\\\\\\\\\\\\\\\n-import facenet\\\\\\\\\\\\\\\\n-import align.detect_face\\\\\\\\\\\\\\\\n+import facenet.src.facenet as facenet   #changed\\\\\\\\\\\\\\\\n+import detect_face  #changed\\\\\\\\\\\\\\\\n import random\\\\\\\\\\\\\\\\n from time import sleep\\\\\\\\\\\\\\\\n \\\\\\\\\\\\\\\\ndiff --git a/src/align/detect_face.py b/src/align/detect_face.py\\\\\\\\\\\\\\\\nindex 7f98ca7..3806b33 100644\\\\\\\\\\\\\\\\n--- a/src/align/detect_face.py\\\\\\\\\\\\\\\\n+++ b/src/align/detect_face.py\\\\\\\\\\\\\\\\n@@ -82,7 +82,10 @@ class Network(object):\\\\\\\\\\\\\\\\n         session: The current TensorFlow session\\\\\\\\\\\\\\\\n         ignore_missing: If true, serialized weights for missing layers are ignored.\\\\\\\\\\\\\\\\n         """\\\\\\\\\\\\\\\\n+        np_load_old = np.load\\\\\\\\\\\\\\\\n+        np.load = lambda *a, **k: np_load_old(*a, allow_pickle=True, **k)\\\\\\\\\\\\\\\\n         data_dict = np.load(data_path, encoding=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'latin1\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\').item() #pylint: disable=no-member\\\\\\\\\\\\\\\\n+        np.load = np_load_old\\\\\\\\\\\\\\\\n \\\\\\\\\\\\\\\\n         for op_name in data_dict:\\\\\\\\\\\\\\\\n             with tf.variable_scope(op_name, reuse=True):\\\\\\\\\\\\\\\\ndiff --git a/src/facenet.py b/src/facenet.py\\\\\\\\\\\\\\\\nindex 0e05676..538b650 100644\\\\\\\\\\\\\\\\n--- a/src/facenet.py\\\\\\\\\\\\\\\\n+++ b/src/facenet.py\\\\\\\\\\\\\\\\n@@ -32,6 +32,7 @@ from subprocess import Popen, PIPE\\\\\\\\\\\\\\\\n import tensorflow as tf\\\\\\\\\\\\\\\\n import numpy as np\\\\\\\\\\\\\\\\n from scipy import misc\\\\\\\\\\\\\\\\n+import imageio\\\\\\\\\\\\\\\\n from sklearn.model_selection import KFold\\\\\\\\\\\\\\\\n from scipy import interpolate\\\\\\\\\\\\\\\\n from tensorflow.python.training import training\\\\\\\\\\\\\\\\n@@ -244,7 +245,7 @@ def load_data(image_paths, do_random_crop, do_random_flip, image_size, do_prewhi\\\\\\\\\\\\\\\\n     nrof_samples = len(image_paths)\\\\\\\\\\\\\\\\n     images = np.zeros((nrof_samples, image_size, image_size, 3))\\\\\\\\\\\\\\\\n     for i in range(nrof_samples):\\\\\\\\\\\\\\\\n-        img = misc.imread(image_paths[i])\\\\\\\\\\\\\\\\n+        img = imageio.imread(image_paths[i])\\\\\\\\\\\\\\\\n         if img.ndim == 2:\\\\\\\\\\\\\\\\n             img = to_rgb(img)\\\\\\\\\\\\\\\\n         if do_prewhiten:\\\\\\\\\\\\\\\'\\\\\\\\n\\\\\\\\\\\\\\\\ No newline at end of file\\\\\\\\ndiff --git a/Dataset/CSE20/raw/B160116CS_Aparna/B160116CS_1.jpeg b/Dataset/CSE20/raw/B160116CS_Aparna/B160116CS_1.jpeg\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..e23a8fc\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160116CS_Aparna/B160116CS_1.jpeg differ\\\\\\\\ndiff --git a/Dataset/CSE20/raw/B160116CS_Aparna/B160116CS_2.jpeg b/Dataset/CSE20/raw/B160116CS_Aparna/B160116CS_2.jpeg\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..f91beaf\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160116CS_Aparna/B160116CS_2.jpeg differ\\\\\\\\ndiff --git a/Dataset/CSE20/raw/B160116CS_Aparna/B160116CS_3.jpeg b/Dataset/CSE20/raw/B160116CS_Aparna/B160116CS_3.jpeg\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..c0bab07\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160116CS_Aparna/B160116CS_3.jpeg differ\\\\\\\\ndiff --git a/Dataset/CSE20/raw/B160118CS_Neeraja/B160118CS_1.jpeg b/Dataset/CSE20/raw/B160118CS_Neeraja/B160118CS_1.jpeg\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..d7870a6\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160118CS_Neeraja/B160118CS_1.jpeg differ\\\\\\\\ndiff --git a/Dataset/CSE20/raw/B160118CS_Neeraja/B160118CS_2.jpeg b/Dataset/CSE20/raw/B160118CS_Neeraja/B160118CS_2.jpeg\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..0af9819\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160118CS_Neeraja/B160118CS_2.jpeg differ\\\\\\\\ndiff --git a/Dataset/CSE20/raw/B160118CS_Neeraja/B160118CS_3.jpeg b/Dataset/CSE20/raw/B160118CS_Neeraja/B160118CS_3.jpeg\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..1fa8fb3\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160118CS_Neeraja/B160118CS_3.jpeg differ\\\\\\\\ndiff --git a/Dataset/CSE20/raw/B160213CS_Nileena/B160213CS_1.jpeg b/Dataset/CSE20/raw/B160213CS_Nileena/B160213CS_1.jpeg\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..0571099\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160213CS_Nileena/B160213CS_1.jpeg differ\\\\\\\\ndiff --git a/Dataset/CSE20/raw/B160213CS_Nileena/B160213CS_2.jpeg b/Dataset/CSE20/raw/B160213CS_Nileena/B160213CS_2.jpeg\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..b834bd2\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160213CS_Nileena/B160213CS_2.jpeg differ\\\\\\\\ndiff --git a/Dataset/CSE20/raw/B160213CS_Nileena/B160213CS_3.jpeg b/Dataset/CSE20/raw/B160213CS_Nileena/B160213CS_3.jpeg\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..6f90c78\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160213CS_Nileena/B160213CS_3.jpeg differ\\\\\\\\ndiff --git a/Dataset/CSE20/raw/B160228CS_Vrindha/B160226CS_1.jpeg b/Dataset/CSE20/raw/B160228CS_Vrindha/B160226CS_1.jpeg\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..cc17e86\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160228CS_Vrindha/B160226CS_1.jpeg differ\\\\\\\\ndiff --git a/Dataset/CSE20/raw/B160228CS_Vrindha/B160226CS_2.jpeg b/Dataset/CSE20/raw/B160228CS_Vrindha/B160226CS_2.jpeg\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..f05098d\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160228CS_Vrindha/B160226CS_2.jpeg differ\\\\\\\\ndiff --git a/Dataset/CSE20/raw/B160228CS_Vrindha/B160226CS_3.jpeg b/Dataset/CSE20/raw/B160228CS_Vrindha/B160226CS_3.jpeg\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..bd97e68\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160228CS_Vrindha/B160226CS_3.jpeg differ\\\\\\\\ndiff --git a/Dataset/CSE20/raw/B160229CS_Reema/B160229CS_1.jpeg b/Dataset/CSE20/raw/B160229CS_Reema/B160229CS_1.jpeg\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..03232a8\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160229CS_Reema/B160229CS_1.jpeg differ\\\\\\\\ndiff --git a/Dataset/CSE20/raw/B160229CS_Reema/B160229CS_2.jpeg b/Dataset/CSE20/raw/B160229CS_Reema/B160229CS_2.jpeg\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..f2f9a82\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160229CS_Reema/B160229CS_2.jpeg differ\\\\\\\\ndiff --git a/Dataset/CSE20/raw/B160229CS_Reema/B160229CS_3.jpeg b/Dataset/CSE20/raw/B160229CS_Reema/B160229CS_3.jpeg\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..caced02\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160229CS_Reema/B160229CS_3.jpeg differ\\\\\\\\ndiff --git a/Dataset/CSE20/raw/B160270CS_Lakshmi/B160270CS_1.jpeg b/Dataset/CSE20/raw/B160270CS_Lakshmi/B160270CS_1.jpeg\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..b6d3dea\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160270CS_Lakshmi/B160270CS_1.jpeg differ\\\\\\\\ndiff --git a/Dataset/CSE20/raw/B160270CS_Lakshmi/B160270CS_2.jpeg b/Dataset/CSE20/raw/B160270CS_Lakshmi/B160270CS_2.jpeg\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..26ac294\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160270CS_Lakshmi/B160270CS_2.jpeg differ\\\\\\\\ndiff --git a/Dataset/CSE20/raw/B160270CS_Lakshmi/B160270CS_3.jpeg b/Dataset/CSE20/raw/B160270CS_Lakshmi/B160270CS_3.jpeg\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..670eb75\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160270CS_Lakshmi/B160270CS_3.jpeg differ\\\\\\\\ndiff --git a/Dataset/CSE20/raw/B160270CS_Lakshmi/B160270CS_4.jpeg b/Dataset/CSE20/raw/B160270CS_Lakshmi/B160270CS_4.jpeg\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..5fab205\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160270CS_Lakshmi/B160270CS_4.jpeg differ\\\\\\\\ndiff --git a/Dataset/CSE20/raw/B160270CS_Lakshmi/B160270CS_5.jpeg b/Dataset/CSE20/raw/B160270CS_Lakshmi/B160270CS_5.jpeg\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..32abaf3\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160270CS_Lakshmi/B160270CS_5.jpeg differ\\\\\\\\ndiff --git a/Dataset/CSE20/raw/B160320ME_Shebin/B160320ME_1.jpeg b/Dataset/CSE20/raw/B160320ME_Shebin/B160320ME_1.jpeg\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..2fd54a5\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160320ME_Shebin/B160320ME_1.jpeg differ\\\\\\\\ndiff --git a/Dataset/CSE20/raw/B160320ME_Shebin/B160320ME_2.jpeg b/Dataset/CSE20/raw/B160320ME_Shebin/B160320ME_2.jpeg\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..1e896db\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160320ME_Shebin/B160320ME_2.jpeg differ\\\\\\\\ndiff --git a/Dataset/CSE20/raw/B160320ME_Shebin/B160320ME_3.jpeg b/Dataset/CSE20/raw/B160320ME_Shebin/B160320ME_3.jpeg\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..2587d2d\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160320ME_Shebin/B160320ME_3.jpeg differ\\\\\\\\ndiff --git a/Dataset/CSE20/raw/B160408CS_Ameen/B160408CS_1.jpeg b/Dataset/CSE20/raw/B160408CS_Ameen/B160408CS_1.jpeg\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..1fa10aa\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160408CS_Ameen/B160408CS_1.jpeg differ\\\\\\\\ndiff --git a/Dataset/CSE20/raw/B160408CS_Ameen/B160408CS_2.jpeg b/Dataset/CSE20/raw/B160408CS_Ameen/B160408CS_2.jpeg\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..96b4941\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160408CS_Ameen/B160408CS_2.jpeg differ\\\\\\\\ndiff --git a/Dataset/CSE20/raw/B160408CS_Ameen/B160408CS_3.jpeg b/Dataset/CSE20/raw/B160408CS_Ameen/B160408CS_3.jpeg\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..f275bc4\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160408CS_Ameen/B160408CS_3.jpeg differ\\\\\\\\ndiff --git a/Dataset/CSE20/raw/B160445CS_Sumalatha/B160445CS_1.jpeg b/Dataset/CSE20/raw/B160445CS_Sumalatha/B160445CS_1.jpeg\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..c317aa8\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160445CS_Sumalatha/B160445CS_1.jpeg differ\\\\\\\\ndiff --git a/Dataset/CSE20/raw/B160445CS_Sumalatha/B160445CS_2.jpeg b/Dataset/CSE20/raw/B160445CS_Sumalatha/B160445CS_2.jpeg\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..5ab2818\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160445CS_Sumalatha/B160445CS_2.jpeg differ\\\\\\\\ndiff --git a/Dataset/CSE20/raw/B160445CS_Sumalatha/B160445CS_3.jpeg b/Dataset/CSE20/raw/B160445CS_Sumalatha/B160445CS_3.jpeg\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..0159b52\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160445CS_Sumalatha/B160445CS_3.jpeg differ\\\\\\\\ndiff --git a/Dataset/CSE20/raw/B160471CS_Dheeraj/B160471CS_1.jpeg b/Dataset/CSE20/raw/B160471CS_Dheeraj/B160471CS_1.jpeg\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..9d6bec9\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160471CS_Dheeraj/B160471CS_1.jpeg differ\\\\\\\\ndiff --git a/Dataset/CSE20/raw/B160688CS_Vishnu/B160688CS_1.jpg b/Dataset/CSE20/raw/B160688CS_Vishnu/B160688CS_1.jpg\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..537a4c0\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160688CS_Vishnu/B160688CS_1.jpg differ\\\\\\\\ndiff --git a/Dataset/CSE20/raw/B160688CS_Vishnu/B160688CS_2.jpg b/Dataset/CSE20/raw/B160688CS_Vishnu/B160688CS_2.jpg\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..0442b3d\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160688CS_Vishnu/B160688CS_2.jpg differ\\\\\\\\ndiff --git a/Dataset/CSE20/raw/B160688CS_Vishnu/B160688CS_3.jpeg b/Dataset/CSE20/raw/B160688CS_Vishnu/B160688CS_3.jpeg\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..460d134\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160688CS_Vishnu/B160688CS_3.jpeg differ\\\\\\\\ndiff --git a/Dataset/CSE20/raw/B160760CS_Vatsala/B160760CS_1.jpeg b/Dataset/CSE20/raw/B160760CS_Vatsala/B160760CS_1.jpeg\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..2856b8e\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160760CS_Vatsala/B160760CS_1.jpeg differ\\\\\\\\ndiff --git a/Dataset/CSE20/raw/B160760CS_Vatsala/B160760CS_2.jpeg b/Dataset/CSE20/raw/B160760CS_Vatsala/B160760CS_2.jpeg\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..76e5ceb\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160760CS_Vatsala/B160760CS_2.jpeg differ\\\\\\\\ndiff --git a/Dataset/CSE20/raw/B160760CS_Vatsala/B160760CS_3.jpeg b/Dataset/CSE20/raw/B160760CS_Vatsala/B160760CS_3.jpeg\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..f43a8a7\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160760CS_Vatsala/B160760CS_3.jpeg differ\\\\\\\\ndiff --git a/Dataset/CSE20/raw/B160873CS_Naina/B160873CS_1.jpg b/Dataset/CSE20/raw/B160873CS_Naina/B160873CS_1.jpg\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..0c66c88\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160873CS_Naina/B160873CS_1.jpg differ\\\\\\\\ndiff --git a/Dataset/CSE20/raw/B160873CS_Naina/B160873CS_2.jpg b/Dataset/CSE20/raw/B160873CS_Naina/B160873CS_2.jpg\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..ad8c724\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160873CS_Naina/B160873CS_2.jpg differ\\\\\\\\ndiff --git a/Dataset/CSE20/raw/B160873CS_Naina/B160873CS_3.png b/Dataset/CSE20/raw/B160873CS_Naina/B160873CS_3.png\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..361493f\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160873CS_Naina/B160873CS_3.png differ\\\\\\\\ndiff --git a/Models/CSE20/CSE20.pkl b/Models/CSE20/CSE20.pkl\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..3793ef7\\\\\\\\nBinary files /dev/null and b/Models/CSE20/CSE20.pkl differ\\\\\\\\ndiff --git a/Models/facenet/20180402-114759.pb b/Models/facenet/20180402-114759.pb\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..39b4ed7\\\\\\\\nBinary files /dev/null and b/Models/facenet/20180402-114759.pb differ\\\\\\\\ndiff --git a/Models/facenet/model-20180402-114759.ckpt-275.data-00000-of-00001 b/Models/facenet/model-20180402-114759.ckpt-275.data-00000-of-00001\\\\\\\\nnew file mode 100755\\\\\\\\nindex 0000000..6160198\\\\\\\\nBinary files /dev/null and b/Models/facenet/model-20180402-114759.ckpt-275.data-00000-of-00001 differ\\\\\\\\ndiff --git a/Models/facenet/model-20180402-114759.ckpt-275.index b/Models/facenet/model-20180402-114759.ckpt-275.index\\\\\\\\nnew file mode 100755\\\\\\\\nindex 0000000..e2b346c\\\\\\\\nBinary files /dev/null and b/Models/facenet/model-20180402-114759.ckpt-275.index differ\\\\\\\\ndiff --git a/Models/facenet/model-20180402-114759.meta b/Models/facenet/model-20180402-114759.meta\\\\\\\\nnew file mode 100755\\\\\\\\nindex 0000000..abffaef\\\\\\\\nBinary files /dev/null and b/Models/facenet/model-20180402-114759.meta differ\\\\\\\\ndiff --git a/src/align/align_dataset_mtcnn.py b/src/align/align_dataset_mtcnn.py\\\\\\\\nindex 7d5e735..21f1457 100644\\\\\\\\n--- a/src/align/align_dataset_mtcnn.py\\\\\\\\n+++ b/src/align/align_dataset_mtcnn.py\\\\\\\\n@@ -31,8 +31,8 @@ import os\\\\\\\\n import argparse\\\\\\\\n import tensorflow as tf\\\\\\\\n import numpy as np\\\\\\\\n-import facenet\\\\\\\\n-import align.detect_face\\\\\\\\n+import facenet.src.facenet as facenet   #changed\\\\\\\\n+import detect_face  #changed\\\\\\\\n import random\\\\\\\\n from time import sleep\\\\\\\\n \\\\\\\\ndiff --git a/src/align/detect_face.py b/src/align/detect_face.py\\\\\\\\nindex 7f98ca7..3806b33 100644\\\\\\\\n--- a/src/align/detect_face.py\\\\\\\\n+++ b/src/align/detect_face.py\\\\\\\\n@@ -82,7 +82,10 @@ class Network(object):\\\\\\\\n         session: The current TensorFlow session\\\\\\\\n         ignore_missing: If true, serialized weights for missing layers are ignored.\\\\\\\\n         """\\\\\\\\n+        np_load_old = np.load\\\\\\\\n+        np.load = lambda *a, **k: np_load_old(*a, allow_pickle=True, **k)\\\\\\\\n         data_dict = np.load(data_path, encoding=\\\\\\\\\\\\\\\'latin1\\\\\\\\\\\\\\\').item() #pylint: disable=no-member\\\\\\\\n+        np.load = np_load_old\\\\\\\\n \\\\\\\\n         for op_name in data_dict:\\\\\\\\n             with tf.variable_scope(op_name, reuse=True):\\\\\\\\ndiff --git a/src/align_dataset_mtcnn.py b/src/align_dataset_mtcnn.py\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..2c2acc4\\\\\\\\n--- /dev/null\\\\\\\\n+++ b/src/align_dataset_mtcnn.py\\\\\\\\n@@ -0,0 +1,161 @@\\\\\\\\n+"""Performs face alignment and stores face thumbnails in the output directory."""\\\\\\\\n+# MIT License\\\\\\\\n+# \\\\\\\\n+# Copyright (c) 2016 David Sandberg\\\\\\\\n+# \\\\\\\\n+# Permission is hereby granted, free of charge, to any person obtaining a copy\\\\\\\\n+# of this software and associated documentation files (the "Software"), to deal\\\\\\\\n+# in the Software without restriction, including without limitation the rights\\\\\\\\n+# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\\\\\\\n+# copies of the Software, and to permit persons to whom the Software is\\\\\\\\n+# furnished to do so, subject to the following conditions:\\\\\\\\n+# \\\\\\\\n+# The above copyright notice and this permission notice shall be included in all\\\\\\\\n+# copies or substantial portions of the Software.\\\\\\\\n+# \\\\\\\\n+# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\\\\\\\n+# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\\\\\\\n+# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\\\\\\\n+# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\\\\\\\n+# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\\\\\\\n+# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\\\\\\\n+# SOFTWARE.\\\\\\\\n+\\\\\\\\n+from __future__ import absolute_import\\\\\\\\n+from __future__ import division\\\\\\\\n+from __future__ import print_function\\\\\\\\n+\\\\\\\\n+from scipy import misc\\\\\\\\n+import imageio #for imread since it\\\\\\\\\\\\\\\'s depricated in scipy.misc\\\\\\\\n+import skimage #for imresize since it\\\\\\\\\\\\\\\'s depricated in scipy.misc\\\\\\\\n+import sys\\\\\\\\n+import os\\\\\\\\n+import argparse\\\\\\\\n+import tensorflow as tf\\\\\\\\n+import numpy as np\\\\\\\\n+import facenet\\\\\\\\n+import align.detect_face\\\\\\\\n+import random\\\\\\\\n+from time import sleep\\\\\\\\n+\\\\\\\\n+def main(args):\\\\\\\\n+    sleep(random.random())\\\\\\\\n+    output_dir = os.path.expanduser(args.output_dir)\\\\\\\\n+    if not os.path.exists(output_dir):\\\\\\\\n+        os.makedirs(output_dir)\\\\\\\\n+    # Store some git revision info in a text file in the log directory\\\\\\\\n+    src_path,_ = os.path.split(os.path.realpath(__file__))\\\\\\\\n+    facenet.store_revision_info(src_path, output_dir, \\\\\\\\\\\\\\\' \\\\\\\\\\\\\\\'.join(sys.argv))\\\\\\\\n+    dataset = facenet.get_dataset(args.input_dir)\\\\\\\\n+    \\\\\\\\n+    print(\\\\\\\\\\\\\\\'Creating networks and loading parameters\\\\\\\\\\\\\\\')\\\\\\\\n+    \\\\\\\\n+    with tf.Graph().as_default():\\\\\\\\n+        gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=args.gpu_memory_fraction)\\\\\\\\n+        sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options, log_device_placement=False))\\\\\\\\n+        with sess.as_default():\\\\\\\\n+            pnet, rnet, onet = align.detect_face.create_mtcnn(sess, None)\\\\\\\\n+    \\\\\\\\n+    minsize = 20 # minimum size of face\\\\\\\\n+    threshold = [ 0.6, 0.7, 0.7 ]  # three steps\\\\\\\\\\\\\\\'s threshold\\\\\\\\n+    factor = 0.709 # scale factor\\\\\\\\n+\\\\\\\\n+    # Add a random key to the filename to allow alignment using multiple processes\\\\\\\\n+    random_key = np.random.randint(0, high=99999)\\\\\\\\n+    bounding_boxes_filename = os.path.join(output_dir, \\\\\\\\\\\\\\\'bounding_boxes_%05d.txt\\\\\\\\\\\\\\\' % random_key)\\\\\\\\n+    \\\\\\\\n+    with open(bounding_boxes_filename, "w") as text_file:\\\\\\\\n+        nrof_images_total = 0\\\\\\\\n+        nrof_successfully_aligned = 0\\\\\\\\n+        if args.random_order:\\\\\\\\n+            random.shuffle(dataset)\\\\\\\\n+        for cls in dataset:\\\\\\\\n+            output_class_dir = os.path.join(output_dir, cls.name)\\\\\\\\n+            if not os.path.exists(output_class_dir):\\\\\\\\n+                os.makedirs(output_class_dir)\\\\\\\\n+                if args.random_order:\\\\\\\\n+                    random.shuffle(cls.image_paths)\\\\\\\\n+            for image_path in cls.image_paths:\\\\\\\\n+                nrof_images_total += 1\\\\\\\\n+                filename = os.path.splitext(os.path.split(image_path)[1])[0]\\\\\\\\n+                output_filename = os.path.join(output_class_dir, filename+\\\\\\\\\\\\\\\'.png\\\\\\\\\\\\\\\')\\\\\\\\n+                print(image_path)\\\\\\\\n+                if not os.path.exists(output_filename):\\\\\\\\n+                    try:\\\\\\\\n+                        img = imageio.imread(image_path)\\\\\\\\n+                    except (IOError, ValueError, IndexError) as e:\\\\\\\\n+                        errorMessage = \\\\\\\\\\\\\\\'{}: {}\\\\\\\\\\\\\\\'.format(image_path, e)\\\\\\\\n+                        print(errorMessage)\\\\\\\\n+                    else:\\\\\\\\n+                        if img.ndim<2:\\\\\\\\n+                            print(\\\\\\\\\\\\\\\'Unable to align "%s"\\\\\\\\\\\\\\\' % image_path)\\\\\\\\n+                            text_file.write(\\\\\\\\\\\\\\\'%s\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\' % (output_filename))\\\\\\\\n+                            continue\\\\\\\\n+                        if img.ndim == 2:\\\\\\\\n+                            img = facenet.to_rgb(img)\\\\\\\\n+                        img = img[:,:,0:3]\\\\\\\\n+    \\\\\\\\n+                        bounding_boxes, _ = align.detect_face.detect_face(img, minsize, pnet, rnet, onet, threshold, factor)\\\\\\\\n+                        nrof_faces = bounding_boxes.shape[0]\\\\\\\\n+                        if nrof_faces>0:\\\\\\\\n+                            det = bounding_boxes[:,0:4]\\\\\\\\n+                            det_arr = []\\\\\\\\n+                            img_size = np.asarray(img.shape)[0:2]\\\\\\\\n+                            if nrof_faces>1:\\\\\\\\n+                                if args.detect_multiple_faces:\\\\\\\\n+                                    for i in range(nrof_faces):\\\\\\\\n+                                        det_arr.append(np.squeeze(det[i]))\\\\\\\\n+                                else:\\\\\\\\n+                                    bounding_box_size = (det[:,2]-det[:,0])*(det[:,3]-det[:,1])\\\\\\\\n+                                    img_center = img_size / 2\\\\\\\\n+                                    offsets = np.vstack([ (det[:,0]+det[:,2])/2-img_center[1], (det[:,1]+det[:,3])/2-img_center[0] ])\\\\\\\\n+                                    offset_dist_squared = np.sum(np.power(offsets,2.0),0)\\\\\\\\n+                                    index = np.argmax(bounding_box_size-offset_dist_squared*2.0) # some extra weight on the centering\\\\\\\\n+                                    det_arr.append(det[index,:])\\\\\\\\n+                            else:\\\\\\\\n+                                det_arr.append(np.squeeze(det))\\\\\\\\n+\\\\\\\\n+                            for i, det in enumerate(det_arr):\\\\\\\\n+                                det = np.squeeze(det)\\\\\\\\n+                                bb = np.zeros(4, dtype=np.int32)\\\\\\\\n+                                bb[0] = np.maximum(det[0]-args.margin/2, 0)\\\\\\\\n+                                bb[1] = np.maximum(det[1]-args.margin/2, 0)\\\\\\\\n+                                bb[2] = np.minimum(det[2]+args.margin/2, img_size[1])\\\\\\\\n+                                bb[3] = np.minimum(det[3]+args.margin/2, img_size[0])\\\\\\\\n+                                cropped = img[bb[1]:bb[3],bb[0]:bb[2],:]\\\\\\\\n+                                scaled = skimage.transform.resize(cropped, (args.image_size, args.image_size))\\\\\\\\n+                                nrof_successfully_aligned += 1\\\\\\\\n+                                filename_base, file_extension = os.path.splitext(output_filename)\\\\\\\\n+                                if args.detect_multiple_faces:\\\\\\\\n+                                    output_filename_n = "{}_{}{}".format(filename_base, i, file_extension)\\\\\\\\n+                                else:\\\\\\\\n+                                    output_filename_n = "{}{}".format(filename_base, file_extension)\\\\\\\\n+                                imageio.imwrite(output_filename_n, scaled)\\\\\\\\n+                                text_file.write(\\\\\\\\\\\\\\\'%s %d %d %d %d\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\' % (output_filename_n, bb[0], bb[1], bb[2], bb[3]))\\\\\\\\n+                        else:\\\\\\\\n+                            print(\\\\\\\\\\\\\\\'Unable to align "%s"\\\\\\\\\\\\\\\' % image_path)\\\\\\\\n+                            text_file.write(\\\\\\\\\\\\\\\'%s\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\' % (output_filename))\\\\\\\\n+                            \\\\\\\\n+    print(\\\\\\\\\\\\\\\'Total number of images: %d\\\\\\\\\\\\\\\' % nrof_images_total)\\\\\\\\n+    print(\\\\\\\\\\\\\\\'Number of successfully aligned images: %d\\\\\\\\\\\\\\\' % nrof_successfully_aligned)\\\\\\\\n+            \\\\\\\\n+\\\\\\\\n+def parse_arguments(argv):\\\\\\\\n+    parser = argparse.ArgumentParser()\\\\\\\\n+    \\\\\\\\n+    parser.add_argument(\\\\\\\\\\\\\\\'input_dir\\\\\\\\\\\\\\\', type=str, help=\\\\\\\\\\\\\\\'Directory with unaligned images.\\\\\\\\\\\\\\\')\\\\\\\\n+    parser.add_argument(\\\\\\\\\\\\\\\'output_dir\\\\\\\\\\\\\\\', type=str, help=\\\\\\\\\\\\\\\'Directory with aligned face thumbnails.\\\\\\\\\\\\\\\')\\\\\\\\n+    parser.add_argument(\\\\\\\\\\\\\\\'--image_size\\\\\\\\\\\\\\\', type=int,\\\\\\\\n+        help=\\\\\\\\\\\\\\\'Image size (height, width) in pixels.\\\\\\\\\\\\\\\', default=182)\\\\\\\\n+    parser.add_argument(\\\\\\\\\\\\\\\'--margin\\\\\\\\\\\\\\\', type=int,\\\\\\\\n+        help=\\\\\\\\\\\\\\\'Margin for the crop around the bounding box (height, width) in pixels.\\\\\\\\\\\\\\\', default=44)\\\\\\\\n+    parser.add_argument(\\\\\\\\\\\\\\\'--random_order\\\\\\\\\\\\\\\', \\\\\\\\n+        help=\\\\\\\\\\\\\\\'Shuffles the order of images to enable alignment using multiple processes.\\\\\\\\\\\\\\\', action=\\\\\\\\\\\\\\\'store_true\\\\\\\\\\\\\\\')\\\\\\\\n+    parser.add_argument(\\\\\\\\\\\\\\\'--gpu_memory_fraction\\\\\\\\\\\\\\\', type=float,\\\\\\\\n+        help=\\\\\\\\\\\\\\\'Upper bound on the amount of GPU memory that will be used by the process.\\\\\\\\\\\\\\\', default=1.0)\\\\\\\\n+    parser.add_argument(\\\\\\\\\\\\\\\'--detect_multiple_faces\\\\\\\\\\\\\\\', type=bool,\\\\\\\\n+                        help=\\\\\\\\\\\\\\\'Detect and align multiple faces per image.\\\\\\\\\\\\\\\', default=False)\\\\\\\\n+    return parser.parse_args(argv)\\\\\\\\n+\\\\\\\\n+if __name__ == \\\\\\\\\\\\\\\'__main__\\\\\\\\\\\\\\\':\\\\\\\\n+    main(parse_arguments(sys.argv[1:]))\\\\\\\\ndiff --git a/src/faceRec.py b/src/faceRec.py\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..a5531a2\\\\\\\\n--- /dev/null\\\\\\\\n+++ b/src/faceRec.py\\\\\\\\n@@ -0,0 +1,117 @@\\\\\\\\n+from __future__ import absolute_import\\\\\\\\n+from __future__ import division\\\\\\\\n+from __future__ import print_function\\\\\\\\n+\\\\\\\\n+import tensorflow as tf\\\\\\\\n+import argparse\\\\\\\\n+import facenet\\\\\\\\n+import os\\\\\\\\n+import sys\\\\\\\\n+import math\\\\\\\\n+import pickle\\\\\\\\n+import align.detect_face\\\\\\\\n+import numpy as np\\\\\\\\n+import cv2\\\\\\\\n+import collections\\\\\\\\n+from sklearn.svm import SVC\\\\\\\\n+\\\\\\\\n+\\\\\\\\n+def main():\\\\\\\\n+    parser = argparse.ArgumentParser()\\\\\\\\n+    parser.add_argument(\\\\\\\\\\\\\\\'--path\\\\\\\\\\\\\\\', help=\\\\\\\\\\\\\\\'Path of the video you want to test on.\\\\\\\\\\\\\\\', default=0)\\\\\\\\n+    args = parser.parse_args()\\\\\\\\n+\\\\\\\\n+    MINSIZE = 20\\\\\\\\n+    THRESHOLD = [0.6, 0.7, 0.7]\\\\\\\\n+    FACTOR = 0.709\\\\\\\\n+    IMAGE_SIZE = 182\\\\\\\\n+    INPUT_IMAGE_SIZE = 160\\\\\\\\n+    CLASSIFIER_PATH = \\\\\\\\\\\\\\\'Models/CSE20/CSE20.pkl\\\\\\\\\\\\\\\'\\\\\\\\n+    VIDEO_PATH = args.path\\\\\\\\n+    FACENET_MODEL_PATH = \\\\\\\\\\\\\\\'Models/facenet/20180402-114759.pb\\\\\\\\\\\\\\\'\\\\\\\\n+\\\\\\\\n+    # Load The Custom Classifier\\\\\\\\n+    with open(CLASSIFIER_PATH, \\\\\\\\\\\\\\\'rb\\\\\\\\\\\\\\\') as file:\\\\\\\\n+        model, class_names = pickle.load(file)\\\\\\\\n+    print("Custom Classifier, Successfully loaded")\\\\\\\\n+\\\\\\\\n+    with tf.Graph().as_default():\\\\\\\\n+\\\\\\\\n+        gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.6)\\\\\\\\n+        sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options, log_device_placement=False))\\\\\\\\n+\\\\\\\\n+        with sess.as_default():\\\\\\\\n+\\\\\\\\n+            # Load the model\\\\\\\\n+            print(\\\\\\\\\\\\\\\'Loading feature extraction model\\\\\\\\\\\\\\\')\\\\\\\\n+            facenet.load_model(FACENET_MODEL_PATH)\\\\\\\\n+\\\\\\\\n+            # Get input and output tensors\\\\\\\\n+            images_placeholder = tf.get_default_graph().get_tensor_by_name("input:0")\\\\\\\\n+            embeddings = tf.get_default_graph().get_tensor_by_name("embeddings:0")\\\\\\\\n+            phase_train_placeholder = tf.get_default_graph().get_tensor_by_name("phase_train:0")\\\\\\\\n+            embedding_size = embeddings.get_shape()[1]\\\\\\\\n+\\\\\\\\n+            pnet, rnet, onet = align.detect_face.create_mtcnn(sess, "./src/align")\\\\\\\\n+\\\\\\\\n+            people_detected = set()\\\\\\\\n+            person_detected = collections.Counter()\\\\\\\\n+\\\\\\\\n+            cap = cv2.VideoCapture(VIDEO_PATH)\\\\\\\\n+\\\\\\\\n+            while (cap.isOpened()):\\\\\\\\n+                ret, frame = cap.read()\\\\\\\\n+\\\\\\\\n+                bounding_boxes, _ = align.detect_face.detect_face(frame, MINSIZE, pnet, rnet, onet, THRESHOLD, FACTOR)\\\\\\\\n+\\\\\\\\n+                faces_found = bounding_boxes.shape[0]\\\\\\\\n+                try:\\\\\\\\n+                    if faces_found > 0:\\\\\\\\n+                        det = bounding_boxes[:, 0:4]\\\\\\\\n+                        bb = np.zeros((faces_found, 4), dtype=np.int32)\\\\\\\\n+                        for i in range(faces_found):\\\\\\\\n+                            bb[i][0] = det[i][0]\\\\\\\\n+                            bb[i][1] = det[i][1]\\\\\\\\n+                            bb[i][2] = det[i][2]\\\\\\\\n+                            bb[i][3] = det[i][3]\\\\\\\\n+\\\\\\\\n+                            cropped = frame[bb[i][1]:bb[i][3], bb[i][0]:bb[i][2], :]\\\\\\\\n+                            scaled = cv2.resize(cropped, (INPUT_IMAGE_SIZE, INPUT_IMAGE_SIZE),\\\\\\\\n+                                                interpolation=cv2.INTER_CUBIC)\\\\\\\\n+                            scaled = facenet.prewhiten(scaled)\\\\\\\\n+                            scaled_reshape = scaled.reshape(-1, INPUT_IMAGE_SIZE, INPUT_IMAGE_SIZE, 3)\\\\\\\\n+                            feed_dict = {images_placeholder: scaled_reshape, phase_train_placeholder: False}\\\\\\\\n+                            emb_array = sess.run(embeddings, feed_dict=feed_dict)\\\\\\\\n+                            predictions = model.predict_proba(emb_array)\\\\\\\\n+                            best_class_indices = np.argmax(predictions, axis=1)\\\\\\\\n+                            best_class_probabilities = predictions[\\\\\\\\n+                                np.arange(len(best_class_indices)), best_class_indices]\\\\\\\\n+                            best_name = class_names[best_class_indices[0]]\\\\\\\\n+                            print("Name: {}, Probability: {}".format(best_name, best_class_probabilities))\\\\\\\\n+\\\\\\\\n+                            cv2.rectangle(frame, (bb[i][0], bb[i][1]), (bb[i][2], bb[i][3]), (0, 255, 0), 2)\\\\\\\\n+                            text_x = bb[i][0]\\\\\\\\n+                            text_y = bb[i][3] + 20\\\\\\\\n+\\\\\\\\n+                            if best_class_probabilities > 0.15:\\\\\\\\n+                                name = class_names[best_class_indices[0]]\\\\\\\\n+                            else:\\\\\\\\n+                                name = "Unknown"\\\\\\\\n+                            cv2.putText(frame, name, (text_x, text_y), cv2.FONT_HERSHEY_COMPLEX_SMALL,\\\\\\\\n+                                        1, (255, 255, 255), thickness=1, lineType=2)\\\\\\\\n+                            cv2.putText(frame, str(round(best_class_probabilities[0], 3)), (text_x, text_y + 17),\\\\\\\\n+                                        cv2.FONT_HERSHEY_COMPLEX_SMALL,\\\\\\\\n+                                        1, (255, 255, 255), thickness=1, lineType=2)\\\\\\\\n+                            person_detected[best_name] += 1\\\\\\\\n+                except:\\\\\\\\n+                    pass\\\\\\\\n+\\\\\\\\n+                cv2.imshow(\\\\\\\\\\\\\\\'Face Recognition\\\\\\\\\\\\\\\', frame)\\\\\\\\n+                if cv2.waitKey(1) & 0xFF == ord(\\\\\\\\\\\\\\\'q\\\\\\\\\\\\\\\'):\\\\\\\\n+                    break\\\\\\\\n+\\\\\\\\n+            cap.release()\\\\\\\\n+            cv2.destroyAllWindows()\\\\\\\\n+\\\\\\\\n+\\\\\\\\n+main()\\\\\\\\n\\\\\\\\\\\\\\\\ No newline at end of file\\\\\\\\ndiff --git a/src/facenet.py b/src/facenet.py\\\\\\\\nindex 0e05676..538b650 100644\\\\\\\\n--- a/src/facenet.py\\\\\\\\n+++ b/src/facenet.py\\\\\\\\n@@ -32,6 +32,7 @@ from subprocess import Popen, PIPE\\\\\\\\n import tensorflow as tf\\\\\\\\n import numpy as np\\\\\\\\n from scipy import misc\\\\\\\\n+import imageio\\\\\\\\n from sklearn.model_selection import KFold\\\\\\\\n from scipy import interpolate\\\\\\\\n from tensorflow.python.training import training\\\\\\\\n@@ -244,7 +245,7 @@ def load_data(image_paths, do_random_crop, do_random_flip, image_size, do_prewhi\\\\\\\\n     nrof_samples = len(image_paths)\\\\\\\\n     images = np.zeros((nrof_samples, image_size, image_size, 3))\\\\\\\\n     for i in range(nrof_samples):\\\\\\\\n-        img = misc.imread(image_paths[i])\\\\\\\\n+        img = imageio.imread(image_paths[i])\\\\\\\\n         if img.ndim == 2:\\\\\\\\n             img = to_rgb(img)\\\\\\\\n         if do_prewhiten:\\\\\\\'\\\\n-\\\\\\\\ No newline at end of file\\\\n-diff --git a/main/Dataset/CSE20/raw/B160116CS_Aparna/B160116CS_1.jpeg b/main/Dataset/CSE20/raw/B160116CS_Aparna/B160116CS_1.jpeg\\\\n-index e23a8fc..d50e775 100644\\\\n-Binary files a/main/Dataset/CSE20/raw/B160116CS_Aparna/B160116CS_1.jpeg and b/main/Dataset/CSE20/raw/B160116CS_Aparna/B160116CS_1.jpeg differ\\\\n-diff --git a/main/README.md b/main/README.md\\\\n-index 9220d20..baaeced 100644\\\\n---- a/main/README.md\\\\n-+++ b/main/README.md\\\\n-@@ -53,3 +53,4 @@ A couple of pretrained models are provided. They are trained using softmax loss\\\\n- \\\\n- ## Performance\\\\n- The accuracy on LFW for the model [20180402-114759](https://drive.google.com/open?id=1EXPBSXwTaqrSC0OhUdXNmKSh9qJUQ55-) is 0.99650+-0.00252. A description of how to run the test can be found on the page [Validate on LFW](https://github.com/davidsandberg/facenet/wiki/Validate-on-lfw). Note that the input images to the model need to be standardized using fixed image standardization (use the option `--use_fixed_image_standardization` when running e.g. `validate_on_lfw.py`).\\\\n-+\\\\n-diff --git a/main/requirements.txt b/main/requirements.txt\\\\n-index b7418c9..167b725 100644\\\\n---- a/main/requirements.txt\\\\n-+++ b/main/requirements.txt\\\\n-@@ -7,3 +7,5 @@ matplotlib\\\\n- Pillow\\\\n- requests\\\\n- psutil\\\\n-+imageio\\\\n-+scikit-image\\\\n\\\\\\\\ No newline at end of file\\\\n+b\\\\\\\'diff --git a/main/Dataset/CSE20/processed/revision_info.txt b/main/Dataset/CSE20/processed/revision_info.txt\\\\\\\\nindex 3f5e408..2e9cb43 100644\\\\\\\\n--- a/main/Dataset/CSE20/processed/revision_info.txt\\\\\\\\n+++ b/main/Dataset/CSE20/processed/revision_info.txt\\\\\\\\n@@ -1,287 +1,7 @@\\\\\\\\n-arguments: src/align_dataset_mtcnn.py ./Dataset/CSE20/raw/ ./Dataset/CSE20/processed --image_size 160 --margin 32 --random_order --gpu_memory_fraction 0.25\\\\\\\\n+arguments: src\\\\\\\\\\\\\\\\align_dataset_mtcnn.py Dataset\\\\\\\\\\\\\\\\CSE20\\\\\\\\\\\\\\\\raw Dataset\\\\\\\\\\\\\\\\CSE20\\\\\\\\\\\\\\\\processed --image_size 160 --margin 32 --random_order --gpu_memory_fraction 0.25\\\\\\\\n --------------------\\\\\\\\n-tensorflow version: 1.7.0\\\\\\\\n+tensorflow version: 1.13.1\\\\\\\\n --------------------\\\\\\\\n-git hash: e5ea2411c6d8091a0c3ca0d6fe3c8be74790c9ab\\\\\\\\n+git hash: b\\\\\\\\\\\\\\\'3d0f9267137d67e77a29f907665b38c8bb4dcd1d\\\\\\\\\\\\\\\'\\\\\\\\n --------------------\\\\\\\\n-diff --git a/main/Dataset/CSE20/processed/B160116CS_Aparna/B160116CS_1.png b/main/Dataset/CSE20/processed/B160116CS_Aparna/B160116CS_1.png\\\\\\\\n-deleted file mode 100644\\\\\\\\n-index f1db83f..0000000\\\\\\\\n-Binary files a/main/Dataset/CSE20/processed/B160116CS_Aparna/B160116CS_1.png and /dev/null differ\\\\\\\\n-diff --git a/main/Dataset/CSE20/processed/B160116CS_Aparna/B160116CS_2.png b/main/Dataset/CSE20/processed/B160116CS_Aparna/B160116CS_2.png\\\\\\\\n-deleted file mode 100644\\\\\\\\n-index 45449c3..0000000\\\\\\\\n-Binary files a/main/Dataset/CSE20/processed/B160116CS_Aparna/B160116CS_2.png and /dev/null differ\\\\\\\\n-diff --git a/main/Dataset/CSE20/processed/B160116CS_Aparna/B160116CS_3.png b/main/Dataset/CSE20/processed/B160116CS_Aparna/B160116CS_3.png\\\\\\\\n-deleted file mode 100644\\\\\\\\n-index 9813f9f..0000000\\\\\\\\n-Binary files a/main/Dataset/CSE20/processed/B160116CS_Aparna/B160116CS_3.png and /dev/null differ\\\\\\\\n-diff --git a/main/Dataset/CSE20/processed/B160118CS_Neeraja/B160118CS_1.png b/main/Dataset/CSE20/processed/B160118CS_Neeraja/B160118CS_1.png\\\\\\\\n-deleted file mode 100644\\\\\\\\n-index fb52346..0000000\\\\\\\\n-Binary files a/main/Dataset/CSE20/processed/B160118CS_Neeraja/B160118CS_1.png and /dev/null differ\\\\\\\\n-diff --git a/main/Dataset/CSE20/processed/B160118CS_Neeraja/B160118CS_2.png b/main/Dataset/CSE20/processed/B160118CS_Neeraja/B160118CS_2.png\\\\\\\\n-deleted file mode 100644\\\\\\\\n-index 3a04b13..0000000\\\\\\\\n-Binary files a/main/Dataset/CSE20/processed/B160118CS_Neeraja/B160118CS_2.png and /dev/null differ\\\\\\\\n-diff --git a/main/Dataset/CSE20/processed/B160118CS_Neeraja/B160118CS_3.png b/main/Dataset/CSE20/processed/B160118CS_Neeraja/B160118CS_3.png\\\\\\\\n-deleted file mode 100644\\\\\\\\n-index f7c2d61..0000000\\\\\\\\n-Binary files a/main/Dataset/CSE20/processed/B160118CS_Neeraja/B160118CS_3.png and /dev/null differ\\\\\\\\n-diff --git a/main/Dataset/CSE20/processed/B160213CS_Nileena/B160213CS_1.png b/main/Dataset/CSE20/processed/B160213CS_Nileena/B160213CS_1.png\\\\\\\\n-deleted file mode 100644\\\\\\\\n-index 5affd0e..0000000\\\\\\\\n-Binary files a/main/Dataset/CSE20/processed/B160213CS_Nileena/B160213CS_1.png and /dev/null differ\\\\\\\\n-diff --git a/main/Dataset/CSE20/processed/B160213CS_Nileena/B160213CS_2.png b/main/Dataset/CSE20/processed/B160213CS_Nileena/B160213CS_2.png\\\\\\\\n-deleted file mode 100644\\\\\\\\n-index 6bf453c..0000000\\\\\\\\n-Binary files a/main/Dataset/CSE20/processed/B160213CS_Nileena/B160213CS_2.png and /dev/null differ\\\\\\\\n-diff --git a/main/Dataset/CSE20/processed/B160213CS_Nileena/B160213CS_3.png b/main/Dataset/CSE20/processed/B160213CS_Nileena/B160213CS_3.png\\\\\\\\n-deleted file mode 100644\\\\\\\\n-index c40a062..0000000\\\\\\\\n-Binary files a/main/Dataset/CSE20/processed/B160213CS_Nileena/B160213CS_3.png and /dev/null differ\\\\\\\\n-diff --git a/main/Dataset/CSE20/processed/B160228CS_Vrindha/B160226CS_1.png b/main/Dataset/CSE20/processed/B160228CS_Vrindha/B160226CS_1.png\\\\\\\\n-deleted file mode 100644\\\\\\\\n-index 598febb..0000000\\\\\\\\n-Binary files a/main/Dataset/CSE20/processed/B160228CS_Vrindha/B160226CS_1.png and /dev/null differ\\\\\\\\n-diff --git a/main/Dataset/CSE20/processed/B160228CS_Vrindha/B160226CS_2.png b/main/Dataset/CSE20/processed/B160228CS_Vrindha/B160226CS_2.png\\\\\\\\n-deleted file mode 100644\\\\\\\\n-index 90186c5..0000000\\\\\\\\n-Binary files a/main/Dataset/CSE20/processed/B160228CS_Vrindha/B160226CS_2.png and /dev/null differ\\\\\\\\n-diff --git a/main/Dataset/CSE20/processed/B160228CS_Vrindha/B160226CS_3.png b/main/Dataset/CSE20/processed/B160228CS_Vrindha/B160226CS_3.png\\\\\\\\n-deleted file mode 100644\\\\\\\\n-index 11e9bc8..0000000\\\\\\\\n-Binary files a/main/Dataset/CSE20/processed/B160228CS_Vrindha/B160226CS_3.png and /dev/null differ\\\\\\\\n-diff --git a/main/Dataset/CSE20/processed/B160229CS_Reema/B160229CS_1.png b/main/Dataset/CSE20/processed/B160229CS_Reema/B160229CS_1.png\\\\\\\\n-deleted file mode 100644\\\\\\\\n-index 078771e..0000000\\\\\\\\n-Binary files a/main/Dataset/CSE20/processed/B160229CS_Reema/B160229CS_1.png and /dev/null differ\\\\\\\\n-diff --git a/main/Dataset/CSE20/processed/B160229CS_Reema/B160229CS_2.png b/main/Dataset/CSE20/processed/B160229CS_Reema/B160229CS_2.png\\\\\\\\n-deleted file mode 100644\\\\\\\\n-index b4aee42..0000000\\\\\\\\n-Binary files a/main/Dataset/CSE20/processed/B160229CS_Reema/B160229CS_2.png and /dev/null differ\\\\\\\\n-diff --git a/main/Dataset/CSE20/processed/B160229CS_Reema/B160229CS_3.png b/main/Dataset/CSE20/processed/B160229CS_Reema/B160229CS_3.png\\\\\\\\n-deleted file mode 100644\\\\\\\\n-index 406508e..0000000\\\\\\\\n-Binary files a/main/Dataset/CSE20/processed/B160229CS_Reema/B160229CS_3.png and /dev/null differ\\\\\\\\n-diff --git a/main/Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_1.png b/main/Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_1.png\\\\\\\\n-deleted file mode 100644\\\\\\\\n-index cb05c38..0000000\\\\\\\\n-Binary files a/main/Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_1.png and /dev/null differ\\\\\\\\n-diff --git a/main/Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_2.png b/main/Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_2.png\\\\\\\\n-deleted file mode 100644\\\\\\\\n-index ebef29c..0000000\\\\\\\\n-Binary files a/main/Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_2.png and /dev/null differ\\\\\\\\n-diff --git a/main/Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_3.png b/main/Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_3.png\\\\\\\\n-deleted file mode 100644\\\\\\\\n-index 5b409b0..0000000\\\\\\\\n-Binary files a/main/Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_3.png and /dev/null differ\\\\\\\\n-diff --git a/main/Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_4.png b/main/Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_4.png\\\\\\\\n-deleted file mode 100644\\\\\\\\n-index 63291a9..0000000\\\\\\\\n-Binary files a/main/Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_4.png and /dev/null differ\\\\\\\\n-diff --git a/main/Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_5.png b/main/Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_5.png\\\\\\\\n-deleted file mode 100644\\\\\\\\n-index 35bb01f..0000000\\\\\\\\n-Binary files a/main/Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_5.png and /dev/null differ\\\\\\\\n-diff --git a/main/Dataset/CSE20/processed/B160320ME_Shebin/B160320ME_1.png b/main/Dataset/CSE20/processed/B160320ME_Shebin/B160320ME_1.png\\\\\\\\n-deleted file mode 100644\\\\\\\\n-index fa0c503..0000000\\\\\\\\n-Binary files a/main/Dataset/CSE20/processed/B160320ME_Shebin/B160320ME_1.png and /dev/null differ\\\\\\\\n-diff --git a/main/Dataset/CSE20/processed/B160320ME_Shebin/B160320ME_2.png b/main/Dataset/CSE20/processed/B160320ME_Shebin/B160320ME_2.png\\\\\\\\n-deleted file mode 100644\\\\\\\\n-index 79a0e5d..0000000\\\\\\\\n-Binary files a/main/Dataset/CSE20/processed/B160320ME_Shebin/B160320ME_2.png and /dev/null differ\\\\\\\\n-diff --git a/main/Dataset/CSE20/processed/B160320ME_Shebin/B160320ME_3.png b/main/Dataset/CSE20/processed/B160320ME_Shebin/B160320ME_3.png\\\\\\\\n-deleted file mode 100644\\\\\\\\n-index c03da94..0000000\\\\\\\\n-Binary files a/main/Dataset/CSE20/processed/B160320ME_Shebin/B160320ME_3.png and /dev/null differ\\\\\\\\n-diff --git a/main/Dataset/CSE20/processed/B160408CS_Ameen/B160408CS_1.png b/main/Dataset/CSE20/processed/B160408CS_Ameen/B160408CS_1.png\\\\\\\\n-deleted file mode 100644\\\\\\\\n-index 16a46a2..0000000\\\\\\\\n-Binary files a/main/Dataset/CSE20/processed/B160408CS_Ameen/B160408CS_1.png and /dev/null differ\\\\\\\\n-diff --git a/main/Dataset/CSE20/processed/B160408CS_Ameen/B160408CS_2.png b/main/Dataset/CSE20/processed/B160408CS_Ameen/B160408CS_2.png\\\\\\\\n-deleted file mode 100644\\\\\\\\n-index 7d933ff..0000000\\\\\\\\n-Binary files a/main/Dataset/CSE20/processed/B160408CS_Ameen/B160408CS_2.png and /dev/null differ\\\\\\\\n-diff --git a/main/Dataset/CSE20/processed/B160408CS_Ameen/B160408CS_3.png b/main/Dataset/CSE20/processed/B160408CS_Ameen/B160408CS_3.png\\\\\\\\n-deleted file mode 100644\\\\\\\\n-index ce20835..0000000\\\\\\\\n-Binary files a/main/Dataset/CSE20/processed/B160408CS_Ameen/B160408CS_3.png and /dev/null differ\\\\\\\\n-diff --git a/main/Dataset/CSE20/processed/B160445CS_Sumalatha/B160445CS_1.png b/main/Dataset/CSE20/processed/B160445CS_Sumalatha/B160445CS_1.png\\\\\\\\n-deleted file mode 100644\\\\\\\\n-index fd9ed6f..0000000\\\\\\\\n-Binary files a/main/Dataset/CSE20/processed/B160445CS_Sumalatha/B160445CS_1.png and /dev/null differ\\\\\\\\n-diff --git a/main/Dataset/CSE20/processed/B160445CS_Sumalatha/B160445CS_2.png b/main/Dataset/CSE20/processed/B160445CS_Sumalatha/B160445CS_2.png\\\\\\\\n-deleted file mode 100644\\\\\\\\n-index ad52a1d..0000000\\\\\\\\n-Binary files a/main/Dataset/CSE20/processed/B160445CS_Sumalatha/B160445CS_2.png and /dev/null differ\\\\\\\\n-diff --git a/main/Dataset/CSE20/processed/B160471CS_Dheeraj/B160471CS_1.png b/main/Dataset/CSE20/processed/B160471CS_Dheeraj/B160471CS_1.png\\\\\\\\n-deleted file mode 100644\\\\\\\\n-index 78a1983..0000000\\\\\\\\n-Binary files a/main/Dataset/CSE20/processed/B160471CS_Dheeraj/B160471CS_1.png and /dev/null differ\\\\\\\\n-diff --git a/main/Dataset/CSE20/processed/B160688CS_Vishnu/B160688CS_1.png b/main/Dataset/CSE20/processed/B160688CS_Vishnu/B160688CS_1.png\\\\\\\\n-deleted file mode 100644\\\\\\\\n-index f43b308..0000000\\\\\\\\n-Binary files a/main/Dataset/CSE20/processed/B160688CS_Vishnu/B160688CS_1.png and /dev/null differ\\\\\\\\n-diff --git a/main/Dataset/CSE20/processed/B160688CS_Vishnu/B160688CS_2.png b/main/Dataset/CSE20/processed/B160688CS_Vishnu/B160688CS_2.png\\\\\\\\n-deleted file mode 100644\\\\\\\\n-index 5654243..0000000\\\\\\\\n-Binary files a/main/Dataset/CSE20/processed/B160688CS_Vishnu/B160688CS_2.png and /dev/null differ\\\\\\\\n-diff --git a/main/Dataset/CSE20/processed/B160688CS_Vishnu/B160688CS_3.png b/main/Dataset/CSE20/processed/B160688CS_Vishnu/B160688CS_3.png\\\\\\\\n-deleted file mode 100644\\\\\\\\n-index 4db5286..0000000\\\\\\\\n-Binary files a/main/Dataset/CSE20/processed/B160688CS_Vishnu/B160688CS_3.png and /dev/null differ\\\\\\\\n-diff --git a/main/Dataset/CSE20/processed/B160760CS_Vatsala/B160760CS_1.png b/main/Dataset/CSE20/processed/B160760CS_Vatsala/B160760CS_1.png\\\\\\\\n-deleted file mode 100644\\\\\\\\n-index 80f206e..0000000\\\\\\\\n-Binary files a/main/Dataset/CSE20/processed/B160760CS_Vatsala/B160760CS_1.png and /dev/null differ\\\\\\\\n-diff --git a/main/Dataset/CSE20/processed/B160760CS_Vatsala/B160760CS_2.png b/main/Dataset/CSE20/processed/B160760CS_Vatsala/B160760CS_2.png\\\\\\\\n-deleted file mode 100644\\\\\\\\n-index fbdeadf..0000000\\\\\\\\n-Binary files a/main/Dataset/CSE20/processed/B160760CS_Vatsala/B160760CS_2.png and /dev/null differ\\\\\\\\n-diff --git a/main/Dataset/CSE20/processed/B160760CS_Vatsala/B160760CS_3.png b/main/Dataset/CSE20/processed/B160760CS_Vatsala/B160760CS_3.png\\\\\\\\n-deleted file mode 100644\\\\\\\\n-index b7bb5e8..0000000\\\\\\\\n-Binary files a/main/Dataset/CSE20/processed/B160760CS_Vatsala/B160760CS_3.png and /dev/null differ\\\\\\\\n-diff --git a/main/Dataset/CSE20/processed/B160873CS_Naina/B160873CS_1.png b/main/Dataset/CSE20/processed/B160873CS_Naina/B160873CS_1.png\\\\\\\\n-deleted file mode 100644\\\\\\\\n-index 71d405b..0000000\\\\\\\\n-Binary files a/main/Dataset/CSE20/processed/B160873CS_Naina/B160873CS_1.png and /dev/null differ\\\\\\\\n-diff --git a/main/Dataset/CSE20/processed/B160873CS_Naina/B160873CS_2.png b/main/Dataset/CSE20/processed/B160873CS_Naina/B160873CS_2.png\\\\\\\\n-deleted file mode 100644\\\\\\\\n-index 2018b5c..0000000\\\\\\\\n-Binary files a/main/Dataset/CSE20/processed/B160873CS_Naina/B160873CS_2.png and /dev/null differ\\\\\\\\n-diff --git a/main/Dataset/CSE20/processed/B160873CS_Naina/B160873CS_3.png b/main/Dataset/CSE20/processed/B160873CS_Naina/B160873CS_3.png\\\\\\\\n-deleted file mode 100644\\\\\\\\n-index 6f1ae5c..0000000\\\\\\\\n-Binary files a/main/Dataset/CSE20/processed/B160873CS_Naina/B160873CS_3.png and /dev/null differ\\\\\\\\n-diff --git a/main/Dataset/CSE20/processed/bounding_boxes_09361.txt b/main/Dataset/CSE20/processed/bounding_boxes_09361.txt\\\\\\\\n-deleted file mode 100644\\\\\\\\n-index da52b30..0000000\\\\\\\\n---- a/main/Dataset/CSE20/processed/bounding_boxes_09361.txt\\\\\\\\n-+++ /dev/null\\\\\\\\n-@@ -1,35 +0,0 @@\\\\\\\\n--Dataset/CSE20/processed/B160760CS_Vatsala/B160760CS_3.png 737 316 933 556\\\\\\\\n--Dataset/CSE20/processed/B160760CS_Vatsala/B160760CS_2.png 153 385 552 891\\\\\\\\n--Dataset/CSE20/processed/B160760CS_Vatsala/B160760CS_1.png 468 264 572 389\\\\\\\\n--Dataset/CSE20/processed/B160320ME_Shebin/B160320ME_1.png 330 315 631 688\\\\\\\\n--Dataset/CSE20/processed/B160320ME_Shebin/B160320ME_3.png 191 285 646 892\\\\\\\\n--Dataset/CSE20/processed/B160320ME_Shebin/B160320ME_2.png 440 427 806 846\\\\\\\\n--Dataset/CSE20/processed/B160688CS_Vishnu/B160688CS_3.png 725 1044 1618 2214\\\\\\\\n--Dataset/CSE20/processed/B160688CS_Vishnu/B160688CS_2.png 973 426 1711 1363\\\\\\\\n--Dataset/CSE20/processed/B160688CS_Vishnu/B160688CS_1.png 544 396 1107 1123\\\\\\\\n--Dataset/CSE20/processed/B160116CS_Aparna/B160116CS_3.png 152 200 367 450\\\\\\\\n--Dataset/CSE20/processed/B160116CS_Aparna/B160116CS_2.png 229 63 386 249\\\\\\\\n--Dataset/CSE20/processed/B160116CS_Aparna/B160116CS_1.png 284 560 332 614\\\\\\\\n--Dataset/CSE20/processed/B160229CS_Reema/B160229CS_3.png 313 266 494 511\\\\\\\\n--Dataset/CSE20/processed/B160229CS_Reema/B160229CS_2.png 144 216 315 427\\\\\\\\n--Dataset/CSE20/processed/B160229CS_Reema/B160229CS_1.png 234 384 322 495\\\\\\\\n--Dataset/CSE20/processed/B160118CS_Neeraja/B160118CS_1.png 130 170 396 484\\\\\\\\n--Dataset/CSE20/processed/B160118CS_Neeraja/B160118CS_3.png 429 535 561 696\\\\\\\\n--Dataset/CSE20/processed/B160118CS_Neeraja/B160118CS_2.png 262 59 490 329\\\\\\\\n--Dataset/CSE20/processed/B160213CS_Nileena/B160213CS_1.png 137 160 397 472\\\\\\\\n--Dataset/CSE20/processed/B160213CS_Nileena/B160213CS_2.png 265 271 455 492\\\\\\\\n--Dataset/CSE20/processed/B160213CS_Nileena/B160213CS_3.png 89 336 272 568\\\\\\\\n--Dataset/CSE20/processed/B160873CS_Naina/B160873CS_1.png 133 145 299 358\\\\\\\\n--Dataset/CSE20/processed/B160873CS_Naina/B160873CS_2.png 451 407 544 518\\\\\\\\n--Dataset/CSE20/processed/B160873CS_Naina/B160873CS_3.png 81 58 278 310\\\\\\\\n--Dataset/CSE20/processed/B160228CS_Vrindha/B160226CS_2.png 69 259 255 491\\\\\\\\n--Dataset/CSE20/processed/B160228CS_Vrindha/B160226CS_1.png 516 60 868 528\\\\\\\\n--Dataset/CSE20/processed/B160228CS_Vrindha/B160226CS_3.png 297 232 727 812\\\\\\\\n--Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_4.png 221 361 404 600\\\\\\\\n--Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_1.png 277 240 512 537\\\\\\\\n--Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_3.png 532 299 622 407\\\\\\\\n--Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_2.png 195 53 286 160\\\\\\\\n--Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_5.png 169 348 584 922\\\\\\\\n--Dataset/CSE20/processed/B160445CS_Sumalatha/B160445CS_1.png 219 73 363 261\\\\\\\\n--Dataset/CSE20/processed/B160445CS_Sumalatha/B160445CS_2.png 406 272 546 443\\\\\\\\n--Dataset/CSE20/processed/B160445CS_Sumalatha/B160445CS_3.png 433 616 484 674\\\\\\\\n-diff --git a/main/Dataset/CSE20/processed/bounding_boxes_19737.txt b/main/Dataset/CSE20/processed/bounding_boxes_19737.txt\\\\\\\\n-deleted file mode 100644\\\\\\\\n-index e69de29..0000000\\\\\\\\n-diff --git a/main/Dataset/CSE20/processed/bounding_boxes_20330.txt b/main/Dataset/CSE20/processed/bounding_boxes_20330.txt\\\\\\\\n-deleted file mode 100644\\\\\\\\n-index e69de29..0000000\\\\\\\\n-diff --git a/main/Dataset/CSE20/processed/bounding_boxes_28104.txt b/main/Dataset/CSE20/processed/bounding_boxes_28104.txt\\\\\\\\n-deleted file mode 100644\\\\\\\\n-index dc58fca..0000000\\\\\\\\n---- a/main/Dataset/CSE20/processed/bounding_boxes_28104.txt\\\\\\\\n-+++ /dev/null\\\\\\\\n-@@ -1,3 +0,0 @@\\\\\\\\n--Dataset/CSE20/processed/Naina/naina2.png 451 407 544 518\\\\\\\\n--Dataset/CSE20/processed/Naina/naina3.png 81 58 278 310\\\\\\\\n--Dataset/CSE20/processed/Naina/naina1.png 133 145 299 358\\\\\\\\n-diff --git a/main/Dataset/CSE20/processed/bounding_boxes_30925.txt b/main/Dataset/CSE20/processed/bounding_boxes_30925.txt\\\\\\\\n-deleted file mode 100644\\\\\\\\n-index e69de29..0000000\\\\\\\\n-diff --git a/main/Dataset/CSE20/processed/bounding_boxes_38733.txt b/main/Dataset/CSE20/processed/bounding_boxes_38733.txt\\\\\\\\n-deleted file mode 100644\\\\\\\\n-index e69de29..0000000\\\\\\\\n-diff --git a/main/Dataset/CSE20/processed/bounding_boxes_40979.txt b/main/Dataset/CSE20/processed/bounding_boxes_40979.txt\\\\\\\\n-deleted file mode 100644\\\\\\\\n-index e69de29..0000000\\\\\\\\n-diff --git a/main/Dataset/CSE20/processed/bounding_boxes_50376.txt b/main/Dataset/CSE20/processed/bounding_boxes_50376.txt\\\\\\\\n-deleted file mode 100644\\\\\\\\n-index 746e69e..0000000\\\\\\\\n---- a/main/Dataset/CSE20/processed/bounding_boxes_50376.txt\\\\\\\\n-+++ /dev/null\\\\\\\\n-@@ -1,3 +0,0 @@\\\\\\\\n--Dataset/CSE20/processed/Poothery/Poothery1.png 544 396 1107 1123\\\\\\\\n--Dataset/CSE20/processed/Poothery/Poothery2.png 973 426 1711 1363\\\\\\\\n--Dataset/CSE20/processed/Poothery/Poothery3.png 725 1044 1618 2214\\\\\\\\n-diff --git a/main/Dataset/CSE20/processed/bounding_boxes_51760.txt b/main/Dataset/CSE20/processed/bounding_boxes_51760.txt\\\\\\\\n-deleted file mode 100644\\\\\\\\n-index e69de29..0000000\\\\\\\\n-diff --git a/main/Dataset/CSE20/processed/bounding_boxes_78500.txt b/main/Dataset/CSE20/processed/bounding_boxes_78500.txt\\\\\\\\n-deleted file mode 100644\\\\\\\\n-index e69de29..0000000\\\\\\\\n-diff --git a/main/Dataset/CSE20/processed/bounding_boxes_80845.txt b/main/Dataset/CSE20/processed/bounding_boxes_80845.txt\\\\\\\\n-deleted file mode 100644\\\\\\\\n-index e69de29..0000000\\\\\\\\n-diff --git a/main/Dataset/CSE20/processed/bounding_boxes_95936.txt b/main/Dataset/CSE20/processed/bounding_boxes_95936.txt\\\\\\\\n-deleted file mode 100644\\\\\\\\n-index 5c0564d..0000000\\\\\\\\n---- a/main/Dataset/CSE20/processed/bounding_boxes_95936.txt\\\\\\\\n-+++ /dev/null\\\\\\\\n-@@ -1,4 +0,0 @@\\\\\\\\n--Dataset/CSE20/processed/B160471CS_Dheeraj/B160471CS_1.png 227 268 413 483\\\\\\\\n--Dataset/CSE20/processed/B160408CS_Ameen/B160408CS_3.png 241 337 448 614\\\\\\\\n--Dataset/CSE20/processed/B160408CS_Ameen/B160408CS_1.png 259 306 442 541\\\\\\\\n--Dataset/CSE20/processed/B160408CS_Ameen/B160408CS_2.png 312 148 530 417\\\\\\\\n-diff --git a/main/Dataset/CSE20/processed/revision_info.txt b/main/Dataset/CSE20/processed/revision_info.txt\\\\\\\\n-deleted file mode 100644\\\\\\\\n-index 3eaf7fb..0000000\\\\\\\\n---- a/main/Dataset/CSE20/processed/revision_info.txt\\\\\\\\n-+++ /dev/null\\\\\\\\n-@@ -1,7 +0,0 @@\\\\\\\\n--arguments: src/align_dataset_mtcnn.py ./Dataset/CSE20/raw/ ./Dataset/CSE20/processed/ --image_size 160 --margin 32 --random_order --gpu_memory_fraction 0.25\\\\\\\\n----------------------\\\\\\\\n--tensorflow version: 1.7.0\\\\\\\\n----------------------\\\\\\\\n--git hash: b\\\\\\\\\\\\\\\'096ed770f163957c1e56efa7feeb194773920f6e\\\\\\\\\\\\\\\'\\\\\\\\n----------------------\\\\\\\\n--b\\\\\\\\\\\\\\\'diff --git a/ /revision_info.txt b/ /revision_info.txt\\\\\\\\\\\\\\\\nnew file mode 100644\\\\\\\\\\\\\\\\nindex 0000000..979e188\\\\\\\\\\\\\\\\n--- /dev/null\\\\\\\\\\\\\\\\n+++ b/ /revision_info.txt\\\\\\\\\\\\\\\\t\\\\\\\\\\\\\\\\n@@ -0,0 +1,8 @@\\\\\\\\\\\\\\\\n+arguments: src/align/align_dataset_mtcnn.py ./Dataset/CSE20/raw \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n+./Dataset/CSE20/processed --image_size 160 --margin 32 --random_order  \\\\\\\\\\\\\\\\n+--------------------\\\\\\\\\\\\\\\\n+tensorflow version: 1.7.0\\\\\\\\\\\\\\\\n+--------------------\\\\\\\\\\\\\\\\n+git hash: b\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'096ed770f163957c1e56efa7feeb194773920f6e\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\\n+--------------------\\\\\\\\\\\\\\\\n+b\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'diff --git a/src/align/align_dataset_mtcnn.py b/src/align/align_dataset_mtcnn.py\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nindex 7d5e735..21f1457 100644\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n--- a/src/align/align_dataset_mtcnn.py\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n+++ b/src/align/align_dataset_mtcnn.py\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n@@ -31,8 +31,8 @@ import os\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n import argparse\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n import tensorflow as tf\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n import numpy as np\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n-import facenet\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n-import align.detect_face\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n+import facenet.src.facenet as facenet   #changed\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n+import detect_face  #changed\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n import random\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n from time import sleep\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ No newline at end of file\\\\\\\\\\\\\\\\ndiff --git a/Dataset/CSE20/processed/B160116CS_Aparna/B160116CS_1.png b/Dataset/CSE20/processed/B160116CS_Aparna/B160116CS_1.png\\\\\\\\\\\\\\\\nnew file mode 100644\\\\\\\\\\\\\\\\nindex 0000000..f1db83f\\\\\\\\\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160116CS_Aparna/B160116CS_1.png differ\\\\\\\\\\\\\\\\ndiff --git a/Dataset/CSE20/processed/B160116CS_Aparna/B160116CS_2.png b/Dataset/CSE20/processed/B160116CS_Aparna/B160116CS_2.png\\\\\\\\\\\\\\\\nnew file mode 100644\\\\\\\\\\\\\\\\nindex 0000000..45449c3\\\\\\\\\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160116CS_Aparna/B160116CS_2.png differ\\\\\\\\\\\\\\\\ndiff --git a/Dataset/CSE20/processed/B160116CS_Aparna/B160116CS_3.png b/Dataset/CSE20/processed/B160116CS_Aparna/B160116CS_3.png\\\\\\\\\\\\\\\\nnew file mode 100644\\\\\\\\\\\\\\\\nindex 0000000..9813f9f\\\\\\\\\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160116CS_Aparna/B160116CS_3.png differ\\\\\\\\\\\\\\\\ndiff --git a/Dataset/CSE20/processed/B160118CS_Neeraja/B160118CS_1.png b/Dataset/CSE20/processed/B160118CS_Neeraja/B160118CS_1.png\\\\\\\\\\\\\\\\nnew file mode 100644\\\\\\\\\\\\\\\\nindex 0000000..fb52346\\\\\\\\\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160118CS_Neeraja/B160118CS_1.png differ\\\\\\\\\\\\\\\\ndiff --git a/Dataset/CSE20/processed/B160118CS_Neeraja/B160118CS_2.png b/Dataset/CSE20/processed/B160118CS_Neeraja/B160118CS_2.png\\\\\\\\\\\\\\\\nnew file mode 100644\\\\\\\\\\\\\\\\nindex 0000000..3a04b13\\\\\\\\\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160118CS_Neeraja/B160118CS_2.png differ\\\\\\\\\\\\\\\\ndiff --git a/Dataset/CSE20/processed/B160118CS_Neeraja/B160118CS_3.png b/Dataset/CSE20/processed/B160118CS_Neeraja/B160118CS_3.png\\\\\\\\\\\\\\\\nnew file mode 100644\\\\\\\\\\\\\\\\nindex 0000000..f7c2d61\\\\\\\\\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160118CS_Neeraja/B160118CS_3.png differ\\\\\\\\\\\\\\\\ndiff --git a/Dataset/CSE20/processed/B160213CS_Nileena/B160213CS_1.png b/Dataset/CSE20/processed/B160213CS_Nileena/B160213CS_1.png\\\\\\\\\\\\\\\\nnew file mode 100644\\\\\\\\\\\\\\\\nindex 0000000..5affd0e\\\\\\\\\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160213CS_Nileena/B160213CS_1.png differ\\\\\\\\\\\\\\\\ndiff --git a/Dataset/CSE20/processed/B160213CS_Nileena/B160213CS_2.png b/Dataset/CSE20/processed/B160213CS_Nileena/B160213CS_2.png\\\\\\\\\\\\\\\\nnew file mode 100644\\\\\\\\\\\\\\\\nindex 0000000..6bf453c\\\\\\\\\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160213CS_Nileena/B160213CS_2.png differ\\\\\\\\\\\\\\\\ndiff --git a/Dataset/CSE20/processed/B160213CS_Nileena/B160213CS_3.png b/Dataset/CSE20/processed/B160213CS_Nileena/B160213CS_3.png\\\\\\\\\\\\\\\\nnew file mode 100644\\\\\\\\\\\\\\\\nindex 0000000..c40a062\\\\\\\\\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160213CS_Nileena/B160213CS_3.png differ\\\\\\\\\\\\\\\\ndiff --git a/Dataset/CSE20/processed/B160228CS_Vrindha/B160226CS_1.png b/Dataset/CSE20/processed/B160228CS_Vrindha/B160226CS_1.png\\\\\\\\\\\\\\\\nnew file mode 100644\\\\\\\\\\\\\\\\nindex 0000000..598febb\\\\\\\\\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160228CS_Vrindha/B160226CS_1.png differ\\\\\\\\\\\\\\\\ndiff --git a/Dataset/CSE20/processed/B160228CS_Vrindha/B160226CS_2.png b/Dataset/CSE20/processed/B160228CS_Vrindha/B160226CS_2.png\\\\\\\\\\\\\\\\nnew file mode 100644\\\\\\\\\\\\\\\\nindex 0000000..90186c5\\\\\\\\\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160228CS_Vrindha/B160226CS_2.png differ\\\\\\\\\\\\\\\\ndiff --git a/Dataset/CSE20/processed/B160228CS_Vrindha/B160226CS_3.png b/Dataset/CSE20/processed/B160228CS_Vrindha/B160226CS_3.png\\\\\\\\\\\\\\\\nnew file mode 100644\\\\\\\\\\\\\\\\nindex 0000000..11e9bc8\\\\\\\\\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160228CS_Vrindha/B160226CS_3.png differ\\\\\\\\\\\\\\\\ndiff --git a/Dataset/CSE20/processed/B160229CS_Reema/B160229CS_1.png b/Dataset/CSE20/processed/B160229CS_Reema/B160229CS_1.png\\\\\\\\\\\\\\\\nnew file mode 100644\\\\\\\\\\\\\\\\nindex 0000000..078771e\\\\\\\\\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160229CS_Reema/B160229CS_1.png differ\\\\\\\\\\\\\\\\ndiff --git a/Dataset/CSE20/processed/B160229CS_Reema/B160229CS_2.png b/Dataset/CSE20/processed/B160229CS_Reema/B160229CS_2.png\\\\\\\\\\\\\\\\nnew file mode 100644\\\\\\\\\\\\\\\\nindex 0000000..b4aee42\\\\\\\\\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160229CS_Reema/B160229CS_2.png differ\\\\\\\\\\\\\\\\ndiff --git a/Dataset/CSE20/processed/B160229CS_Reema/B160229CS_3.png b/Dataset/CSE20/processed/B160229CS_Reema/B160229CS_3.png\\\\\\\\\\\\\\\\nnew file mode 100644\\\\\\\\\\\\\\\\nindex 0000000..406508e\\\\\\\\\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160229CS_Reema/B160229CS_3.png differ\\\\\\\\\\\\\\\\ndiff --git a/Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_1.png b/Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_1.png\\\\\\\\\\\\\\\\nnew file mode 100644\\\\\\\\\\\\\\\\nindex 0000000..cb05c38\\\\\\\\\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_1.png differ\\\\\\\\\\\\\\\\ndiff --git a/Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_2.png b/Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_2.png\\\\\\\\\\\\\\\\nnew file mode 100644\\\\\\\\\\\\\\\\nindex 0000000..ebef29c\\\\\\\\\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_2.png differ\\\\\\\\\\\\\\\\ndiff --git a/Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_3.png b/Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_3.png\\\\\\\\\\\\\\\\nnew file mode 100644\\\\\\\\\\\\\\\\nindex 0000000..5b409b0\\\\\\\\\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_3.png differ\\\\\\\\\\\\\\\\ndiff --git a/Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_4.png b/Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_4.png\\\\\\\\\\\\\\\\nnew file mode 100644\\\\\\\\\\\\\\\\nindex 0000000..63291a9\\\\\\\\\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_4.png differ\\\\\\\\\\\\\\\\ndiff --git a/Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_5.png b/Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_5.png\\\\\\\\\\\\\\\\nnew file mode 100644\\\\\\\\\\\\\\\\nindex 0000000..35bb01f\\\\\\\\\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_5.png differ\\\\\\\\\\\\\\\\ndiff --git a/Dataset/CSE20/processed/B160320ME_Shebin/B160320ME_1.png b/Dataset/CSE20/processed/B160320ME_Shebin/B160320ME_1.png\\\\\\\\\\\\\\\\nnew file mode 100644\\\\\\\\\\\\\\\\nindex 0000000..fa0c503\\\\\\\\\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160320ME_Shebin/B160320ME_1.png differ\\\\\\\\\\\\\\\\ndiff --git a/Dataset/CSE20/processed/B160320ME_Shebin/B160320ME_2.png b/Dataset/CSE20/processed/B160320ME_Shebin/B160320ME_2.png\\\\\\\\\\\\\\\\nnew file mode 100644\\\\\\\\\\\\\\\\nindex 0000000..79a0e5d\\\\\\\\\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160320ME_Shebin/B160320ME_2.png differ\\\\\\\\\\\\\\\\ndiff --git a/Dataset/CSE20/processed/B160320ME_Shebin/B160320ME_3.png b/Dataset/CSE20/processed/B160320ME_Shebin/B160320ME_3.png\\\\\\\\\\\\\\\\nnew file mode 100644\\\\\\\\\\\\\\\\nindex 0000000..c03da94\\\\\\\\\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160320ME_Shebin/B160320ME_3.png differ\\\\\\\\\\\\\\\\ndiff --git a/Dataset/CSE20/processed/B160408CS_Ameen/B160408CS_1.png b/Dataset/CSE20/processed/B160408CS_Ameen/B160408CS_1.png\\\\\\\\\\\\\\\\nnew file mode 100644\\\\\\\\\\\\\\\\nindex 0000000..16a46a2\\\\\\\\\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160408CS_Ameen/B160408CS_1.png differ\\\\\\\\\\\\\\\\ndiff --git a/Dataset/CSE20/processed/B160408CS_Ameen/B160408CS_2.png b/Dataset/CSE20/processed/B160408CS_Ameen/B160408CS_2.png\\\\\\\\\\\\\\\\nnew file mode 100644\\\\\\\\\\\\\\\\nindex 0000000..7d933ff\\\\\\\\\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160408CS_Ameen/B160408CS_2.png differ\\\\\\\\\\\\\\\\ndiff --git a/Dataset/CSE20/processed/B160408CS_Ameen/B160408CS_3.png b/Dataset/CSE20/processed/B160408CS_Ameen/B160408CS_3.png\\\\\\\\\\\\\\\\nnew file mode 100644\\\\\\\\\\\\\\\\nindex 0000000..ce20835\\\\\\\\\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160408CS_Ameen/B160408CS_3.png differ\\\\\\\\\\\\\\\\ndiff --git a/Dataset/CSE20/processed/B160445CS_Sumalatha/B160445CS_1.png b/Dataset/CSE20/processed/B160445CS_Sumalatha/B160445CS_1.png\\\\\\\\\\\\\\\\nnew file mode 100644\\\\\\\\\\\\\\\\nindex 0000000..fd9ed6f\\\\\\\\\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160445CS_Sumalatha/B160445CS_1.png differ\\\\\\\\\\\\\\\\ndiff --git a/Dataset/CSE20/processed/B160445CS_Sumalatha/B160445CS_2.png b/Dataset/CSE20/processed/B160445CS_Sumalatha/B160445CS_2.png\\\\\\\\\\\\\\\\nnew file mode 100644\\\\\\\\\\\\\\\\nindex 0000000..ad52a1d\\\\\\\\\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160445CS_Sumalatha/B160445CS_2.png differ\\\\\\\\\\\\\\\\ndiff --git a/Dataset/CSE20/processed/B160445CS_Sumalatha/B160445CS_3.png b/Dataset/CSE20/processed/B160445CS_Sumalatha/B160445CS_3.png\\\\\\\\\\\\\\\\nnew file mode 100644\\\\\\\\\\\\\\\\nindex 0000000..7fc6b80\\\\\\\\\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160445CS_Sumalatha/B160445CS_3.png differ\\\\\\\\\\\\\\\\ndiff --git a/Dataset/CSE20/processed/B160471CS_Dheeraj/B160471CS_1.png b/Dataset/CSE20/processed/B160471CS_Dheeraj/B160471CS_1.png\\\\\\\\\\\\\\\\nnew file mode 100644\\\\\\\\\\\\\\\\nindex 0000000..78a1983\\\\\\\\\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160471CS_Dheeraj/B160471CS_1.png differ\\\\\\\\\\\\\\\\ndiff --git a/Dataset/CSE20/processed/B160688CS_Vishnu/B160688CS_1.png b/Dataset/CSE20/processed/B160688CS_Vishnu/B160688CS_1.png\\\\\\\\\\\\\\\\nnew file mode 100644\\\\\\\\\\\\\\\\nindex 0000000..f43b308\\\\\\\\\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160688CS_Vishnu/B160688CS_1.png differ\\\\\\\\\\\\\\\\ndiff --git a/Dataset/CSE20/processed/B160688CS_Vishnu/B160688CS_2.png b/Dataset/CSE20/processed/B160688CS_Vishnu/B160688CS_2.png\\\\\\\\\\\\\\\\nnew file mode 100644\\\\\\\\\\\\\\\\nindex 0000000..5654243\\\\\\\\\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160688CS_Vishnu/B160688CS_2.png differ\\\\\\\\\\\\\\\\ndiff --git a/Dataset/CSE20/processed/B160688CS_Vishnu/B160688CS_3.png b/Dataset/CSE20/processed/B160688CS_Vishnu/B160688CS_3.png\\\\\\\\\\\\\\\\nnew file mode 100644\\\\\\\\\\\\\\\\nindex 0000000..4db5286\\\\\\\\\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160688CS_Vishnu/B160688CS_3.png differ\\\\\\\\\\\\\\\\ndiff --git a/Dataset/CSE20/processed/B160760CS_Vatsala/B160760CS_1.png b/Dataset/CSE20/processed/B160760CS_Vatsala/B160760CS_1.png\\\\\\\\\\\\\\\\nnew file mode 100644\\\\\\\\\\\\\\\\nindex 0000000..80f206e\\\\\\\\\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160760CS_Vatsala/B160760CS_1.png differ\\\\\\\\\\\\\\\\ndiff --git a/Dataset/CSE20/processed/B160760CS_Vatsala/B160760CS_2.png b/Dataset/CSE20/processed/B160760CS_Vatsala/B160760CS_2.png\\\\\\\\\\\\\\\\nnew file mode 100644\\\\\\\\\\\\\\\\nindex 0000000..fbdeadf\\\\\\\\\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160760CS_Vatsala/B160760CS_2.png differ\\\\\\\\\\\\\\\\ndiff --git a/Dataset/CSE20/processed/B160760CS_Vatsala/B160760CS_3.png b/Dataset/CSE20/processed/B160760CS_Vatsala/B160760CS_3.png\\\\\\\\\\\\\\\\nnew file mode 100644\\\\\\\\\\\\\\\\nindex 0000000..b7bb5e8\\\\\\\\\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160760CS_Vatsala/B160760CS_3.png differ\\\\\\\\\\\\\\\\ndiff --git a/Dataset/CSE20/processed/B160873CS_Naina/B160873CS_1.png b/Dataset/CSE20/processed/B160873CS_Naina/B160873CS_1.png\\\\\\\\\\\\\\\\nnew file mode 100644\\\\\\\\\\\\\\\\nindex 0000000..71d405b\\\\\\\\\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160873CS_Naina/B160873CS_1.png differ\\\\\\\\\\\\\\\\ndiff --git a/Dataset/CSE20/processed/B160873CS_Naina/B160873CS_2.png b/Dataset/CSE20/processed/B160873CS_Naina/B160873CS_2.png\\\\\\\\\\\\\\\\nnew file mode 100644\\\\\\\\\\\\\\\\nindex 0000000..2018b5c\\\\\\\\\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160873CS_Naina/B160873CS_2.png differ\\\\\\\\\\\\\\\\ndiff --git a/Dataset/CSE20/processed/B160873CS_Naina/B160873CS_3.png b/Dataset/CSE20/processed/B160873CS_Naina/B160873CS_3.png\\\\\\\\\\\\\\\\nnew file mode 100644\\\\\\\\\\\\\\\\nindex 0000000..6f1ae5c\\\\\\\\\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/B160873CS_Naina/B160873CS_3.png differ\\\\\\\\\\\\\\\\ndiff --git a/Dataset/CSE20/processed/Naina/naina1.png b/Dataset/CSE20/processed/Naina/naina1.png\\\\\\\\\\\\\\\\nnew file mode 100644\\\\\\\\\\\\\\\\nindex 0000000..71d405b\\\\\\\\\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/Naina/naina1.png differ\\\\\\\\\\\\\\\\ndiff --git a/Dataset/CSE20/processed/Naina/naina2.png b/Dataset/CSE20/processed/Naina/naina2.png\\\\\\\\\\\\\\\\nnew file mode 100644\\\\\\\\\\\\\\\\nindex 0000000..2018b5c\\\\\\\\\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/Naina/naina2.png differ\\\\\\\\\\\\\\\\ndiff --git a/Dataset/CSE20/processed/Naina/naina3.png b/Dataset/CSE20/processed/Naina/naina3.png\\\\\\\\\\\\\\\\nnew file mode 100644\\\\\\\\\\\\\\\\nindex 0000000..6f1ae5c\\\\\\\\\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/Naina/naina3.png differ\\\\\\\\\\\\\\\\ndiff --git a/Dataset/CSE20/processed/Poothery/Poothery1.png b/Dataset/CSE20/processed/Poothery/Poothery1.png\\\\\\\\\\\\\\\\nnew file mode 100644\\\\\\\\\\\\\\\\nindex 0000000..f43b308\\\\\\\\\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/Poothery/Poothery1.png differ\\\\\\\\\\\\\\\\ndiff --git a/Dataset/CSE20/processed/Poothery/Poothery2.png b/Dataset/CSE20/processed/Poothery/Poothery2.png\\\\\\\\\\\\\\\\nnew file mode 100644\\\\\\\\\\\\\\\\nindex 0000000..5654243\\\\\\\\\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/Poothery/Poothery2.png differ\\\\\\\\\\\\\\\\ndiff --git a/Dataset/CSE20/processed/Poothery/Poothery3.png b/Dataset/CSE20/processed/Poothery/Poothery3.png\\\\\\\\\\\\\\\\nnew file mode 100644\\\\\\\\\\\\\\\\nindex 0000000..4db5286\\\\\\\\\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/processed/Poothery/Poothery3.png differ\\\\\\\\\\\\\\\\ndiff --git a/Dataset/CSE20/processed/bounding_boxes_09361.txt b/Dataset/CSE20/processed/bounding_boxes_09361.txt\\\\\\\\\\\\\\\\nnew file mode 100644\\\\\\\\\\\\\\\\nindex 0000000..da52b30\\\\\\\\\\\\\\\\n--- /dev/null\\\\\\\\\\\\\\\\n+++ b/Dataset/CSE20/processed/bounding_boxes_09361.txt\\\\\\\\\\\\\\\\n@@ -0,0 +1,35 @@\\\\\\\\\\\\\\\\n+Dataset/CSE20/processed/B160760CS_Vatsala/B160760CS_3.png 737 316 933 556\\\\\\\\\\\\\\\\n+Dataset/CSE20/processed/B160760CS_Vatsala/B160760CS_2.png 153 385 552 891\\\\\\\\\\\\\\\\n+Dataset/CSE20/processed/B160760CS_Vatsala/B160760CS_1.png 468 264 572 389\\\\\\\\\\\\\\\\n+Dataset/CSE20/processed/B160320ME_Shebin/B160320ME_1.png 330 315 631 688\\\\\\\\\\\\\\\\n+Dataset/CSE20/processed/B160320ME_Shebin/B160320ME_3.png 191 285 646 892\\\\\\\\\\\\\\\\n+Dataset/CSE20/processed/B160320ME_Shebin/B160320ME_2.png 440 427 806 846\\\\\\\\\\\\\\\\n+Dataset/CSE20/processed/B160688CS_Vishnu/B160688CS_3.png 725 1044 1618 2214\\\\\\\\\\\\\\\\n+Dataset/CSE20/processed/B160688CS_Vishnu/B160688CS_2.png 973 426 1711 1363\\\\\\\\\\\\\\\\n+Dataset/CSE20/processed/B160688CS_Vishnu/B160688CS_1.png 544 396 1107 1123\\\\\\\\\\\\\\\\n+Dataset/CSE20/processed/B160116CS_Aparna/B160116CS_3.png 152 200 367 450\\\\\\\\\\\\\\\\n+Dataset/CSE20/processed/B160116CS_Aparna/B160116CS_2.png 229 63 386 249\\\\\\\\\\\\\\\\n+Dataset/CSE20/processed/B160116CS_Aparna/B160116CS_1.png 284 560 332 614\\\\\\\\\\\\\\\\n+Dataset/CSE20/processed/B160229CS_Reema/B160229CS_3.png 313 266 494 511\\\\\\\\\\\\\\\\n+Dataset/CSE20/processed/B160229CS_Reema/B160229CS_2.png 144 216 315 427\\\\\\\\\\\\\\\\n+Dataset/CSE20/processed/B160229CS_Reema/B160229CS_1.png 234 384 322 495\\\\\\\\\\\\\\\\n+Dataset/CSE20/processed/B160118CS_Neeraja/B160118CS_1.png 130 170 396 484\\\\\\\\\\\\\\\\n+Dataset/CSE20/processed/B160118CS_Neeraja/B160118CS_3.png 429 535 561 696\\\\\\\\\\\\\\\\n+Dataset/CSE20/processed/B160118CS_Neeraja/B160118CS_2.png 262 59 490 329\\\\\\\\\\\\\\\\n+Dataset/CSE20/processed/B160213CS_Nileena/B160213CS_1.png 137 160 397 472\\\\\\\\\\\\\\\\n+Dataset/CSE20/processed/B160213CS_Nileena/B160213CS_2.png 265 271 455 492\\\\\\\\\\\\\\\\n+Dataset/CSE20/processed/B160213CS_Nileena/B160213CS_3.png 89 336 272 568\\\\\\\\\\\\\\\\n+Dataset/CSE20/processed/B160873CS_Naina/B160873CS_1.png 133 145 299 358\\\\\\\\\\\\\\\\n+Dataset/CSE20/processed/B160873CS_Naina/B160873CS_2.png 451 407 544 518\\\\\\\\\\\\\\\\n+Dataset/CSE20/processed/B160873CS_Naina/B160873CS_3.png 81 58 278 310\\\\\\\\\\\\\\\\n+Dataset/CSE20/processed/B160228CS_Vrindha/B160226CS_2.png 69 259 255 491\\\\\\\\\\\\\\\\n+Dataset/CSE20/processed/B160228CS_Vrindha/B160226CS_1.png 516 60 868 528\\\\\\\\\\\\\\\\n+Dataset/CSE20/processed/B160228CS_Vrindha/B160226CS_3.png 297 232 727 812\\\\\\\\\\\\\\\\n+Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_4.png 221 361 404 600\\\\\\\\\\\\\\\\n+Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_1.png 277 240 512 537\\\\\\\\\\\\\\\\n+Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_3.png 532 299 622 407\\\\\\\\\\\\\\\\n+Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_2.png 195 53 286 160\\\\\\\\\\\\\\\\n+Dataset/CSE20/processed/B160270CS_Lakshmi/B160270CS_5.png 169 348 584 922\\\\\\\\\\\\\\\\n+Dataset/CSE20/processed/B160445CS_Sumalatha/B160445CS_1.png 219 73 363 261\\\\\\\\\\\\\\\\n+Dataset/CSE20/processed/B160445CS_Sumalatha/B160445CS_2.png 406 272 546 443\\\\\\\\\\\\\\\\n+Dataset/CSE20/processed/B160445CS_Sumalatha/B160445CS_3.png 433 616 484 674\\\\\\\\\\\\\\\\ndiff --git a/Dataset/CSE20/processed/bounding_boxes_19737.txt b/Dataset/CSE20/processed/bounding_boxes_19737.txt\\\\\\\\\\\\\\\\nnew file mode 100644\\\\\\\\\\\\\\\\nindex 0000000..e69de29\\\\\\\\\\\\\\\\ndiff --git a/Dataset/CSE20/processed/bounding_boxes_20330.txt b/Dataset/CSE20/processed/bounding_boxes_20330.txt\\\\\\\\\\\\\\\\nnew file mode 100644\\\\\\\\\\\\\\\\nindex 0000000..e69de29\\\\\\\\\\\\\\\\ndiff --git a/Dataset/CSE20/processed/bounding_boxes_28104.txt b/Dataset/CSE20/processed/bounding_boxes_28104.txt\\\\\\\\\\\\\\\\nnew file mode 100644\\\\\\\\\\\\\\\\nindex 0000000..dc58fca\\\\\\\\\\\\\\\\n--- /dev/null\\\\\\\\\\\\\\\\n+++ b/Dataset/CSE20/processed/bounding_boxes_28104.txt\\\\\\\\\\\\\\\\n@@ -0,0 +1,3 @@\\\\\\\\\\\\\\\\n+Dataset/CSE20/processed/Naina/naina2.png 451 407 544 518\\\\\\\\\\\\\\\\n+Dataset/CSE20/processed/Naina/naina3.png 81 58 278 310\\\\\\\\\\\\\\\\n+Dataset/CSE20/processed/Naina/naina1.png 133 145 299 358\\\\\\\\\\\\\\\\ndiff --git a/Dataset/CSE20/processed/bounding_boxes_30925.txt b/Dataset/CSE20/processed/bounding_boxes_30925.txt\\\\\\\\\\\\\\\\nnew file mode 100644\\\\\\\\\\\\\\\\nindex 0000000..e69de29\\\\\\\\\\\\\\\\ndiff --git a/Dataset/CSE20/processed/bounding_boxes_38733.txt b/Dataset/CSE20/processed/bounding_boxes_38733.txt\\\\\\\\\\\\\\\\nnew file mode 100644\\\\\\\\\\\\\\\\nindex 0000000..e69de29\\\\\\\\\\\\\\\\ndiff --git a/Dataset/CSE20/processed/bounding_boxes_40979.txt b/Dataset/CSE20/processed/bounding_boxes_40979.txt\\\\\\\\\\\\\\\\nnew file mode 100644\\\\\\\\\\\\\\\\nindex 0000000..e69de29\\\\\\\\\\\\\\\\ndiff --git a/Dataset/CSE20/processed/bounding_boxes_50376.txt b/Dataset/CSE20/processed/bounding_boxes_50376.txt\\\\\\\\\\\\\\\\nnew file mode 100644\\\\\\\\\\\\\\\\nindex 0000000..746e69e\\\\\\\\\\\\\\\\n--- /dev/null\\\\\\\\\\\\\\\\n+++ b/Dataset/CSE20/processed/bounding_boxes_50376.txt\\\\\\\\\\\\\\\\n@@ -0,0 +1,3 @@\\\\\\\\\\\\\\\\n+Dataset/CSE20/processed/Poothery/Poothery1.png 544 396 1107 1123\\\\\\\\\\\\\\\\n+Dataset/CSE20/processed/Poothery/Poothery2.png 973 426 1711 1363\\\\\\\\\\\\\\\\n+Dataset/CSE20/processed/Poothery/Poothery3.png 725 1044 1618 2214\\\\\\\\\\\\\\\\ndiff --git a/Dataset/CSE20/processed/bounding_boxes_51760.txt b/Dataset/CSE20/processed/bounding_boxes_51760.txt\\\\\\\\\\\\\\\\nnew file mode 100644\\\\\\\\\\\\\\\\nindex 0000000..e69de29\\\\\\\\\\\\\\\\ndiff --git a/Dataset/CSE20/processed/bounding_boxes_80845.txt b/Dataset/CSE20/processed/bounding_boxes_80845.txt\\\\\\\\\\\\\\\\nnew file mode 100644\\\\\\\\\\\\\\\\nindex 0000000..e69de29\\\\\\\\\\\\\\\\ndiff --git a/Dataset/CSE20/processed/bounding_boxes_95936.txt b/Dataset/CSE20/processed/bounding_boxes_95936.txt\\\\\\\\\\\\\\\\nnew file mode 100644\\\\\\\\\\\\\\\\nindex 0000000..5c0564d\\\\\\\\\\\\\\\\n--- /dev/null\\\\\\\\\\\\\\\\n+++ b/Dataset/CSE20/processed/bounding_boxes_95936.txt\\\\\\\\\\\\\\\\n@@ -0,0 +1,4 @@\\\\\\\\\\\\\\\\n+Dataset/CSE20/processed/B160471CS_Dheeraj/B160471CS_1.png 227 268 413 483\\\\\\\\\\\\\\\\n+Dataset/CSE20/processed/B160408CS_Ameen/B160408CS_3.png 241 337 448 614\\\\\\\\\\\\\\\\n+Dataset/CSE20/processed/B160408CS_Ameen/B160408CS_1.png 259 306 442 541\\\\\\\\\\\\\\\\n+Dataset/CSE20/processed/B160408CS_Ameen/B160408CS_2.png 312 148 530 417\\\\\\\\\\\\\\\\ndiff --git a/Dataset/CSE20/processed/revision_info.txt b/Dataset/CSE20/processed/revision_info.txt\\\\\\\\\\\\\\\\nnew file mode 100644\\\\\\\\\\\\\\\\nindex 0000000..5373839\\\\\\\\\\\\\\\\n--- /dev/null\\\\\\\\\\\\\\\\n+++ b/Dataset/CSE20/processed/revision_info.txt\\\\\\\\\\\\\\\\n@@ -0,0 +1,7 @@\\\\\\\\\\\\\\\\n+arguments: src/align_dataset_mtcnn.py Dataset/CSE20/raw/ Dataset/CSE20/processed/ --image_size 160 --margin 32 --random_order --gpu_memory_fraction 0.25\\\\\\\\\\\\\\\\n+--------------------\\\\\\\\\\\\\\\\n+tensorflow version: 1.7.0\\\\\\\\\\\\\\\\n+--------------------\\\\\\\\\\\\\\\\n+git hash: b\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'096ed770f163957c1e56efa7feeb194773920f6e\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\\n+--------------------\\\\\\\\\\\\\\\\n+b\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'diff --git a/src/align/align_dataset_mtcnn.py b/src/align/align_dataset_mtcnn.py\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nindex 7d5e735..21f1457 100644\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n--- a/src/align/align_dataset_mtcnn.py\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n+++ b/src/align/align_dataset_mtcnn.py\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n@@ -31,8 +31,8 @@ import os\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n import argparse\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n import tensorflow as tf\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n import numpy as np\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n-import facenet\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n-import align.detect_face\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n+import facenet.src.facenet as facenet   #changed\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n+import detect_face  #changed\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n import random\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n from time import sleep\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ndiff --git a/src/align/detect_face.py b/src/align/detect_face.py\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nindex 7f98ca7..3806b33 100644\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n--- a/src/align/detect_face.py\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n+++ b/src/align/detect_face.py\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n@@ -82,7 +82,10 @@ class Network(object):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n         session: The current TensorFlow session\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n         ignore_missing: If true, serialized weights for missing layers are ignored.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n         """\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n+        np_load_old = np.load\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n+        np.load = lambda *a, **k: np_load_old(*a, allow_pickle=True, **k)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n         data_dict = np.load(data_path, encoding=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'latin1\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\').item() #pylint: disable=no-member\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n+        np.load = np_load_old\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n         for op_name in data_dict:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n             with tf.variable_scope(op_name, reuse=True):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ndiff --git a/src/facenet.py b/src/facenet.py\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nindex 0e05676..538b650 100644\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n--- a/src/facenet.py\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n+++ b/src/facenet.py\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n@@ -32,6 +32,7 @@ from subprocess import Popen, PIPE\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n import tensorflow as tf\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n import numpy as np\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n from scipy import misc\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n+import imageio\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n from sklearn.model_selection import KFold\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n from scipy import interpolate\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n from tensorflow.python.training import training\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n@@ -244,7 +245,7 @@ def load_data(image_paths, do_random_crop, do_random_flip, image_size, do_prewhi\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n     nrof_samples = len(image_paths)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n     images = np.zeros((nrof_samples, image_size, image_size, 3))\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n     for i in range(nrof_samples):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n-        img = misc.imread(image_paths[i])\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n+        img = imageio.imread(image_paths[i])\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n         if img.ndim == 2:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n             img = to_rgb(img)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n         if do_prewhiten:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ No newline at end of file\\\\\\\\\\\\\\\\ndiff --git a/Dataset/CSE20/raw/B160116CS_Aparna/B160116CS_1.jpeg b/Dataset/CSE20/raw/B160116CS_Aparna/B160116CS_1.jpeg\\\\\\\\\\\\\\\\nnew file mode 100644\\\\\\\\\\\\\\\\nindex 0000000..e23a8fc\\\\\\\\\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160116CS_Aparna/B160116CS_1.jpeg differ\\\\\\\\\\\\\\\\ndiff --git a/Dataset/CSE20/raw/B160116CS_Aparna/B160116CS_2.jpeg b/Dataset/CSE20/raw/B160116CS_Aparna/B160116CS_2.jpeg\\\\\\\\\\\\\\\\nnew file mode 100644\\\\\\\\\\\\\\\\nindex 0000000..f91beaf\\\\\\\\\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160116CS_Aparna/B160116CS_2.jpeg differ\\\\\\\\\\\\\\\\ndiff --git a/Dataset/CSE20/raw/B160116CS_Aparna/B160116CS_3.jpeg b/Dataset/CSE20/raw/B160116CS_Aparna/B160116CS_3.jpeg\\\\\\\\\\\\\\\\nnew file mode 100644\\\\\\\\\\\\\\\\nindex 0000000..c0bab07\\\\\\\\\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160116CS_Aparna/B160116CS_3.jpeg differ\\\\\\\\\\\\\\\\ndiff --git a/Dataset/CSE20/raw/B160118CS_Neeraja/B160118CS_1.jpeg b/Dataset/CSE20/raw/B160118CS_Neeraja/B160118CS_1.jpeg\\\\\\\\\\\\\\\\nnew file mode 100644\\\\\\\\\\\\\\\\nindex 0000000..d7870a6\\\\\\\\\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160118CS_Neeraja/B160118CS_1.jpeg differ\\\\\\\\\\\\\\\\ndiff --git a/Dataset/CSE20/raw/B160118CS_Neeraja/B160118CS_2.jpeg b/Dataset/CSE20/raw/B160118CS_Neeraja/B160118CS_2.jpeg\\\\\\\\\\\\\\\\nnew file mode 100644\\\\\\\\\\\\\\\\nindex 0000000..0af9819\\\\\\\\\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160118CS_Neeraja/B160118CS_2.jpeg differ\\\\\\\\\\\\\\\\ndiff --git a/Dataset/CSE20/raw/B160118CS_Neeraja/B160118CS_3.jpeg b/Dataset/CSE20/raw/B160118CS_Neeraja/B160118CS_3.jpeg\\\\\\\\\\\\\\\\nnew file mode 100644\\\\\\\\\\\\\\\\nindex 0000000..1fa8fb3\\\\\\\\\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160118CS_Neeraja/B160118CS_3.jpeg differ\\\\\\\\\\\\\\\\ndiff --git a/Dataset/CSE20/raw/B160213CS_Nileena/B160213CS_1.jpeg b/Dataset/CSE20/raw/B160213CS_Nileena/B160213CS_1.jpeg\\\\\\\\\\\\\\\\nnew file mode 100644\\\\\\\\\\\\\\\\nindex 0000000..0571099\\\\\\\\\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160213CS_Nileena/B160213CS_1.jpeg differ\\\\\\\\\\\\\\\\ndiff --git a/Dataset/CSE20/raw/B160213CS_Nileena/B160213CS_2.jpeg b/Dataset/CSE20/raw/B160213CS_Nileena/B160213CS_2.jpeg\\\\\\\\\\\\\\\\nnew file mode 100644\\\\\\\\\\\\\\\\nindex 0000000..b834bd2\\\\\\\\\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160213CS_Nileena/B160213CS_2.jpeg differ\\\\\\\\\\\\\\\\ndiff --git a/Dataset/CSE20/raw/B160213CS_Nileena/B160213CS_3.jpeg b/Dataset/CSE20/raw/B160213CS_Nileena/B160213CS_3.jpeg\\\\\\\\\\\\\\\\nnew file mode 100644\\\\\\\\\\\\\\\\nindex 0000000..6f90c78\\\\\\\\\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160213CS_Nileena/B160213CS_3.jpeg differ\\\\\\\\\\\\\\\\ndiff --git a/Dataset/CSE20/raw/B160228CS_Vrindha/B160226CS_1.jpeg b/Dataset/CSE20/raw/B160228CS_Vrindha/B160226CS_1.jpeg\\\\\\\\\\\\\\\\nnew file mode 100644\\\\\\\\\\\\\\\\nindex 0000000..cc17e86\\\\\\\\\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160228CS_Vrindha/B160226CS_1.jpeg differ\\\\\\\\\\\\\\\\ndiff --git a/Dataset/CSE20/raw/B160228CS_Vrindha/B160226CS_2.jpeg b/Dataset/CSE20/raw/B160228CS_Vrindha/B160226CS_2.jpeg\\\\\\\\\\\\\\\\nnew file mode 100644\\\\\\\\\\\\\\\\nindex 0000000..f05098d\\\\\\\\\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160228CS_Vrindha/B160226CS_2.jpeg differ\\\\\\\\\\\\\\\\ndiff --git a/Dataset/CSE20/raw/B160228CS_Vrindha/B160226CS_3.jpeg b/Dataset/CSE20/raw/B160228CS_Vrindha/B160226CS_3.jpeg\\\\\\\\\\\\\\\\nnew file mode 100644\\\\\\\\\\\\\\\\nindex 0000000..bd97e68\\\\\\\\\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160228CS_Vrindha/B160226CS_3.jpeg differ\\\\\\\\\\\\\\\\ndiff --git a/Dataset/CSE20/raw/B160229CS_Reema/B160229CS_1.jpeg b/Dataset/CSE20/raw/B160229CS_Reema/B160229CS_1.jpeg\\\\\\\\\\\\\\\\nnew file mode 100644\\\\\\\\\\\\\\\\nindex 0000000..03232a8\\\\\\\\\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160229CS_Reema/B160229CS_1.jpeg differ\\\\\\\\\\\\\\\\ndiff --git a/Dataset/CSE20/raw/B160229CS_Reema/B160229CS_2.jpeg b/Dataset/CSE20/raw/B160229CS_Reema/B160229CS_2.jpeg\\\\\\\\\\\\\\\\nnew file mode 100644\\\\\\\\\\\\\\\\nindex 0000000..f2f9a82\\\\\\\\\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160229CS_Reema/B160229CS_2.jpeg differ\\\\\\\\\\\\\\\\ndiff --git a/Dataset/CSE20/raw/B160229CS_Reema/B160229CS_3.jpeg b/Dataset/CSE20/raw/B160229CS_Reema/B160229CS_3.jpeg\\\\\\\\\\\\\\\\nnew file mode 100644\\\\\\\\\\\\\\\\nindex 0000000..caced02\\\\\\\\\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160229CS_Reema/B160229CS_3.jpeg differ\\\\\\\\\\\\\\\\ndiff --git a/Dataset/CSE20/raw/B160270CS_Lakshmi/B160270CS_1.jpeg b/Dataset/CSE20/raw/B160270CS_Lakshmi/B160270CS_1.jpeg\\\\\\\\\\\\\\\\nnew file mode 100644\\\\\\\\\\\\\\\\nindex 0000000..b6d3dea\\\\\\\\\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160270CS_Lakshmi/B160270CS_1.jpeg differ\\\\\\\\\\\\\\\\ndiff --git a/Dataset/CSE20/raw/B160270CS_Lakshmi/B160270CS_2.jpeg b/Dataset/CSE20/raw/B160270CS_Lakshmi/B160270CS_2.jpeg\\\\\\\\\\\\\\\\nnew file mode 100644\\\\\\\\\\\\\\\\nindex 0000000..26ac294\\\\\\\\\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160270CS_Lakshmi/B160270CS_2.jpeg differ\\\\\\\\\\\\\\\\ndiff --git a/Dataset/CSE20/raw/B160270CS_Lakshmi/B160270CS_3.jpeg b/Dataset/CSE20/raw/B160270CS_Lakshmi/B160270CS_3.jpeg\\\\\\\\\\\\\\\\nnew file mode 100644\\\\\\\\\\\\\\\\nindex 0000000..670eb75\\\\\\\\\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160270CS_Lakshmi/B160270CS_3.jpeg differ\\\\\\\\\\\\\\\\ndiff --git a/Dataset/CSE20/raw/B160270CS_Lakshmi/B160270CS_4.jpeg b/Dataset/CSE20/raw/B160270CS_Lakshmi/B160270CS_4.jpeg\\\\\\\\\\\\\\\\nnew file mode 100644\\\\\\\\\\\\\\\\nindex 0000000..5fab205\\\\\\\\\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160270CS_Lakshmi/B160270CS_4.jpeg differ\\\\\\\\\\\\\\\\ndiff --git a/Dataset/CSE20/raw/B160270CS_Lakshmi/B160270CS_5.jpeg b/Dataset/CSE20/raw/B160270CS_Lakshmi/B160270CS_5.jpeg\\\\\\\\\\\\\\\\nnew file mode 100644\\\\\\\\\\\\\\\\nindex 0000000..32abaf3\\\\\\\\\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160270CS_Lakshmi/B160270CS_5.jpeg differ\\\\\\\\\\\\\\\\ndiff --git a/Dataset/CSE20/raw/B160320ME_Shebin/B160320ME_1.jpeg b/Dataset/CSE20/raw/B160320ME_Shebin/B160320ME_1.jpeg\\\\\\\\\\\\\\\\nnew file mode 100644\\\\\\\\\\\\\\\\nindex 0000000..2fd54a5\\\\\\\\\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160320ME_Shebin/B160320ME_1.jpeg differ\\\\\\\\\\\\\\\\ndiff --git a/Dataset/CSE20/raw/B160320ME_Shebin/B160320ME_2.jpeg b/Dataset/CSE20/raw/B160320ME_Shebin/B160320ME_2.jpeg\\\\\\\\\\\\\\\\nnew file mode 100644\\\\\\\\\\\\\\\\nindex 0000000..1e896db\\\\\\\\\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160320ME_Shebin/B160320ME_2.jpeg differ\\\\\\\\\\\\\\\\ndiff --git a/Dataset/CSE20/raw/B160320ME_Shebin/B160320ME_3.jpeg b/Dataset/CSE20/raw/B160320ME_Shebin/B160320ME_3.jpeg\\\\\\\\\\\\\\\\nnew file mode 100644\\\\\\\\\\\\\\\\nindex 0000000..2587d2d\\\\\\\\\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160320ME_Shebin/B160320ME_3.jpeg differ\\\\\\\\\\\\\\\\ndiff --git a/Dataset/CSE20/raw/B160408CS_Ameen/B160408CS_1.jpeg b/Dataset/CSE20/raw/B160408CS_Ameen/B160408CS_1.jpeg\\\\\\\\\\\\\\\\nnew file mode 100644\\\\\\\\\\\\\\\\nindex 0000000..1fa10aa\\\\\\\\\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160408CS_Ameen/B160408CS_1.jpeg differ\\\\\\\\\\\\\\\\ndiff --git a/Dataset/CSE20/raw/B160408CS_Ameen/B160408CS_2.jpeg b/Dataset/CSE20/raw/B160408CS_Ameen/B160408CS_2.jpeg\\\\\\\\\\\\\\\\nnew file mode 100644\\\\\\\\\\\\\\\\nindex 0000000..96b4941\\\\\\\\\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160408CS_Ameen/B160408CS_2.jpeg differ\\\\\\\\\\\\\\\\ndiff --git a/Dataset/CSE20/raw/B160408CS_Ameen/B160408CS_3.jpeg b/Dataset/CSE20/raw/B160408CS_Ameen/B160408CS_3.jpeg\\\\\\\\\\\\\\\\nnew file mode 100644\\\\\\\\\\\\\\\\nindex 0000000..f275bc4\\\\\\\\\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160408CS_Ameen/B160408CS_3.jpeg differ\\\\\\\\\\\\\\\\ndiff --git a/Dataset/CSE20/raw/B160445CS_Sumalatha/B160445CS_1.jpeg b/Dataset/CSE20/raw/B160445CS_Sumalatha/B160445CS_1.jpeg\\\\\\\\\\\\\\\\nnew file mode 100644\\\\\\\\\\\\\\\\nindex 0000000..c317aa8\\\\\\\\\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160445CS_Sumalatha/B160445CS_1.jpeg differ\\\\\\\\\\\\\\\\ndiff --git a/Dataset/CSE20/raw/B160445CS_Sumalatha/B160445CS_2.jpeg b/Dataset/CSE20/raw/B160445CS_Sumalatha/B160445CS_2.jpeg\\\\\\\\\\\\\\\\nnew file mode 100644\\\\\\\\\\\\\\\\nindex 0000000..5ab2818\\\\\\\\\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160445CS_Sumalatha/B160445CS_2.jpeg differ\\\\\\\\\\\\\\\\ndiff --git a/Dataset/CSE20/raw/B160445CS_Sumalatha/B160445CS_3.jpeg b/Dataset/CSE20/raw/B160445CS_Sumalatha/B160445CS_3.jpeg\\\\\\\\\\\\\\\\nnew file mode 100644\\\\\\\\\\\\\\\\nindex 0000000..0159b52\\\\\\\\\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160445CS_Sumalatha/B160445CS_3.jpeg differ\\\\\\\\\\\\\\\\ndiff --git a/Dataset/CSE20/raw/B160471CS_Dheeraj/B160471CS_1.jpeg b/Dataset/CSE20/raw/B160471CS_Dheeraj/B160471CS_1.jpeg\\\\\\\\\\\\\\\\nnew file mode 100644\\\\\\\\\\\\\\\\nindex 0000000..9d6bec9\\\\\\\\\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160471CS_Dheeraj/B160471CS_1.jpeg differ\\\\\\\\\\\\\\\\ndiff --git a/Dataset/CSE20/raw/B160688CS_Vishnu/B160688CS_1.jpg b/Dataset/CSE20/raw/B160688CS_Vishnu/B160688CS_1.jpg\\\\\\\\\\\\\\\\nnew file mode 100644\\\\\\\\\\\\\\\\nindex 0000000..537a4c0\\\\\\\\\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160688CS_Vishnu/B160688CS_1.jpg differ\\\\\\\\\\\\\\\\ndiff --git a/Dataset/CSE20/raw/B160688CS_Vishnu/B160688CS_2.jpg b/Dataset/CSE20/raw/B160688CS_Vishnu/B160688CS_2.jpg\\\\\\\\\\\\\\\\nnew file mode 100644\\\\\\\\\\\\\\\\nindex 0000000..0442b3d\\\\\\\\\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160688CS_Vishnu/B160688CS_2.jpg differ\\\\\\\\\\\\\\\\ndiff --git a/Dataset/CSE20/raw/B160688CS_Vishnu/B160688CS_3.jpeg b/Dataset/CSE20/raw/B160688CS_Vishnu/B160688CS_3.jpeg\\\\\\\\\\\\\\\\nnew file mode 100644\\\\\\\\\\\\\\\\nindex 0000000..460d134\\\\\\\\\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160688CS_Vishnu/B160688CS_3.jpeg differ\\\\\\\\\\\\\\\\ndiff --git a/Dataset/CSE20/raw/B160760CS_Vatsala/B160760CS_1.jpeg b/Dataset/CSE20/raw/B160760CS_Vatsala/B160760CS_1.jpeg\\\\\\\\\\\\\\\\nnew file mode 100644\\\\\\\\\\\\\\\\nindex 0000000..2856b8e\\\\\\\\\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160760CS_Vatsala/B160760CS_1.jpeg differ\\\\\\\\\\\\\\\\ndiff --git a/Dataset/CSE20/raw/B160760CS_Vatsala/B160760CS_2.jpeg b/Dataset/CSE20/raw/B160760CS_Vatsala/B160760CS_2.jpeg\\\\\\\\\\\\\\\\nnew file mode 100644\\\\\\\\\\\\\\\\nindex 0000000..76e5ceb\\\\\\\\\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160760CS_Vatsala/B160760CS_2.jpeg differ\\\\\\\\\\\\\\\\ndiff --git a/Dataset/CSE20/raw/B160760CS_Vatsala/B160760CS_3.jpeg b/Dataset/CSE20/raw/B160760CS_Vatsala/B160760CS_3.jpeg\\\\\\\\\\\\\\\\nnew file mode 100644\\\\\\\\\\\\\\\\nindex 0000000..f43a8a7\\\\\\\\\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160760CS_Vatsala/B160760CS_3.jpeg differ\\\\\\\\\\\\\\\\ndiff --git a/Dataset/CSE20/raw/B160873CS_Naina/B160873CS_1.jpg b/Dataset/CSE20/raw/B160873CS_Naina/B160873CS_1.jpg\\\\\\\\\\\\\\\\nnew file mode 100644\\\\\\\\\\\\\\\\nindex 0000000..0c66c88\\\\\\\\\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160873CS_Naina/B160873CS_1.jpg differ\\\\\\\\\\\\\\\\ndiff --git a/Dataset/CSE20/raw/B160873CS_Naina/B160873CS_2.jpg b/Dataset/CSE20/raw/B160873CS_Naina/B160873CS_2.jpg\\\\\\\\\\\\\\\\nnew file mode 100644\\\\\\\\\\\\\\\\nindex 0000000..ad8c724\\\\\\\\\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160873CS_Naina/B160873CS_2.jpg differ\\\\\\\\\\\\\\\\ndiff --git a/Dataset/CSE20/raw/B160873CS_Naina/B160873CS_3.png b/Dataset/CSE20/raw/B160873CS_Naina/B160873CS_3.png\\\\\\\\\\\\\\\\nnew file mode 100644\\\\\\\\\\\\\\\\nindex 0000000..361493f\\\\\\\\\\\\\\\\nBinary files /dev/null and b/Dataset/CSE20/raw/B160873CS_Naina/B160873CS_3.png differ\\\\\\\\\\\\\\\\ndiff --git a/Models/CSE20/CSE20.pkl b/Models/CSE20/CSE20.pkl\\\\\\\\\\\\\\\\nnew file mode 100644\\\\\\\\\\\\\\\\nindex 0000000..3793ef7\\\\\\\\\\\\\\\\nBinary files /dev/null and b/Models/CSE20/CSE20.pkl differ\\\\\\\\\\\\\\\\ndiff --git a/Models/facenet/20180402-114759.pb b/Models/facenet/20180402-114759.pb\\\\\\\\\\\\\\\\nnew file mode 100644\\\\\\\\\\\\\\\\nindex 0000000..39b4ed7\\\\\\\\\\\\\\\\nBinary files /dev/null and b/Models/facenet/20180402-114759.pb differ\\\\\\\\\\\\\\\\ndiff --git a/Models/facenet/model-20180402-114759.ckpt-275.data-00000-of-00001 b/Models/facenet/model-20180402-114759.ckpt-275.data-00000-of-00001\\\\\\\\\\\\\\\\nnew file mode 100755\\\\\\\\\\\\\\\\nindex 0000000..6160198\\\\\\\\\\\\\\\\nBinary files /dev/null and b/Models/facenet/model-20180402-114759.ckpt-275.data-00000-of-00001 differ\\\\\\\\\\\\\\\\ndiff --git a/Models/facenet/model-20180402-114759.ckpt-275.index b/Models/facenet/model-20180402-114759.ckpt-275.index\\\\\\\\\\\\\\\\nnew file mode 100755\\\\\\\\\\\\\\\\nindex 0000000..e2b346c\\\\\\\\\\\\\\\\nBinary files /dev/null and b/Models/facenet/model-20180402-114759.ckpt-275.index differ\\\\\\\\\\\\\\\\ndiff --git a/Models/facenet/model-20180402-114759.meta b/Models/facenet/model-20180402-114759.meta\\\\\\\\\\\\\\\\nnew file mode 100755\\\\\\\\\\\\\\\\nindex 0000000..abffaef\\\\\\\\\\\\\\\\nBinary files /dev/null and b/Models/facenet/model-20180402-114759.meta differ\\\\\\\\\\\\\\\\ndiff --git a/src/align/align_dataset_mtcnn.py b/src/align/align_dataset_mtcnn.py\\\\\\\\\\\\\\\\nindex 7d5e735..21f1457 100644\\\\\\\\\\\\\\\\n--- a/src/align/align_dataset_mtcnn.py\\\\\\\\\\\\\\\\n+++ b/src/align/align_dataset_mtcnn.py\\\\\\\\\\\\\\\\n@@ -31,8 +31,8 @@ import os\\\\\\\\\\\\\\\\n import argparse\\\\\\\\\\\\\\\\n import tensorflow as tf\\\\\\\\\\\\\\\\n import numpy as np\\\\\\\\\\\\\\\\n-import facenet\\\\\\\\\\\\\\\\n-import align.detect_face\\\\\\\\\\\\\\\\n+import facenet.src.facenet as facenet   #changed\\\\\\\\\\\\\\\\n+import detect_face  #changed\\\\\\\\\\\\\\\\n import random\\\\\\\\\\\\\\\\n from time import sleep\\\\\\\\\\\\\\\\n \\\\\\\\\\\\\\\\ndiff --git a/src/align/detect_face.py b/src/align/detect_face.py\\\\\\\\\\\\\\\\nindex 7f98ca7..3806b33 100644\\\\\\\\\\\\\\\\n--- a/src/align/detect_face.py\\\\\\\\\\\\\\\\n+++ b/src/align/detect_face.py\\\\\\\\\\\\\\\\n@@ -82,7 +82,10 @@ class Network(object):\\\\\\\\\\\\\\\\n         session: The current TensorFlow session\\\\\\\\\\\\\\\\n         ignore_missing: If true, serialized weights for missing layers are ignored.\\\\\\\\\\\\\\\\n         """\\\\\\\\\\\\\\\\n+        np_load_old = np.load\\\\\\\\\\\\\\\\n+        np.load = lambda *a, **k: np_load_old(*a, allow_pickle=True, **k)\\\\\\\\\\\\\\\\n         data_dict = np.load(data_path, encoding=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'latin1\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\').item() #pylint: disable=no-member\\\\\\\\\\\\\\\\n+        np.load = np_load_old\\\\\\\\\\\\\\\\n \\\\\\\\\\\\\\\\n         for op_name in data_dict:\\\\\\\\\\\\\\\\n             with tf.variable_scope(op_name, reuse=True):\\\\\\\\\\\\\\\\ndiff --git a/src/align_dataset_mtcnn.py b/src/align_dataset_mtcnn.py\\\\\\\\\\\\\\\\nnew file mode 100644\\\\\\\\\\\\\\\\nindex 0000000..2c2acc4\\\\\\\\\\\\\\\\n--- /dev/null\\\\\\\\\\\\\\\\n+++ b/src/align_dataset_mtcnn.py\\\\\\\\\\\\\\\\n@@ -0,0 +1,161 @@\\\\\\\\\\\\\\\\n+"""Performs face alignment and stores face thumbnails in the output directory."""\\\\\\\\\\\\\\\\n+# MIT License\\\\\\\\\\\\\\\\n+# \\\\\\\\\\\\\\\\n+# Copyright (c) 2016 David Sandberg\\\\\\\\\\\\\\\\n+# \\\\\\\\\\\\\\\\n+# Permission is hereby granted, free of charge, to any person obtaining a copy\\\\\\\\\\\\\\\\n+# of this software and associated documentation files (the "Software"), to deal\\\\\\\\\\\\\\\\n+# in the Software without restriction, including without limitation the rights\\\\\\\\\\\\\\\\n+# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\\\\\\\\\\\\\\\n+# copies of the Software, and to permit persons to whom the Software is\\\\\\\\\\\\\\\\n+# furnished to do so, subject to the following conditions:\\\\\\\\\\\\\\\\n+# \\\\\\\\\\\\\\\\n+# The above copyright notice and this permission notice shall be included in all\\\\\\\\\\\\\\\\n+# copies or substantial portions of the Software.\\\\\\\\\\\\\\\\n+# \\\\\\\\\\\\\\\\n+# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\\\\\\\\\\\\\\\n+# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\\\\\\\\\\\\\\\n+# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\\\\\\\\\\\\\\\n+# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\\\\\\\\\\\\\\\n+# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\\\\\\\\\\\\\\\n+# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\\\\\\\\\\\\\\\n+# SOFTWARE.\\\\\\\\\\\\\\\\n+\\\\\\\\\\\\\\\\n+from __future__ import absolute_import\\\\\\\\\\\\\\\\n+from __future__ import division\\\\\\\\\\\\\\\\n+from __future__ import print_function\\\\\\\\\\\\\\\\n+\\\\\\\\\\\\\\\\n+from scipy import misc\\\\\\\\\\\\\\\\n+import imageio #for imread since it\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'s depricated in scipy.misc\\\\\\\\\\\\\\\\n+import skimage #for imresize since it\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'s depricated in scipy.misc\\\\\\\\\\\\\\\\n+import sys\\\\\\\\\\\\\\\\n+import os\\\\\\\\\\\\\\\\n+import argparse\\\\\\\\\\\\\\\\n+import tensorflow as tf\\\\\\\\\\\\\\\\n+import numpy as np\\\\\\\\\\\\\\\\n+import facenet\\\\\\\\\\\\\\\\n+import align.detect_face\\\\\\\\\\\\\\\\n+import random\\\\\\\\\\\\\\\\n+from time import sleep\\\\\\\\\\\\\\\\n+\\\\\\\\\\\\\\\\n+def main(args):\\\\\\\\\\\\\\\\n+    sleep(random.random())\\\\\\\\\\\\\\\\n+    output_dir = os.path.expanduser(args.output_dir)\\\\\\\\\\\\\\\\n+    if not os.path.exists(output_dir):\\\\\\\\\\\\\\\\n+        os.makedirs(output_dir)\\\\\\\\\\\\\\\\n+    # Store some git revision info in a text file in the log directory\\\\\\\\\\\\\\\\n+    src_path,_ = os.path.split(os.path.realpath(__file__))\\\\\\\\\\\\\\\\n+    facenet.store_revision_info(src_path, output_dir, \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\' \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'.join(sys.argv))\\\\\\\\\\\\\\\\n+    dataset = facenet.get_dataset(args.input_dir)\\\\\\\\\\\\\\\\n+    \\\\\\\\\\\\\\\\n+    print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'Creating networks and loading parameters\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\')\\\\\\\\\\\\\\\\n+    \\\\\\\\\\\\\\\\n+    with tf.Graph().as_default():\\\\\\\\\\\\\\\\n+        gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=args.gpu_memory_fraction)\\\\\\\\\\\\\\\\n+        sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options, log_device_placement=False))\\\\\\\\\\\\\\\\n+        with sess.as_default():\\\\\\\\\\\\\\\\n+            pnet, rnet, onet = align.detect_face.create_mtcnn(sess, None)\\\\\\\\\\\\\\\\n+    \\\\\\\\\\\\\\\\n+    minsize = 20 # minimum size of face\\\\\\\\\\\\\\\\n+    threshold = [ 0.6, 0.7, 0.7 ]  # three steps\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'s threshold\\\\\\\\\\\\\\\\n+    factor = 0.709 # scale factor\\\\\\\\\\\\\\\\n+\\\\\\\\\\\\\\\\n+    # Add a random key to the filename to allow alignment using multiple processes\\\\\\\\\\\\\\\\n+    random_key = np.random.randint(0, high=99999)\\\\\\\\\\\\\\\\n+    bounding_boxes_filename = os.path.join(output_dir, \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'bounding_boxes_%05d.txt\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\' % random_key)\\\\\\\\\\\\\\\\n+    \\\\\\\\\\\\\\\\n+    with open(bounding_boxes_filename, "w") as text_file:\\\\\\\\\\\\\\\\n+        nrof_images_total = 0\\\\\\\\\\\\\\\\n+        nrof_successfully_aligned = 0\\\\\\\\\\\\\\\\n+        if args.random_order:\\\\\\\\\\\\\\\\n+            random.shuffle(dataset)\\\\\\\\\\\\\\\\n+        for cls in dataset:\\\\\\\\\\\\\\\\n+            output_class_dir = os.path.join(output_dir, cls.name)\\\\\\\\\\\\\\\\n+            if not os.path.exists(output_class_dir):\\\\\\\\\\\\\\\\n+                os.makedirs(output_class_dir)\\\\\\\\\\\\\\\\n+                if args.random_order:\\\\\\\\\\\\\\\\n+                    random.shuffle(cls.image_paths)\\\\\\\\\\\\\\\\n+            for image_path in cls.image_paths:\\\\\\\\\\\\\\\\n+                nrof_images_total += 1\\\\\\\\\\\\\\\\n+                filename = os.path.splitext(os.path.split(image_path)[1])[0]\\\\\\\\\\\\\\\\n+                output_filename = os.path.join(output_class_dir, filename+\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'.png\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\')\\\\\\\\\\\\\\\\n+                print(image_path)\\\\\\\\\\\\\\\\n+                if not os.path.exists(output_filename):\\\\\\\\\\\\\\\\n+                    try:\\\\\\\\\\\\\\\\n+                        img = imageio.imread(image_path)\\\\\\\\\\\\\\\\n+                    except (IOError, ValueError, IndexError) as e:\\\\\\\\\\\\\\\\n+                        errorMessage = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'{}: {}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'.format(image_path, e)\\\\\\\\\\\\\\\\n+                        print(errorMessage)\\\\\\\\\\\\\\\\n+                    else:\\\\\\\\\\\\\\\\n+                        if img.ndim<2:\\\\\\\\\\\\\\\\n+                            print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'Unable to align "%s"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\' % image_path)\\\\\\\\\\\\\\\\n+                            text_file.write(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'%s\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\' % (output_filename))\\\\\\\\\\\\\\\\n+                            continue\\\\\\\\\\\\\\\\n+                        if img.ndim == 2:\\\\\\\\\\\\\\\\n+                            img = facenet.to_rgb(img)\\\\\\\\\\\\\\\\n+                        img = img[:,:,0:3]\\\\\\\\\\\\\\\\n+    \\\\\\\\\\\\\\\\n+                        bounding_boxes, _ = align.detect_face.detect_face(img, minsize, pnet, rnet, onet, threshold, factor)\\\\\\\\\\\\\\\\n+                        nrof_faces = bounding_boxes.shape[0]\\\\\\\\\\\\\\\\n+                        if nrof_faces>0:\\\\\\\\\\\\\\\\n+                            det = bounding_boxes[:,0:4]\\\\\\\\\\\\\\\\n+                            det_arr = []\\\\\\\\\\\\\\\\n+                            img_size = np.asarray(img.shape)[0:2]\\\\\\\\\\\\\\\\n+                            if nrof_faces>1:\\\\\\\\\\\\\\\\n+                                if args.detect_multiple_faces:\\\\\\\\\\\\\\\\n+                                    for i in range(nrof_faces):\\\\\\\\\\\\\\\\n+                                        det_arr.append(np.squeeze(det[i]))\\\\\\\\\\\\\\\\n+                                else:\\\\\\\\\\\\\\\\n+                                    bounding_box_size = (det[:,2]-det[:,0])*(det[:,3]-det[:,1])\\\\\\\\\\\\\\\\n+                                    img_center = img_size / 2\\\\\\\\\\\\\\\\n+                                    offsets = np.vstack([ (det[:,0]+det[:,2])/2-img_center[1], (det[:,1]+det[:,3])/2-img_center[0] ])\\\\\\\\\\\\\\\\n+                                    offset_dist_squared = np.sum(np.power(offsets,2.0),0)\\\\\\\\\\\\\\\\n+                                    index = np.argmax(bounding_box_size-offset_dist_squared*2.0) # some extra weight on the centering\\\\\\\\\\\\\\\\n+                                    det_arr.append(det[index,:])\\\\\\\\\\\\\\\\n+                            else:\\\\\\\\\\\\\\\\n+                                det_arr.append(np.squeeze(det))\\\\\\\\\\\\\\\\n+\\\\\\\\\\\\\\\\n+                            for i, det in enumerate(det_arr):\\\\\\\\\\\\\\\\n+                                det = np.squeeze(det)\\\\\\\\\\\\\\\\n+                                bb = np.zeros(4, dtype=np.int32)\\\\\\\\\\\\\\\\n+                                bb[0] = np.maximum(det[0]-args.margin/2, 0)\\\\\\\\\\\\\\\\n+                                bb[1] = np.maximum(det[1]-args.margin/2, 0)\\\\\\\\\\\\\\\\n+                                bb[2] = np.minimum(det[2]+args.margin/2, img_size[1])\\\\\\\\\\\\\\\\n+                                bb[3] = np.minimum(det[3]+args.margin/2, img_size[0])\\\\\\\\\\\\\\\\n+                                cropped = img[bb[1]:bb[3],bb[0]:bb[2],:]\\\\\\\\\\\\\\\\n+                                scaled = skimage.transform.resize(cropped, (args.image_size, args.image_size))\\\\\\\\\\\\\\\\n+                                nrof_successfully_aligned += 1\\\\\\\\\\\\\\\\n+                                filename_base, file_extension = os.path.splitext(output_filename)\\\\\\\\\\\\\\\\n+                                if args.detect_multiple_faces:\\\\\\\\\\\\\\\\n+                                    output_filename_n = "{}_{}{}".format(filename_base, i, file_extension)\\\\\\\\\\\\\\\\n+                                else:\\\\\\\\\\\\\\\\n+                                    output_filename_n = "{}{}".format(filename_base, file_extension)\\\\\\\\\\\\\\\\n+                                imageio.imwrite(output_filename_n, scaled)\\\\\\\\\\\\\\\\n+                                text_file.write(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'%s %d %d %d %d\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\' % (output_filename_n, bb[0], bb[1], bb[2], bb[3]))\\\\\\\\\\\\\\\\n+                        else:\\\\\\\\\\\\\\\\n+                            print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'Unable to align "%s"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\' % image_path)\\\\\\\\\\\\\\\\n+                            text_file.write(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'%s\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\' % (output_filename))\\\\\\\\\\\\\\\\n+                            \\\\\\\\\\\\\\\\n+    print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'Total number of images: %d\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\' % nrof_images_total)\\\\\\\\\\\\\\\\n+    print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'Number of successfully aligned images: %d\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\' % nrof_successfully_aligned)\\\\\\\\\\\\\\\\n+            \\\\\\\\\\\\\\\\n+\\\\\\\\\\\\\\\\n+def parse_arguments(argv):\\\\\\\\\\\\\\\\n+    parser = argparse.ArgumentParser()\\\\\\\\\\\\\\\\n+    \\\\\\\\\\\\\\\\n+    parser.add_argument(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'input_dir\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\', type=str, help=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'Directory with unaligned images.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\')\\\\\\\\\\\\\\\\n+    parser.add_argument(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'output_dir\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\', type=str, help=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'Directory with aligned face thumbnails.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\')\\\\\\\\\\\\\\\\n+    parser.add_argument(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'--image_size\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\', type=int,\\\\\\\\\\\\\\\\n+        help=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'Image size (height, width) in pixels.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\', default=182)\\\\\\\\\\\\\\\\n+    parser.add_argument(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'--margin\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\', type=int,\\\\\\\\\\\\\\\\n+        help=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'Margin for the crop around the bounding box (height, width) in pixels.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\', default=44)\\\\\\\\\\\\\\\\n+    parser.add_argument(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'--random_order\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\', \\\\\\\\\\\\\\\\n+        help=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'Shuffles the order of images to enable alignment using multiple processes.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\', action=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'store_true\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\')\\\\\\\\\\\\\\\\n+    parser.add_argument(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'--gpu_memory_fraction\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\', type=float,\\\\\\\\\\\\\\\\n+        help=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'Upper bound on the amount of GPU memory that will be used by the process.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\', default=1.0)\\\\\\\\\\\\\\\\n+    parser.add_argument(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'--detect_multiple_faces\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\', type=bool,\\\\\\\\\\\\\\\\n+                        help=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'Detect and align multiple faces per image.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\', default=False)\\\\\\\\\\\\\\\\n+    return parser.parse_args(argv)\\\\\\\\\\\\\\\\n+\\\\\\\\\\\\\\\\n+if __name__ == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'__main__\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\':\\\\\\\\\\\\\\\\n+    main(parse_arguments(sys.argv[1:]))\\\\\\\\\\\\\\\\ndiff --git a/src/faceRec.py b/src/faceRec.py\\\\\\\\\\\\\\\\nnew file mode 100644\\\\\\\\\\\\\\\\nindex 0000000..a5531a2\\\\\\\\\\\\\\\\n--- /dev/null\\\\\\\\\\\\\\\\n+++ b/src/faceRec.py\\\\\\\\\\\\\\\\n@@ -0,0 +1,117 @@\\\\\\\\\\\\\\\\n+from __future__ import absolute_import\\\\\\\\\\\\\\\\n+from __future__ import division\\\\\\\\\\\\\\\\n+from __future__ import print_function\\\\\\\\\\\\\\\\n+\\\\\\\\\\\\\\\\n+import tensorflow as tf\\\\\\\\\\\\\\\\n+import argparse\\\\\\\\\\\\\\\\n+import facenet\\\\\\\\\\\\\\\\n+import os\\\\\\\\\\\\\\\\n+import sys\\\\\\\\\\\\\\\\n+import math\\\\\\\\\\\\\\\\n+import pickle\\\\\\\\\\\\\\\\n+import align.detect_face\\\\\\\\\\\\\\\\n+import numpy as np\\\\\\\\\\\\\\\\n+import cv2\\\\\\\\\\\\\\\\n+import collections\\\\\\\\\\\\\\\\n+from sklearn.svm import SVC\\\\\\\\\\\\\\\\n+\\\\\\\\\\\\\\\\n+\\\\\\\\\\\\\\\\n+def main():\\\\\\\\\\\\\\\\n+    parser = argparse.ArgumentParser()\\\\\\\\\\\\\\\\n+    parser.add_argument(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'--path\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\', help=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'Path of the video you want to test on.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\', default=0)\\\\\\\\\\\\\\\\n+    args = parser.parse_args()\\\\\\\\\\\\\\\\n+\\\\\\\\\\\\\\\\n+    MINSIZE = 20\\\\\\\\\\\\\\\\n+    THRESHOLD = [0.6, 0.7, 0.7]\\\\\\\\\\\\\\\\n+    FACTOR = 0.709\\\\\\\\\\\\\\\\n+    IMAGE_SIZE = 182\\\\\\\\\\\\\\\\n+    INPUT_IMAGE_SIZE = 160\\\\\\\\\\\\\\\\n+    CLASSIFIER_PATH = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'Models/CSE20/CSE20.pkl\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\\n+    VIDEO_PATH = args.path\\\\\\\\\\\\\\\\n+    FACENET_MODEL_PATH = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'Models/facenet/20180402-114759.pb\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\\n+\\\\\\\\\\\\\\\\n+    # Load The Custom Classifier\\\\\\\\\\\\\\\\n+    with open(CLASSIFIER_PATH, \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'rb\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\') as file:\\\\\\\\\\\\\\\\n+        model, class_names = pickle.load(file)\\\\\\\\\\\\\\\\n+    print("Custom Classifier, Successfully loaded")\\\\\\\\\\\\\\\\n+\\\\\\\\\\\\\\\\n+    with tf.Graph().as_default():\\\\\\\\\\\\\\\\n+\\\\\\\\\\\\\\\\n+        gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.6)\\\\\\\\\\\\\\\\n+        sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options, log_device_placement=False))\\\\\\\\\\\\\\\\n+\\\\\\\\\\\\\\\\n+        with sess.as_default():\\\\\\\\\\\\\\\\n+\\\\\\\\\\\\\\\\n+            # Load the model\\\\\\\\\\\\\\\\n+            print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'Loading feature extraction model\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\')\\\\\\\\\\\\\\\\n+            facenet.load_model(FACENET_MODEL_PATH)\\\\\\\\\\\\\\\\n+\\\\\\\\\\\\\\\\n+            # Get input and output tensors\\\\\\\\\\\\\\\\n+            images_placeholder = tf.get_default_graph().get_tensor_by_name("input:0")\\\\\\\\\\\\\\\\n+            embeddings = tf.get_default_graph().get_tensor_by_name("embeddings:0")\\\\\\\\\\\\\\\\n+            phase_train_placeholder = tf.get_default_graph().get_tensor_by_name("phase_train:0")\\\\\\\\\\\\\\\\n+            embedding_size = embeddings.get_shape()[1]\\\\\\\\\\\\\\\\n+\\\\\\\\\\\\\\\\n+            pnet, rnet, onet = align.detect_face.create_mtcnn(sess, "./src/align")\\\\\\\\\\\\\\\\n+\\\\\\\\\\\\\\\\n+            people_detected = set()\\\\\\\\\\\\\\\\n+            person_detected = collections.Counter()\\\\\\\\\\\\\\\\n+\\\\\\\\\\\\\\\\n+            cap = cv2.VideoCapture(VIDEO_PATH)\\\\\\\\\\\\\\\\n+\\\\\\\\\\\\\\\\n+            while (cap.isOpened()):\\\\\\\\\\\\\\\\n+                ret, frame = cap.read()\\\\\\\\\\\\\\\\n+\\\\\\\\\\\\\\\\n+                bounding_boxes, _ = align.detect_face.detect_face(frame, MINSIZE, pnet, rnet, onet, THRESHOLD, FACTOR)\\\\\\\\\\\\\\\\n+\\\\\\\\\\\\\\\\n+                faces_found = bounding_boxes.shape[0]\\\\\\\\\\\\\\\\n+                try:\\\\\\\\\\\\\\\\n+                    if faces_found > 0:\\\\\\\\\\\\\\\\n+                        det = bounding_boxes[:, 0:4]\\\\\\\\\\\\\\\\n+                        bb = np.zeros((faces_found, 4), dtype=np.int32)\\\\\\\\\\\\\\\\n+                        for i in range(faces_found):\\\\\\\\\\\\\\\\n+                            bb[i][0] = det[i][0]\\\\\\\\\\\\\\\\n+                            bb[i][1] = det[i][1]\\\\\\\\\\\\\\\\n+                            bb[i][2] = det[i][2]\\\\\\\\\\\\\\\\n+                            bb[i][3] = det[i][3]\\\\\\\\\\\\\\\\n+\\\\\\\\\\\\\\\\n+                            cropped = frame[bb[i][1]:bb[i][3], bb[i][0]:bb[i][2], :]\\\\\\\\\\\\\\\\n+                            scaled = cv2.resize(cropped, (INPUT_IMAGE_SIZE, INPUT_IMAGE_SIZE),\\\\\\\\\\\\\\\\n+                                                interpolation=cv2.INTER_CUBIC)\\\\\\\\\\\\\\\\n+                            scaled = facenet.prewhiten(scaled)\\\\\\\\\\\\\\\\n+                            scaled_reshape = scaled.reshape(-1, INPUT_IMAGE_SIZE, INPUT_IMAGE_SIZE, 3)\\\\\\\\\\\\\\\\n+                            feed_dict = {images_placeholder: scaled_reshape, phase_train_placeholder: False}\\\\\\\\\\\\\\\\n+                            emb_array = sess.run(embeddings, feed_dict=feed_dict)\\\\\\\\\\\\\\\\n+                            predictions = model.predict_proba(emb_array)\\\\\\\\\\\\\\\\n+                            best_class_indices = np.argmax(predictions, axis=1)\\\\\\\\\\\\\\\\n+                            best_class_probabilities = predictions[\\\\\\\\\\\\\\\\n+                                np.arange(len(best_class_indices)), best_class_indices]\\\\\\\\\\\\\\\\n+                            best_name = class_names[best_class_indices[0]]\\\\\\\\\\\\\\\\n+                            print("Name: {}, Probability: {}".format(best_name, best_class_probabilities))\\\\\\\\\\\\\\\\n+\\\\\\\\\\\\\\\\n+                            cv2.rectangle(frame, (bb[i][0], bb[i][1]), (bb[i][2], bb[i][3]), (0, 255, 0), 2)\\\\\\\\\\\\\\\\n+                            text_x = bb[i][0]\\\\\\\\\\\\\\\\n+                            text_y = bb[i][3] + 20\\\\\\\\\\\\\\\\n+\\\\\\\\\\\\\\\\n+                            if best_class_probabilities > 0.15:\\\\\\\\\\\\\\\\n+                                name = class_names[best_class_indices[0]]\\\\\\\\\\\\\\\\n+                            else:\\\\\\\\\\\\\\\\n+                                name = "Unknown"\\\\\\\\\\\\\\\\n+                            cv2.putText(frame, name, (text_x, text_y), cv2.FONT_HERSHEY_COMPLEX_SMALL,\\\\\\\\\\\\\\\\n+                                        1, (255, 255, 255), thickness=1, lineType=2)\\\\\\\\\\\\\\\\n+                            cv2.putText(frame, str(round(best_class_probabilities[0], 3)), (text_x, text_y + 17),\\\\\\\\\\\\\\\\n+                                        cv2.FONT_HERSHEY_COMPLEX_SMALL,\\\\\\\\\\\\\\\\n+                                        1, (255, 255, 255), thickness=1, lineType=2)\\\\\\\\\\\\\\\\n+                            person_detected[best_name] += 1\\\\\\\\\\\\\\\\n+                except:\\\\\\\\\\\\\\\\n+                    pass\\\\\\\\\\\\\\\\n+\\\\\\\\\\\\\\\\n+                cv2.imshow(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'Face Recognition\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\', frame)\\\\\\\\\\\\\\\\n+                if cv2.waitKey(1) & 0xFF == ord(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'q\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'):\\\\\\\\\\\\\\\\n+                    break\\\\\\\\\\\\\\\\n+\\\\\\\\\\\\\\\\n+            cap.release()\\\\\\\\\\\\\\\\n+            cv2.destroyAllWindows()\\\\\\\\\\\\\\\\n+\\\\\\\\\\\\\\\\n+\\\\\\\\\\\\\\\\n+main()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ No newline at end of file\\\\\\\\\\\\\\\\ndiff --git a/src/facenet.py b/src/facenet.py\\\\\\\\\\\\\\\\nindex 0e05676..538b650 100644\\\\\\\\\\\\\\\\n--- a/src/facenet.py\\\\\\\\\\\\\\\\n+++ b/src/facenet.py\\\\\\\\\\\\\\\\n@@ -32,6 +32,7 @@ from subprocess import Popen, PIPE\\\\\\\\\\\\\\\\n import tensorflow as tf\\\\\\\\\\\\\\\\n import numpy as np\\\\\\\\\\\\\\\\n from scipy import misc\\\\\\\\\\\\\\\\n+import imageio\\\\\\\\\\\\\\\\n from sklearn.model_selection import KFold\\\\\\\\\\\\\\\\n from scipy import interpolate\\\\\\\\\\\\\\\\n from tensorflow.python.training import training\\\\\\\\\\\\\\\\n@@ -244,7 +245,7 @@ def load_data(image_paths, do_random_crop, do_random_flip, image_size, do_prewhi\\\\\\\\\\\\\\\\n     nrof_samples = len(image_paths)\\\\\\\\\\\\\\\\n     images = np.zeros((nrof_samples, image_size, image_size, 3))\\\\\\\\\\\\\\\\n     for i in range(nrof_samples):\\\\\\\\\\\\\\\\n-        img = misc.imread(image_paths[i])\\\\\\\\\\\\\\\\n+        img = imageio.imread(image_paths[i])\\\\\\\\\\\\\\\\n         if img.ndim == 2:\\\\\\\\\\\\\\\\n             img = to_rgb(img)\\\\\\\\\\\\\\\\n         if do_prewhiten:\\\\\\\\\\\\\\\'\\\\\\\\n-\\\\\\\\\\\\\\\\ No newline at end of file\\\\\\\\n-diff --git a/main/Dataset/CSE20/raw/B160116CS_Aparna/B160116CS_1.jpeg b/main/Dataset/CSE20/raw/B160116CS_Aparna/B160116CS_1.jpeg\\\\\\\\n-index e23a8fc..d50e775 100644\\\\\\\\n-Binary files a/main/Dataset/CSE20/raw/B160116CS_Aparna/B160116CS_1.jpeg and b/main/Dataset/CSE20/raw/B160116CS_Aparna/B160116CS_1.jpeg differ\\\\\\\\n-diff --git a/main/README.md b/main/README.md\\\\\\\\n-index 9220d20..baaeced 100644\\\\\\\\n---- a/main/README.md\\\\\\\\n-+++ b/main/README.md\\\\\\\\n-@@ -53,3 +53,4 @@ A couple of pretrained models are provided. They are trained using softmax loss\\\\\\\\n- \\\\\\\\n- ## Performance\\\\\\\\n- The accuracy on LFW for the model [20180402-114759](https://drive.google.com/open?id=1EXPBSXwTaqrSC0OhUdXNmKSh9qJUQ55-) is 0.99650+-0.00252. A description of how to run the test can be found on the page [Validate on LFW](https://github.com/davidsandberg/facenet/wiki/Validate-on-lfw). Note that the input images to the model need to be standardized using fixed image standardization (use the option `--use_fixed_image_standardization` when running e.g. `validate_on_lfw.py`).\\\\\\\\n-+\\\\\\\\n-diff --git a/main/requirements.txt b/main/requirements.txt\\\\\\\\n-index b7418c9..167b725 100644\\\\\\\\n---- a/main/requirements.txt\\\\\\\\n-+++ b/main/requirements.txt\\\\\\\\n-@@ -7,3 +7,5 @@ matplotlib\\\\\\\\n- Pillow\\\\\\\\n- requests\\\\\\\\n- psutil\\\\\\\\n-+imageio\\\\\\\\n-+scikit-image\\\\\\\\n\\\\\\\\\\\\\\\\ No newline at end of file\\\\\\\\n+b\\\\\\\\\\\\\\\'diff --git a/main/requirements.txt b/main/requirements.txt\\\\\\\\\\\\\\\\nindex 167b725..558415a 100644\\\\\\\\\\\\\\\\n--- a/main/requirements.txt\\\\\\\\\\\\\\\\n+++ b/main/requirements.txt\\\\\\\\\\\\\\\\n@@ -1,11 +1,50 @@\\\\\\\\\\\\\\\\n-tensorflow==1.7\\\\\\\\\\\\\\\\n-scipy\\\\\\\\\\\\\\\\n-scikit-learn\\\\\\\\\\\\\\\\n-opencv-python\\\\\\\\\\\\\\\\n-h5py\\\\\\\\\\\\\\\\n-matplotlib\\\\\\\\\\\\\\\\n-Pillow\\\\\\\\\\\\\\\\n-requests\\\\\\\\\\\\\\\\n-psutil\\\\\\\\\\\\\\\\n-imageio\\\\\\\\\\\\\\\\n-scikit-image\\\\\\\\\\\\\\\\n+absl-py==0.8.1\\\\\\\\\\\\\\\\n+align==0.0.5\\\\\\\\\\\\\\\\n+astor==0.8.0\\\\\\\\\\\\\\\\n+bleach==1.5.0\\\\\\\\\\\\\\\\n+boto==2.49.0\\\\\\\\\\\\\\\\n+boto3==1.9.245\\\\\\\\\\\\\\\\n+botocore==1.12.245\\\\\\\\\\\\\\\\n+certifi==2019.9.11\\\\\\\\\\\\\\\\n+chardet==3.0.4\\\\\\\\\\\\\\\\n+cycler==0.10.0\\\\\\\\\\\\\\\\n+decorator==4.4.0\\\\\\\\\\\\\\\\n+docutils==0.15.2\\\\\\\\\\\\\\\\n+facenet==1.0.5\\\\\\\\\\\\\\\\n+gast==0.3.2\\\\\\\\\\\\\\\\n+gensim==3.8.1\\\\\\\\\\\\\\\\n+grpcio==1.24.1\\\\\\\\\\\\\\\\n+h5py==2.10.0\\\\\\\\\\\\\\\\n+html5lib==0.9999999\\\\\\\\\\\\\\\\n+idna==2.8\\\\\\\\\\\\\\\\n+imageio==2.6.1\\\\\\\\\\\\\\\\n+jmespath==0.9.4\\\\\\\\\\\\\\\\n+joblib==0.14.0\\\\\\\\\\\\\\\\n+kiwisolver==1.1.0\\\\\\\\\\\\\\\\n+Markdown==3.1.1\\\\\\\\\\\\\\\\n+matplotlib==3.0.3\\\\\\\\\\\\\\\\n+networkx==2.3\\\\\\\\\\\\\\\\n+nltk==3.4.5\\\\\\\\\\\\\\\\n+numpy==1.17.2\\\\\\\\\\\\\\\\n+opencv-python==4.1.1.26\\\\\\\\\\\\\\\\n+pandas==0.24.2\\\\\\\\\\\\\\\\n+Pillow==6.2.0\\\\\\\\\\\\\\\\n+protobuf==3.10.0\\\\\\\\\\\\\\\\n+psutil==5.6.3\\\\\\\\\\\\\\\\n+pyparsing==2.4.2\\\\\\\\\\\\\\\\n+python-dateutil==2.8.0\\\\\\\\\\\\\\\\n+pytz==2019.3\\\\\\\\\\\\\\\\n+PyWavelets==1.0.3\\\\\\\\\\\\\\\\n+requests==2.22.0\\\\\\\\\\\\\\\\n+s3transfer==0.2.1\\\\\\\\\\\\\\\\n+scikit-image==0.15.0\\\\\\\\\\\\\\\\n+scikit-learn==0.21.3\\\\\\\\\\\\\\\\n+scipy==1.3.1\\\\\\\\\\\\\\\\n+six==1.12.0\\\\\\\\\\\\\\\\n+sklearn==0.0\\\\\\\\\\\\\\\\n+smart-open==1.8.4\\\\\\\\\\\\\\\\n+tensorboard==1.7.0\\\\\\\\\\\\\\\\n+tensorflow==1.7.0\\\\\\\\\\\\\\\\n+termcolor==1.1.0\\\\\\\\\\\\\\\\n+urllib3==1.25.6\\\\\\\\\\\\\\\\n+Werkzeug==0.16.0\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ No newline at end of file\\\\\\\\\\\\\\\\ndiff --git a/main/src/align/align_dataset_mtcnn.py b/main/src/align/align_dataset_mtcnn.py\\\\\\\\\\\\\\\\ndeleted file mode 100644\\\\\\\\\\\\\\\\nindex 21f1457..0000000\\\\\\\\\\\\\\\\n--- a/main/src/align/align_dataset_mtcnn.py\\\\\\\\\\\\\\\\n+++ /dev/null\\\\\\\\\\\\\\\\n@@ -1,159 +0,0 @@\\\\\\\\\\\\\\\\n-"""Performs face alignment and stores face thumbnails in the output directory."""\\\\\\\\\\\\\\\\n-# MIT License\\\\\\\\\\\\\\\\n-# \\\\\\\\\\\\\\\\n-# Copyright (c) 2016 David Sandberg\\\\\\\\\\\\\\\\n-# \\\\\\\\\\\\\\\\n-# Permission is hereby granted, free of charge, to any person obtaining a copy\\\\\\\\\\\\\\\\n-# of this software and associated documentation files (the "Software"), to deal\\\\\\\\\\\\\\\\n-# in the Software without restriction, including without limitation the rights\\\\\\\\\\\\\\\\n-# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\\\\\\\\\\\\\\\n-# copies of the Software, and to permit persons to whom the Software is\\\\\\\\\\\\\\\\n-# furnished to do so, subject to the following conditions:\\\\\\\\\\\\\\\\n-# \\\\\\\\\\\\\\\\n-# The above copyright notice and this permission notice shall be included in all\\\\\\\\\\\\\\\\n-# copies or substantial portions of the Software.\\\\\\\\\\\\\\\\n-# \\\\\\\\\\\\\\\\n-# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\\\\\\\\\\\\\\\n-# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\\\\\\\\\\\\\\\n-# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\\\\\\\\\\\\\\\n-# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\\\\\\\\\\\\\\\n-# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\\\\\\\\\\\\\\\n-# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\\\\\\\\\\\\\\\n-# SOFTWARE.\\\\\\\\\\\\\\\\n-\\\\\\\\\\\\\\\\n-from __future__ import absolute_import\\\\\\\\\\\\\\\\n-from __future__ import division\\\\\\\\\\\\\\\\n-from __future__ import print_function\\\\\\\\\\\\\\\\n-\\\\\\\\\\\\\\\\n-from scipy import misc\\\\\\\\\\\\\\\\n-import sys\\\\\\\\\\\\\\\\n-import os\\\\\\\\\\\\\\\\n-import argparse\\\\\\\\\\\\\\\\n-import tensorflow as tf\\\\\\\\\\\\\\\\n-import numpy as np\\\\\\\\\\\\\\\\n-import facenet.src.facenet as facenet   #changed\\\\\\\\\\\\\\\\n-import detect_face  #changed\\\\\\\\\\\\\\\\n-import random\\\\\\\\\\\\\\\\n-from time import sleep\\\\\\\\\\\\\\\\n-\\\\\\\\\\\\\\\\n-def main(args):\\\\\\\\\\\\\\\\n-    sleep(random.random())\\\\\\\\\\\\\\\\n-    output_dir = os.path.expanduser(args.output_dir)\\\\\\\\\\\\\\\\n-    if not os.path.exists(output_dir):\\\\\\\\\\\\\\\\n-        os.makedirs(output_dir)\\\\\\\\\\\\\\\\n-    # Store some git revision info in a text file in the log directory\\\\\\\\\\\\\\\\n-    src_path,_ = os.path.split(os.path.realpath(__file__))\\\\\\\\\\\\\\\\n-    facenet.store_revision_info(src_path, output_dir, \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\' \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'.join(sys.argv))\\\\\\\\\\\\\\\\n-    dataset = facenet.get_dataset(args.input_dir)\\\\\\\\\\\\\\\\n-    \\\\\\\\\\\\\\\\n-    print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'Creating networks and loading parameters\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\')\\\\\\\\\\\\\\\\n-    \\\\\\\\\\\\\\\\n-    with tf.Graph().as_default():\\\\\\\\\\\\\\\\n-        gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=args.gpu_memory_fraction)\\\\\\\\\\\\\\\\n-        sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options, log_device_placement=False))\\\\\\\\\\\\\\\\n-        with sess.as_default():\\\\\\\\\\\\\\\\n-            pnet, rnet, onet = align.detect_face.create_mtcnn(sess, None)\\\\\\\\\\\\\\\\n-    \\\\\\\\\\\\\\\\n-    minsize = 20 # minimum size of face\\\\\\\\\\\\\\\\n-    threshold = [ 0.6, 0.7, 0.7 ]  # three steps\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'s threshold\\\\\\\\\\\\\\\\n-    factor = 0.709 # scale factor\\\\\\\\\\\\\\\\n-\\\\\\\\\\\\\\\\n-    # Add a random key to the filename to allow alignment using multiple processes\\\\\\\\\\\\\\\\n-    random_key = np.random.randint(0, high=99999)\\\\\\\\\\\\\\\\n-    bounding_boxes_filename = os.path.join(output_dir, \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'bounding_boxes_%05d.txt\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\' % random_key)\\\\\\\\\\\\\\\\n-    \\\\\\\\\\\\\\\\n-    with open(bounding_boxes_filename, "w") as text_file:\\\\\\\\\\\\\\\\n-        nrof_images_total = 0\\\\\\\\\\\\\\\\n-        nrof_successfully_aligned = 0\\\\\\\\\\\\\\\\n-        if args.random_order:\\\\\\\\\\\\\\\\n-            random.shuffle(dataset)\\\\\\\\\\\\\\\\n-        for cls in dataset:\\\\\\\\\\\\\\\\n-            output_class_dir = os.path.join(output_dir, cls.name)\\\\\\\\\\\\\\\\n-            if not os.path.exists(output_class_dir):\\\\\\\\\\\\\\\\n-                os.makedirs(output_class_dir)\\\\\\\\\\\\\\\\n-                if args.random_order:\\\\\\\\\\\\\\\\n-                    random.shuffle(cls.image_paths)\\\\\\\\\\\\\\\\n-            for image_path in cls.image_paths:\\\\\\\\\\\\\\\\n-                nrof_images_total += 1\\\\\\\\\\\\\\\\n-                filename = os.path.splitext(os.path.split(image_path)[1])[0]\\\\\\\\\\\\\\\\n-                output_filename = os.path.join(output_class_dir, filename+\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'.png\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\')\\\\\\\\\\\\\\\\n-                print(image_path)\\\\\\\\\\\\\\\\n-                if not os.path.exists(output_filename):\\\\\\\\\\\\\\\\n-                    try:\\\\\\\\\\\\\\\\n-                        img = misc.imread(image_path)\\\\\\\\\\\\\\\\n-                    except (IOError, ValueError, IndexError) as e:\\\\\\\\\\\\\\\\n-                        errorMessage = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'{}: {}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'.format(image_path, e)\\\\\\\\\\\\\\\\n-                        print(errorMessage)\\\\\\\\\\\\\\\\n-                    else:\\\\\\\\\\\\\\\\n-                        if img.ndim<2:\\\\\\\\\\\\\\\\n-                            print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'Unable to align "%s"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\' % image_path)\\\\\\\\\\\\\\\\n-                            text_file.write(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'%s\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\' % (output_filename))\\\\\\\\\\\\\\\\n-                            continue\\\\\\\\\\\\\\\\n-                        if img.ndim == 2:\\\\\\\\\\\\\\\\n-                            img = facenet.to_rgb(img)\\\\\\\\\\\\\\\\n-                        img = img[:,:,0:3]\\\\\\\\\\\\\\\\n-    \\\\\\\\\\\\\\\\n-                        bounding_boxes, _ = align.detect_face.detect_face(img, minsize, pnet, rnet, onet, threshold, factor)\\\\\\\\\\\\\\\\n-                        nrof_faces = bounding_boxes.shape[0]\\\\\\\\\\\\\\\\n-                        if nrof_faces>0:\\\\\\\\\\\\\\\\n-                            det = bounding_boxes[:,0:4]\\\\\\\\\\\\\\\\n-                            det_arr = []\\\\\\\\\\\\\\\\n-                            img_size = np.asarray(img.shape)[0:2]\\\\\\\\\\\\\\\\n-                            if nrof_faces>1:\\\\\\\\\\\\\\\\n-                                if args.detect_multiple_faces:\\\\\\\\\\\\\\\\n-                                    for i in range(nrof_faces):\\\\\\\\\\\\\\\\n-                                        det_arr.append(np.squeeze(det[i]))\\\\\\\\\\\\\\\\n-                                else:\\\\\\\\\\\\\\\\n-                                    bounding_box_size = (det[:,2]-det[:,0])*(det[:,3]-det[:,1])\\\\\\\\\\\\\\\\n-                                    img_center = img_size / 2\\\\\\\\\\\\\\\\n-                                    offsets = np.vstack([ (det[:,0]+det[:,2])/2-img_center[1], (det[:,1]+det[:,3])/2-img_center[0] ])\\\\\\\\\\\\\\\\n-                                    offset_dist_squared = np.sum(np.power(offsets,2.0),0)\\\\\\\\\\\\\\\\n-                                    index = np.argmax(bounding_box_size-offset_dist_squared*2.0) # some extra weight on the centering\\\\\\\\\\\\\\\\n-                                    det_arr.append(det[index,:])\\\\\\\\\\\\\\\\n-                            else:\\\\\\\\\\\\\\\\n-                                det_arr.append(np.squeeze(det))\\\\\\\\\\\\\\\\n-\\\\\\\\\\\\\\\\n-                            for i, det in enumerate(det_arr):\\\\\\\\\\\\\\\\n-                                det = np.squeeze(det)\\\\\\\\\\\\\\\\n-                                bb = np.zeros(4, dtype=np.int32)\\\\\\\\\\\\\\\\n-                                bb[0] = np.maximum(det[0]-args.margin/2, 0)\\\\\\\\\\\\\\\\n-                                bb[1] = np.maximum(det[1]-args.margin/2, 0)\\\\\\\\\\\\\\\\n-                                bb[2] = np.minimum(det[2]+args.margin/2, img_size[1])\\\\\\\\\\\\\\\\n-                                bb[3] = np.minimum(det[3]+args.margin/2, img_size[0])\\\\\\\\\\\\\\\\n-                                cropped = img[bb[1]:bb[3],bb[0]:bb[2],:]\\\\\\\\\\\\\\\\n-                                scaled = misc.imresize(cropped, (args.image_size, args.image_size), interp=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'bilinear\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\')\\\\\\\\\\\\\\\\n-                                nrof_successfully_aligned += 1\\\\\\\\\\\\\\\\n-                                filename_base, file_extension = os.path.splitext(output_filename)\\\\\\\\\\\\\\\\n-                                if args.detect_multiple_faces:\\\\\\\\\\\\\\\\n-                                    output_filename_n = "{}_{}{}".format(filename_base, i, file_extension)\\\\\\\\\\\\\\\\n-                                else:\\\\\\\\\\\\\\\\n-                                    output_filename_n = "{}{}".format(filename_base, file_extension)\\\\\\\\\\\\\\\\n-                                misc.imsave(output_filename_n, scaled)\\\\\\\\\\\\\\\\n-                                text_file.write(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'%s %d %d %d %d\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\' % (output_filename_n, bb[0], bb[1], bb[2], bb[3]))\\\\\\\\\\\\\\\\n-                        else:\\\\\\\\\\\\\\\\n-                            print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'Unable to align "%s"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\' % image_path)\\\\\\\\\\\\\\\\n-                            text_file.write(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'%s\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\' % (output_filename))\\\\\\\\\\\\\\\\n-                            \\\\\\\\\\\\\\\\n-    print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'Total number of images: %d\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\' % nrof_images_total)\\\\\\\\\\\\\\\\n-    print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'Number of successfully aligned images: %d\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\' % nrof_successfully_aligned)\\\\\\\\\\\\\\\\n-            \\\\\\\\\\\\\\\\n-\\\\\\\\\\\\\\\\n-def parse_arguments(argv):\\\\\\\\\\\\\\\\n-    parser = argparse.ArgumentParser()\\\\\\\\\\\\\\\\n-    \\\\\\\\\\\\\\\\n-    parser.add_argument(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'input_dir\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\', type=str, help=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'Directory with unaligned images.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\')\\\\\\\\\\\\\\\\n-    parser.add_argument(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'output_dir\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\', type=str, help=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'Directory with aligned face thumbnails.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\')\\\\\\\\\\\\\\\\n-    parser.add_argument(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'--image_size\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\', type=int,\\\\\\\\\\\\\\\\n-        help=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'Image size (height, width) in pixels.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\', default=182)\\\\\\\\\\\\\\\\n-    parser.add_argument(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'--margin\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\', type=int,\\\\\\\\\\\\\\\\n-        help=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'Margin for the crop around the bounding box (height, width) in pixels.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\', default=44)\\\\\\\\\\\\\\\\n-    parser.add_argument(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'--random_order\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\', \\\\\\\\\\\\\\\\n-        help=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'Shuffles the order of images to enable alignment using multiple processes.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\', action=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'store_true\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\')\\\\\\\\\\\\\\\\n-    parser.add_argument(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'--gpu_memory_fraction\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\', type=float,\\\\\\\\\\\\\\\\n-        help=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'Upper bound on the amount of GPU memory that will be used by the process.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\', default=1.0)\\\\\\\\\\\\\\\\n-    parser.add_argument(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'--detect_multiple_faces\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\', type=bool,\\\\\\\\\\\\\\\\n-                        help=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'Detect and align multiple faces per image.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\', default=False)\\\\\\\\\\\\\\\\n-    return parser.parse_args(argv)\\\\\\\\\\\\\\\\n-\\\\\\\\\\\\\\\\n-if __name__ == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'__main__\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\':\\\\\\\\\\\\\\\\n-    main(parse_arguments(sys.argv[1:]))\\\\\\\\\\\\\\\'\\\\\\\\n\\\\\\\\\\\\\\\\ No newline at end of file\\\\\\\\ndiff --git a/main/Models/CSE20/CSE20.pkl b/main/Models/CSE20/CSE20.pkl\\\\\\\\nindex 3266061..e162f5b 100644\\\\\\\\nBinary files a/main/Models/CSE20/CSE20.pkl and b/main/Models/CSE20/CSE20.pkl differ\\\\\\\\ndiff --git a/main/requirements.txt b/main/requirements.txt\\\\\\\\nindex 167b725..558415a 100644\\\\\\\\n--- a/main/requirements.txt\\\\\\\\n+++ b/main/requirements.txt\\\\\\\\n@@ -1,11 +1,50 @@\\\\\\\\n-tensorflow==1.7\\\\\\\\n-scipy\\\\\\\\n-scikit-learn\\\\\\\\n-opencv-python\\\\\\\\n-h5py\\\\\\\\n-matplotlib\\\\\\\\n-Pillow\\\\\\\\n-requests\\\\\\\\n-psutil\\\\\\\\n-imageio\\\\\\\\n-scikit-image\\\\\\\\n+absl-py==0.8.1\\\\\\\\n+align==0.0.5\\\\\\\\n+astor==0.8.0\\\\\\\\n+bleach==1.5.0\\\\\\\\n+boto==2.49.0\\\\\\\\n+boto3==1.9.245\\\\\\\\n+botocore==1.12.245\\\\\\\\n+certifi==2019.9.11\\\\\\\\n+chardet==3.0.4\\\\\\\\n+cycler==0.10.0\\\\\\\\n+decorator==4.4.0\\\\\\\\n+docutils==0.15.2\\\\\\\\n+facenet==1.0.5\\\\\\\\n+gast==0.3.2\\\\\\\\n+gensim==3.8.1\\\\\\\\n+grpcio==1.24.1\\\\\\\\n+h5py==2.10.0\\\\\\\\n+html5lib==0.9999999\\\\\\\\n+idna==2.8\\\\\\\\n+imageio==2.6.1\\\\\\\\n+jmespath==0.9.4\\\\\\\\n+joblib==0.14.0\\\\\\\\n+kiwisolver==1.1.0\\\\\\\\n+Markdown==3.1.1\\\\\\\\n+matplotlib==3.0.3\\\\\\\\n+networkx==2.3\\\\\\\\n+nltk==3.4.5\\\\\\\\n+numpy==1.17.2\\\\\\\\n+opencv-python==4.1.1.26\\\\\\\\n+pandas==0.24.2\\\\\\\\n+Pillow==6.2.0\\\\\\\\n+protobuf==3.10.0\\\\\\\\n+psutil==5.6.3\\\\\\\\n+pyparsing==2.4.2\\\\\\\\n+python-dateutil==2.8.0\\\\\\\\n+pytz==2019.3\\\\\\\\n+PyWavelets==1.0.3\\\\\\\\n+requests==2.22.0\\\\\\\\n+s3transfer==0.2.1\\\\\\\\n+scikit-image==0.15.0\\\\\\\\n+scikit-learn==0.21.3\\\\\\\\n+scipy==1.3.1\\\\\\\\n+six==1.12.0\\\\\\\\n+sklearn==0.0\\\\\\\\n+smart-open==1.8.4\\\\\\\\n+tensorboard==1.7.0\\\\\\\\n+tensorflow==1.7.0\\\\\\\\n+termcolor==1.1.0\\\\\\\\n+urllib3==1.25.6\\\\\\\\n+Werkzeug==0.16.0\\\\\\\\n\\\\\\\\\\\\\\\\ No newline at end of file\\\\\\\\ndiff --git a/main/src/align/align_dataset_mtcnn.py b/main/src/align/align_dataset_mtcnn.py\\\\\\\\ndeleted file mode 100644\\\\\\\\nindex 21f1457..0000000\\\\\\\\n--- a/main/src/align/align_dataset_mtcnn.py\\\\\\\\n+++ /dev/null\\\\\\\\n@@ -1,159 +0,0 @@\\\\\\\\n-"""Performs face alignment and stores face thumbnails in the output directory."""\\\\\\\\n-# MIT License\\\\\\\\n-# \\\\\\\\n-# Copyright (c) 2016 David Sandberg\\\\\\\\n-# \\\\\\\\n-# Permission is hereby granted, free of charge, to any person obtaining a copy\\\\\\\\n-# of this software and associated documentation files (the "Software"), to deal\\\\\\\\n-# in the Software without restriction, including without limitation the rights\\\\\\\\n-# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\\\\\\\n-# copies of the Software, and to permit persons to whom the Software is\\\\\\\\n-# furnished to do so, subject to the following conditions:\\\\\\\\n-# \\\\\\\\n-# The above copyright notice and this permission notice shall be included in all\\\\\\\\n-# copies or substantial portions of the Software.\\\\\\\\n-# \\\\\\\\n-# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\\\\\\\n-# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\\\\\\\n-# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\\\\\\\n-# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\\\\\\\n-# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\\\\\\\n-# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\\\\\\\n-# SOFTWARE.\\\\\\\\n-\\\\\\\\n-from __future__ import absolute_import\\\\\\\\n-from __future__ import division\\\\\\\\n-from __future__ import print_function\\\\\\\\n-\\\\\\\\n-from scipy import misc\\\\\\\\n-import sys\\\\\\\\n-import os\\\\\\\\n-import argparse\\\\\\\\n-import tensorflow as tf\\\\\\\\n-import numpy as np\\\\\\\\n-import facenet.src.facenet as facenet   #changed\\\\\\\\n-import detect_face  #changed\\\\\\\\n-import random\\\\\\\\n-from time import sleep\\\\\\\\n-\\\\\\\\n-def main(args):\\\\\\\\n-    sleep(random.random())\\\\\\\\n-    output_dir = os.path.expanduser(args.output_dir)\\\\\\\\n-    if not os.path.exists(output_dir):\\\\\\\\n-        os.makedirs(output_dir)\\\\\\\\n-    # Store some git revision info in a text file in the log directory\\\\\\\\n-    src_path,_ = os.path.split(os.path.realpath(__file__))\\\\\\\\n-    facenet.store_revision_info(src_path, output_dir, \\\\\\\\\\\\\\\' \\\\\\\\\\\\\\\'.join(sys.argv))\\\\\\\\n-    dataset = facenet.get_dataset(args.input_dir)\\\\\\\\n-    \\\\\\\\n-    print(\\\\\\\\\\\\\\\'Creating networks and loading parameters\\\\\\\\\\\\\\\')\\\\\\\\n-    \\\\\\\\n-    with tf.Graph().as_default():\\\\\\\\n-        gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=args.gpu_memory_fraction)\\\\\\\\n-        sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options, log_device_placement=False))\\\\\\\\n-        with sess.as_default():\\\\\\\\n-            pnet, rnet, onet = align.detect_face.create_mtcnn(sess, None)\\\\\\\\n-    \\\\\\\\n-    minsize = 20 # minimum size of face\\\\\\\\n-    threshold = [ 0.6, 0.7, 0.7 ]  # three steps\\\\\\\\\\\\\\\'s threshold\\\\\\\\n-    factor = 0.709 # scale factor\\\\\\\\n-\\\\\\\\n-    # Add a random key to the filename to allow alignment using multiple processes\\\\\\\\n-    random_key = np.random.randint(0, high=99999)\\\\\\\\n-    bounding_boxes_filename = os.path.join(output_dir, \\\\\\\\\\\\\\\'bounding_boxes_%05d.txt\\\\\\\\\\\\\\\' % random_key)\\\\\\\\n-    \\\\\\\\n-    with open(bounding_boxes_filename, "w") as text_file:\\\\\\\\n-        nrof_images_total = 0\\\\\\\\n-        nrof_successfully_aligned = 0\\\\\\\\n-        if args.random_order:\\\\\\\\n-            random.shuffle(dataset)\\\\\\\\n-        for cls in dataset:\\\\\\\\n-            output_class_dir = os.path.join(output_dir, cls.name)\\\\\\\\n-            if not os.path.exists(output_class_dir):\\\\\\\\n-                os.makedirs(output_class_dir)\\\\\\\\n-                if args.random_order:\\\\\\\\n-                    random.shuffle(cls.image_paths)\\\\\\\\n-            for image_path in cls.image_paths:\\\\\\\\n-                nrof_images_total += 1\\\\\\\\n-                filename = os.path.splitext(os.path.split(image_path)[1])[0]\\\\\\\\n-                output_filename = os.path.join(output_class_dir, filename+\\\\\\\\\\\\\\\'.png\\\\\\\\\\\\\\\')\\\\\\\\n-                print(image_path)\\\\\\\\n-                if not os.path.exists(output_filename):\\\\\\\\n-                    try:\\\\\\\\n-                        img = misc.imread(image_path)\\\\\\\\n-                    except (IOError, ValueError, IndexError) as e:\\\\\\\\n-                        errorMessage = \\\\\\\\\\\\\\\'{}: {}\\\\\\\\\\\\\\\'.format(image_path, e)\\\\\\\\n-                        print(errorMessage)\\\\\\\\n-                    else:\\\\\\\\n-                        if img.ndim<2:\\\\\\\\n-                            print(\\\\\\\\\\\\\\\'Unable to align "%s"\\\\\\\\\\\\\\\' % image_path)\\\\\\\\n-                            text_file.write(\\\\\\\\\\\\\\\'%s\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\' % (output_filename))\\\\\\\\n-                            continue\\\\\\\\n-                        if img.ndim == 2:\\\\\\\\n-                            img = facenet.to_rgb(img)\\\\\\\\n-                        img = img[:,:,0:3]\\\\\\\\n-    \\\\\\\\n-                        bounding_boxes, _ = align.detect_face.detect_face(img, minsize, pnet, rnet, onet, threshold, factor)\\\\\\\\n-                        nrof_faces = bounding_boxes.shape[0]\\\\\\\\n-                        if nrof_faces>0:\\\\\\\\n-                            det = bounding_boxes[:,0:4]\\\\\\\\n-                            det_arr = []\\\\\\\\n-                            img_size = np.asarray(img.shape)[0:2]\\\\\\\\n-                            if nrof_faces>1:\\\\\\\\n-                                if args.detect_multiple_faces:\\\\\\\\n-                                    for i in range(nrof_faces):\\\\\\\\n-                                        det_arr.append(np.squeeze(det[i]))\\\\\\\\n-                                else:\\\\\\\\n-                                    bounding_box_size = (det[:,2]-det[:,0])*(det[:,3]-det[:,1])\\\\\\\\n-                                    img_center = img_size / 2\\\\\\\\n-                                    offsets = np.vstack([ (det[:,0]+det[:,2])/2-img_center[1], (det[:,1]+det[:,3])/2-img_center[0] ])\\\\\\\\n-                                    offset_dist_squared = np.sum(np.power(offsets,2.0),0)\\\\\\\\n-                                    index = np.argmax(bounding_box_size-offset_dist_squared*2.0) # some extra weight on the centering\\\\\\\\n-                                    det_arr.append(det[index,:])\\\\\\\\n-                            else:\\\\\\\\n-                                det_arr.append(np.squeeze(det))\\\\\\\\n-\\\\\\\\n-                            for i, det in enumerate(det_arr):\\\\\\\\n-                                det = np.squeeze(det)\\\\\\\\n-                                bb = np.zeros(4, dtype=np.int32)\\\\\\\\n-                                bb[0] = np.maximum(det[0]-args.margin/2, 0)\\\\\\\\n-                                bb[1] = np.maximum(det[1]-args.margin/2, 0)\\\\\\\\n-                                bb[2] = np.minimum(det[2]+args.margin/2, img_size[1])\\\\\\\\n-                                bb[3] = np.minimum(det[3]+args.margin/2, img_size[0])\\\\\\\\n-                                cropped = img[bb[1]:bb[3],bb[0]:bb[2],:]\\\\\\\\n-                                scaled = misc.imresize(cropped, (args.image_size, args.image_size), interp=\\\\\\\\\\\\\\\'bilinear\\\\\\\\\\\\\\\')\\\\\\\\n-                                nrof_successfully_aligned += 1\\\\\\\\n-                                filename_base, file_extension = os.path.splitext(output_filename)\\\\\\\\n-                                if args.detect_multiple_faces:\\\\\\\\n-                                    output_filename_n = "{}_{}{}".format(filename_base, i, file_extension)\\\\\\\\n-                                else:\\\\\\\\n-                                    output_filename_n = "{}{}".format(filename_base, file_extension)\\\\\\\\n-                                misc.imsave(output_filename_n, scaled)\\\\\\\\n-                                text_file.write(\\\\\\\\\\\\\\\'%s %d %d %d %d\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\' % (output_filename_n, bb[0], bb[1], bb[2], bb[3]))\\\\\\\\n-                        else:\\\\\\\\n-                            print(\\\\\\\\\\\\\\\'Unable to align "%s"\\\\\\\\\\\\\\\' % image_path)\\\\\\\\n-                            text_file.write(\\\\\\\\\\\\\\\'%s\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\' % (output_filename))\\\\\\\\n-                            \\\\\\\\n-    print(\\\\\\\\\\\\\\\'Total number of images: %d\\\\\\\\\\\\\\\' % nrof_images_total)\\\\\\\\n-    print(\\\\\\\\\\\\\\\'Number of successfully aligned images: %d\\\\\\\\\\\\\\\' % nrof_successfully_aligned)\\\\\\\\n-            \\\\\\\\n-\\\\\\\\n-def parse_arguments(argv):\\\\\\\\n-    parser = argparse.ArgumentParser()\\\\\\\\n-    \\\\\\\\n-    parser.add_argument(\\\\\\\\\\\\\\\'input_dir\\\\\\\\\\\\\\\', type=str, help=\\\\\\\\\\\\\\\'Directory with unaligned images.\\\\\\\\\\\\\\\')\\\\\\\\n-    parser.add_argument(\\\\\\\\\\\\\\\'output_dir\\\\\\\\\\\\\\\', type=str, help=\\\\\\\\\\\\\\\'Directory with aligned face thumbnails.\\\\\\\\\\\\\\\')\\\\\\\\n-    parser.add_argument(\\\\\\\\\\\\\\\'--image_size\\\\\\\\\\\\\\\', type=int,\\\\\\\\n-        help=\\\\\\\\\\\\\\\'Image size (height, width) in pixels.\\\\\\\\\\\\\\\', default=182)\\\\\\\\n-    parser.add_argument(\\\\\\\\\\\\\\\'--margin\\\\\\\\\\\\\\\', type=int,\\\\\\\\n-        help=\\\\\\\\\\\\\\\'Margin for the crop around the bounding box (height, width) in pixels.\\\\\\\\\\\\\\\', default=44)\\\\\\\\n-    parser.add_argument(\\\\\\\\\\\\\\\'--random_order\\\\\\\\\\\\\\\', \\\\\\\\n-        help=\\\\\\\\\\\\\\\'Shuffles the order of images to enable alignment using multiple processes.\\\\\\\\\\\\\\\', action=\\\\\\\\\\\\\\\'store_true\\\\\\\\\\\\\\\')\\\\\\\\n-    parser.add_argument(\\\\\\\\\\\\\\\'--gpu_memory_fraction\\\\\\\\\\\\\\\', type=float,\\\\\\\\n-        help=\\\\\\\\\\\\\\\'Upper bound on the amount of GPU memory that will be used by the process.\\\\\\\\\\\\\\\', default=1.0)\\\\\\\\n-    parser.add_argument(\\\\\\\\\\\\\\\'--detect_multiple_faces\\\\\\\\\\\\\\\', type=bool,\\\\\\\\n-                        help=\\\\\\\\\\\\\\\'Detect and align multiple faces per image.\\\\\\\\\\\\\\\', default=False)\\\\\\\\n-    return parser.parse_args(argv)\\\\\\\\n-\\\\\\\\n-if __name__ == \\\\\\\\\\\\\\\'__main__\\\\\\\\\\\\\\\':\\\\\\\\n-    main(parse_arguments(sys.argv[1:]))\\\\\\\'\\\\n\\\\\\\\ No newline at end of file\\\\ndiff --git a/main/Models/CSE20/CSE20.pkl b/main/Models/CSE20/CSE20.pkl\\\\nindex 3266061..0778a5e 100644\\\\nBinary files a/main/Models/CSE20/CSE20.pkl and b/main/Models/CSE20/CSE20.pkl differ\\\\ndiff --git a/main/requirements.txt b/main/requirements.txt\\\\nindex 167b725..558415a 100644\\\\n--- a/main/requirements.txt\\\\n+++ b/main/requirements.txt\\\\n@@ -1,11 +1,50 @@\\\\n-tensorflow==1.7\\\\n-scipy\\\\n-scikit-learn\\\\n-opencv-python\\\\n-h5py\\\\n-matplotlib\\\\n-Pillow\\\\n-requests\\\\n-psutil\\\\n-imageio\\\\n-scikit-image\\\\n+absl-py==0.8.1\\\\n+align==0.0.5\\\\n+astor==0.8.0\\\\n+bleach==1.5.0\\\\n+boto==2.49.0\\\\n+boto3==1.9.245\\\\n+botocore==1.12.245\\\\n+certifi==2019.9.11\\\\n+chardet==3.0.4\\\\n+cycler==0.10.0\\\\n+decorator==4.4.0\\\\n+docutils==0.15.2\\\\n+facenet==1.0.5\\\\n+gast==0.3.2\\\\n+gensim==3.8.1\\\\n+grpcio==1.24.1\\\\n+h5py==2.10.0\\\\n+html5lib==0.9999999\\\\n+idna==2.8\\\\n+imageio==2.6.1\\\\n+jmespath==0.9.4\\\\n+joblib==0.14.0\\\\n+kiwisolver==1.1.0\\\\n+Markdown==3.1.1\\\\n+matplotlib==3.0.3\\\\n+networkx==2.3\\\\n+nltk==3.4.5\\\\n+numpy==1.17.2\\\\n+opencv-python==4.1.1.26\\\\n+pandas==0.24.2\\\\n+Pillow==6.2.0\\\\n+protobuf==3.10.0\\\\n+psutil==5.6.3\\\\n+pyparsing==2.4.2\\\\n+python-dateutil==2.8.0\\\\n+pytz==2019.3\\\\n+PyWavelets==1.0.3\\\\n+requests==2.22.0\\\\n+s3transfer==0.2.1\\\\n+scikit-image==0.15.0\\\\n+scikit-learn==0.21.3\\\\n+scipy==1.3.1\\\\n+six==1.12.0\\\\n+sklearn==0.0\\\\n+smart-open==1.8.4\\\\n+tensorboard==1.7.0\\\\n+tensorflow==1.7.0\\\\n+termcolor==1.1.0\\\\n+urllib3==1.25.6\\\\n+Werkzeug==0.16.0\\\\n\\\\\\\\ No newline at end of file\\\\ndiff --git a/main/src/align/align_dataset_mtcnn.py b/main/src/align/align_dataset_mtcnn.py\\\\ndeleted file mode 100644\\\\nindex 21f1457..0000000\\\\n--- a/main/src/align/align_dataset_mtcnn.py\\\\n+++ /dev/null\\\\n@@ -1,159 +0,0 @@\\\\n-"""Performs face alignment and stores face thumbnails in the output directory."""\\\\n-# MIT License\\\\n-# \\\\n-# Copyright (c) 2016 David Sandberg\\\\n-# \\\\n-# Permission is hereby granted, free of charge, to any person obtaining a copy\\\\n-# of this software and associated documentation files (the "Software"), to deal\\\\n-# in the Software without restriction, including without limitation the rights\\\\n-# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\\\n-# copies of the Software, and to permit persons to whom the Software is\\\\n-# furnished to do so, subject to the following conditions:\\\\n-# \\\\n-# The above copyright notice and this permission notice shall be included in all\\\\n-# copies or substantial portions of the Software.\\\\n-# \\\\n-# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\\\n-# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\\\n-# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\\\n-# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\\\n-# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\\\n-# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\\\n-# SOFTWARE.\\\\n-\\\\n-from __future__ import absolute_import\\\\n-from __future__ import division\\\\n-from __future__ import print_function\\\\n-\\\\n-from scipy import misc\\\\n-import sys\\\\n-import os\\\\n-import argparse\\\\n-import tensorflow as tf\\\\n-import numpy as np\\\\n-import facenet.src.facenet as facenet   #changed\\\\n-import detect_face  #changed\\\\n-import random\\\\n-from time import sleep\\\\n-\\\\n-def main(args):\\\\n-    sleep(random.random())\\\\n-    output_dir = os.path.expanduser(args.output_dir)\\\\n-    if not os.path.exists(output_dir):\\\\n-        os.makedirs(output_dir)\\\\n-    # Store some git revision info in a text file in the log directory\\\\n-    src_path,_ = os.path.split(os.path.realpath(__file__))\\\\n-    facenet.store_revision_info(src_path, output_dir, \\\\\\\' \\\\\\\'.join(sys.argv))\\\\n-    dataset = facenet.get_dataset(args.input_dir)\\\\n-    \\\\n-    print(\\\\\\\'Creating networks and loading parameters\\\\\\\')\\\\n-    \\\\n-    with tf.Graph().as_default():\\\\n-        gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=args.gpu_memory_fraction)\\\\n-        sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options, log_device_placement=False))\\\\n-        with sess.as_default():\\\\n-            pnet, rnet, onet = align.detect_face.create_mtcnn(sess, None)\\\\n-    \\\\n-    minsize = 20 # minimum size of face\\\\n-    threshold = [ 0.6, 0.7, 0.7 ]  # three steps\\\\\\\'s threshold\\\\n-    factor = 0.709 # scale factor\\\\n-\\\\n-    # Add a random key to the filename to allow alignment using multiple processes\\\\n-    random_key = np.random.randint(0, high=99999)\\\\n-    bounding_boxes_filename = os.path.join(output_dir, \\\\\\\'bounding_boxes_%05d.txt\\\\\\\' % random_key)\\\\n-    \\\\n-    with open(bounding_boxes_filename, "w") as text_file:\\\\n-        nrof_images_total = 0\\\\n-        nrof_successfully_aligned = 0\\\\n-        if args.random_order:\\\\n-            random.shuffle(dataset)\\\\n-        for cls in dataset:\\\\n-            output_class_dir = os.path.join(output_dir, cls.name)\\\\n-            if not os.path.exists(output_class_dir):\\\\n-                os.makedirs(output_class_dir)\\\\n-                if args.random_order:\\\\n-                    random.shuffle(cls.image_paths)\\\\n-            for image_path in cls.image_paths:\\\\n-                nrof_images_total += 1\\\\n-                filename = os.path.splitext(os.path.split(image_path)[1])[0]\\\\n-                output_filename = os.path.join(output_class_dir, filename+\\\\\\\'.png\\\\\\\')\\\\n-                print(image_path)\\\\n-                if not os.path.exists(output_filename):\\\\n-                    try:\\\\n-                        img = misc.imread(image_path)\\\\n-                    except (IOError, ValueError, IndexError) as e:\\\\n-                        errorMessage = \\\\\\\'{}: {}\\\\\\\'.format(image_path, e)\\\\n-                        print(errorMessage)\\\\n-                    else:\\\\n-                        if img.ndim<2:\\\\n-                            print(\\\\\\\'Unable to align "%s"\\\\\\\' % image_path)\\\\n-                            text_file.write(\\\\\\\'%s\\\\\\\\n\\\\\\\' % (output_filename))\\\\n-                            continue\\\\n-                        if img.ndim == 2:\\\\n-                            img = facenet.to_rgb(img)\\\\n-                        img = img[:,:,0:3]\\\\n-    \\\\n-                        bounding_boxes, _ = align.detect_face.detect_face(img, minsize, pnet, rnet, onet, threshold, factor)\\\\n-                        nrof_faces = bounding_boxes.shape[0]\\\\n-                        if nrof_faces>0:\\\\n-                            det = bounding_boxes[:,0:4]\\\\n-                            det_arr = []\\\\n-                            img_size = np.asarray(img.shape)[0:2]\\\\n-                            if nrof_faces>1:\\\\n-                                if args.detect_multiple_faces:\\\\n-                                    for i in range(nrof_faces):\\\\n-                                        det_arr.append(np.squeeze(det[i]))\\\\n-                                else:\\\\n-                                    bounding_box_size = (det[:,2]-det[:,0])*(det[:,3]-det[:,1])\\\\n-                                    img_center = img_size / 2\\\\n-                                    offsets = np.vstack([ (det[:,0]+det[:,2])/2-img_center[1], (det[:,1]+det[:,3])/2-img_center[0] ])\\\\n-                                    offset_dist_squared = np.sum(np.power(offsets,2.0),0)\\\\n-                                    index = np.argmax(bounding_box_size-offset_dist_squared*2.0) # some extra weight on the centering\\\\n-                                    det_arr.append(det[index,:])\\\\n-                            else:\\\\n-                                det_arr.append(np.squeeze(det))\\\\n-\\\\n-                            for i, det in enumerate(det_arr):\\\\n-                                det = np.squeeze(det)\\\\n-                                bb = np.zeros(4, dtype=np.int32)\\\\n-                                bb[0] = np.maximum(det[0]-args.margin/2, 0)\\\\n-                                bb[1] = np.maximum(det[1]-args.margin/2, 0)\\\\n-                                bb[2] = np.minimum(det[2]+args.margin/2, img_size[1])\\\\n-                                bb[3] = np.minimum(det[3]+args.margin/2, img_size[0])\\\\n-                                cropped = img[bb[1]:bb[3],bb[0]:bb[2],:]\\\\n-                                scaled = misc.imresize(cropped, (args.image_size, args.image_size), interp=\\\\\\\'bilinear\\\\\\\')\\\\n-                                nrof_successfully_aligned += 1\\\\n-                                filename_base, file_extension = os.path.splitext(output_filename)\\\\n-                                if args.detect_multiple_faces:\\\\n-                                    output_filename_n = "{}_{}{}".format(filename_base, i, file_extension)\\\\n-                                else:\\\\n-                                    output_filename_n = "{}{}".format(filename_base, file_extension)\\\\n-                                misc.imsave(output_filename_n, scaled)\\\\n-                                text_file.write(\\\\\\\'%s %d %d %d %d\\\\\\\\n\\\\\\\' % (output_filename_n, bb[0], bb[1], bb[2], bb[3]))\\\\n-                        else:\\\\n-                            print(\\\\\\\'Unable to align "%s"\\\\\\\' % image_path)\\\\n-                            text_file.write(\\\\\\\'%s\\\\\\\\n\\\\\\\' % (output_filename))\\\\n-                            \\\\n-    print(\\\\\\\'Total number of images: %d\\\\\\\' % nrof_images_total)\\\\n-    print(\\\\\\\'Number of successfully aligned images: %d\\\\\\\' % nrof_successfully_aligned)\\\\n-            \\\\n-\\\\n-def parse_arguments(argv):\\\\n-    parser = argparse.ArgumentParser()\\\\n-    \\\\n-    parser.add_argument(\\\\\\\'input_dir\\\\\\\', type=str, help=\\\\\\\'Directory with unaligned images.\\\\\\\')\\\\n-    parser.add_argument(\\\\\\\'output_dir\\\\\\\', type=str, help=\\\\\\\'Directory with aligned face thumbnails.\\\\\\\')\\\\n-    parser.add_argument(\\\\\\\'--image_size\\\\\\\', type=int,\\\\n-        help=\\\\\\\'Image size (height, width) in pixels.\\\\\\\', default=182)\\\\n-    parser.add_argument(\\\\\\\'--margin\\\\\\\', type=int,\\\\n-        help=\\\\\\\'Margin for the crop around the bounding box (height, width) in pixels.\\\\\\\', default=44)\\\\n-    parser.add_argument(\\\\\\\'--random_order\\\\\\\', \\\\n-        help=\\\\\\\'Shuffles the order of images to enable alignment using multiple processes.\\\\\\\', action=\\\\\\\'store_true\\\\\\\')\\\\n-    parser.add_argument(\\\\\\\'--gpu_memory_fraction\\\\\\\', type=float,\\\\n-        help=\\\\\\\'Upper bound on the amount of GPU memory that will be used by the process.\\\\\\\', default=1.0)\\\\n-    parser.add_argument(\\\\\\\'--detect_multiple_faces\\\\\\\', type=bool,\\\\n-                        help=\\\\\\\'Detect and align multiple faces per image.\\\\\\\', default=False)\\\\n-    return parser.parse_args(argv)\\\\n-\\\\n-if __name__ == \\\\\\\'__main__\\\\\\\':\\\\n-    main(parse_arguments(sys.argv[1:]))\\\\ndiff --git a/main/src/faceRec.py b/main/src/faceRec.py\\\\nindex b33af2d..1f1adec 100644\\\\n--- a/main/src/faceRec.py\\\\n+++ b/main/src/faceRec.py\\\\n@@ -3,6 +3,7 @@ from __future__ import division\\\\n from __future__ import print_function\\\\n \\\\n import tensorflow as tf\\\\n+import imageio\\\\n import argparse\\\\n import facenet\\\\n import os\\\\n@@ -62,6 +63,12 @@ def main():\\\\n             while (cap.isOpened()):\\\\n                 ret, frame = cap.read()\\\\n \\\\n+                print(type(frame))\\\\n+                print(frame.shape)\\\\n+                imageio.imwrite("test.jpg",frame)\\\\n+\\\\n+                break\\\\n+\\\\n                 bounding_boxes, _ = align.detect_face.detect_face(frame, MINSIZE, pnet, rnet, onet, THRESHOLD, FACTOR)\\\\n \\\\n                 faces_found = bounding_boxes.shape[0]\\\'\\n\\\\ No newline at end of file\\ndiff --git a/main/Dataset/CSE20/raw/B160760CS_Vatsala/B160760CS_1.jpeg b/main/Dataset/CSE20/raw/B160760CS_Vatsala/B160760CS_1.jpeg\\ndeleted file mode 100644\\nindex 2856b8e..0000000\\nBinary files a/main/Dataset/CSE20/raw/B160760CS_Vatsala/B160760CS_1.jpeg and /dev/null differ\\ndiff --git a/main/Dataset/CSE20/raw/B160760CS_Vatsala/B160760CS_2.jpeg b/main/Dataset/CSE20/raw/B160760CS_Vatsala/B160760CS_2.jpeg\\ndeleted file mode 100644\\nindex 76e5ceb..0000000\\nBinary files a/main/Dataset/CSE20/raw/B160760CS_Vatsala/B160760CS_2.jpeg and /dev/null differ\\ndiff --git a/main/Dataset/CSE20/raw/B160760CS_Vatsala/B160760CS_3.jpeg b/main/Dataset/CSE20/raw/B160760CS_Vatsala/B160760CS_3.jpeg\\ndeleted file mode 100644\\nindex f43a8a7..0000000\\nBinary files a/main/Dataset/CSE20/raw/B160760CS_Vatsala/B160760CS_3.jpeg and /dev/null differ\\ndiff --git a/main/Models/CSE20/CSE20.pkl b/main/Models/CSE20/CSE20.pkl\\nindex 3266061..2c290e1 100644\\nBinary files a/main/Models/CSE20/CSE20.pkl and b/main/Models/CSE20/CSE20.pkl differ\\ndiff --git a/main/requirements.txt b/main/requirements.txt\\nindex 167b725..558415a 100644\\n--- a/main/requirements.txt\\n+++ b/main/requirements.txt\\n@@ -1,11 +1,50 @@\\n-tensorflow==1.7\\n-scipy\\n-scikit-learn\\n-opencv-python\\n-h5py\\n-matplotlib\\n-Pillow\\n-requests\\n-psutil\\n-imageio\\n-scikit-image\\n+absl-py==0.8.1\\n+align==0.0.5\\n+astor==0.8.0\\n+bleach==1.5.0\\n+boto==2.49.0\\n+boto3==1.9.245\\n+botocore==1.12.245\\n+certifi==2019.9.11\\n+chardet==3.0.4\\n+cycler==0.10.0\\n+decorator==4.4.0\\n+docutils==0.15.2\\n+facenet==1.0.5\\n+gast==0.3.2\\n+gensim==3.8.1\\n+grpcio==1.24.1\\n+h5py==2.10.0\\n+html5lib==0.9999999\\n+idna==2.8\\n+imageio==2.6.1\\n+jmespath==0.9.4\\n+joblib==0.14.0\\n+kiwisolver==1.1.0\\n+Markdown==3.1.1\\n+matplotlib==3.0.3\\n+networkx==2.3\\n+nltk==3.4.5\\n+numpy==1.17.2\\n+opencv-python==4.1.1.26\\n+pandas==0.24.2\\n+Pillow==6.2.0\\n+protobuf==3.10.0\\n+psutil==5.6.3\\n+pyparsing==2.4.2\\n+python-dateutil==2.8.0\\n+pytz==2019.3\\n+PyWavelets==1.0.3\\n+requests==2.22.0\\n+s3transfer==0.2.1\\n+scikit-image==0.15.0\\n+scikit-learn==0.21.3\\n+scipy==1.3.1\\n+six==1.12.0\\n+sklearn==0.0\\n+smart-open==1.8.4\\n+tensorboard==1.7.0\\n+tensorflow==1.7.0\\n+termcolor==1.1.0\\n+urllib3==1.25.6\\n+Werkzeug==0.16.0\\n\\\\ No newline at end of file\\ndiff --git a/main/src/align/align_dataset_mtcnn.py b/main/src/align/align_dataset_mtcnn.py\\ndeleted file mode 100644\\nindex 21f1457..0000000\\n--- a/main/src/align/align_dataset_mtcnn.py\\n+++ /dev/null\\n@@ -1,159 +0,0 @@\\n-"""Performs face alignment and stores face thumbnails in the output directory."""\\n-# MIT License\\n-# \\n-# Copyright (c) 2016 David Sandberg\\n-# \\n-# Permission is hereby granted, free of charge, to any person obtaining a copy\\n-# of this software and associated documentation files (the "Software"), to deal\\n-# in the Software without restriction, including without limitation the rights\\n-# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\n-# copies of the Software, and to permit persons to whom the Software is\\n-# furnished to do so, subject to the following conditions:\\n-# \\n-# The above copyright notice and this permission notice shall be included in all\\n-# copies or substantial portions of the Software.\\n-# \\n-# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\n-# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\n-# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\n-# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\n-# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\n-# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\n-# SOFTWARE.\\n-\\n-from __future__ import absolute_import\\n-from __future__ import division\\n-from __future__ import print_function\\n-\\n-from scipy import misc\\n-import sys\\n-import os\\n-import argparse\\n-import tensorflow as tf\\n-import numpy as np\\n-import facenet.src.facenet as facenet   #changed\\n-import detect_face  #changed\\n-import random\\n-from time import sleep\\n-\\n-def main(args):\\n-    sleep(random.random())\\n-    output_dir = os.path.expanduser(args.output_dir)\\n-    if not os.path.exists(output_dir):\\n-        os.makedirs(output_dir)\\n-    # Store some git revision info in a text file in the log directory\\n-    src_path,_ = os.path.split(os.path.realpath(__file__))\\n-    facenet.store_revision_info(src_path, output_dir, \\\' \\\'.join(sys.argv))\\n-    dataset = facenet.get_dataset(args.input_dir)\\n-    \\n-    print(\\\'Creating networks and loading parameters\\\')\\n-    \\n-    with tf.Graph().as_default():\\n-        gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=args.gpu_memory_fraction)\\n-        sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options, log_device_placement=False))\\n-        with sess.as_default():\\n-            pnet, rnet, onet = align.detect_face.create_mtcnn(sess, None)\\n-    \\n-    minsize = 20 # minimum size of face\\n-    threshold = [ 0.6, 0.7, 0.7 ]  # three steps\\\'s threshold\\n-    factor = 0.709 # scale factor\\n-\\n-    # Add a random key to the filename to allow alignment using multiple processes\\n-    random_key = np.random.randint(0, high=99999)\\n-    bounding_boxes_filename = os.path.join(output_dir, \\\'bounding_boxes_%05d.txt\\\' % random_key)\\n-    \\n-    with open(bounding_boxes_filename, "w") as text_file:\\n-        nrof_images_total = 0\\n-        nrof_successfully_aligned = 0\\n-        if args.random_order:\\n-            random.shuffle(dataset)\\n-        for cls in dataset:\\n-            output_class_dir = os.path.join(output_dir, cls.name)\\n-            if not os.path.exists(output_class_dir):\\n-                os.makedirs(output_class_dir)\\n-                if args.random_order:\\n-                    random.shuffle(cls.image_paths)\\n-            for image_path in cls.image_paths:\\n-                nrof_images_total += 1\\n-                filename = os.path.splitext(os.path.split(image_path)[1])[0]\\n-                output_filename = os.path.join(output_class_dir, filename+\\\'.png\\\')\\n-                print(image_path)\\n-                if not os.path.exists(output_filename):\\n-                    try:\\n-                        img = misc.imread(image_path)\\n-                    except (IOError, ValueError, IndexError) as e:\\n-                        errorMessage = \\\'{}: {}\\\'.format(image_path, e)\\n-                        print(errorMessage)\\n-                    else:\\n-                        if img.ndim<2:\\n-                            print(\\\'Unable to align "%s"\\\' % image_path)\\n-                            text_file.write(\\\'%s\\\\n\\\' % (output_filename))\\n-                            continue\\n-                        if img.ndim == 2:\\n-                            img = facenet.to_rgb(img)\\n-                        img = img[:,:,0:3]\\n-    \\n-                        bounding_boxes, _ = align.detect_face.detect_face(img, minsize, pnet, rnet, onet, threshold, factor)\\n-                        nrof_faces = bounding_boxes.shape[0]\\n-                        if nrof_faces>0:\\n-                            det = bounding_boxes[:,0:4]\\n-                            det_arr = []\\n-                            img_size = np.asarray(img.shape)[0:2]\\n-                            if nrof_faces>1:\\n-                                if args.detect_multiple_faces:\\n-                                    for i in range(nrof_faces):\\n-                                        det_arr.append(np.squeeze(det[i]))\\n-                                else:\\n-                                    bounding_box_size = (det[:,2]-det[:,0])*(det[:,3]-det[:,1])\\n-                                    img_center = img_size / 2\\n-                                    offsets = np.vstack([ (det[:,0]+det[:,2])/2-img_center[1], (det[:,1]+det[:,3])/2-img_center[0] ])\\n-                                    offset_dist_squared = np.sum(np.power(offsets,2.0),0)\\n-                                    index = np.argmax(bounding_box_size-offset_dist_squared*2.0) # some extra weight on the centering\\n-                                    det_arr.append(det[index,:])\\n-                            else:\\n-                                det_arr.append(np.squeeze(det))\\n-\\n-                            for i, det in enumerate(det_arr):\\n-                                det = np.squeeze(det)\\n-                                bb = np.zeros(4, dtype=np.int32)\\n-                                bb[0] = np.maximum(det[0]-args.margin/2, 0)\\n-                                bb[1] = np.maximum(det[1]-args.margin/2, 0)\\n-                                bb[2] = np.minimum(det[2]+args.margin/2, img_size[1])\\n-                                bb[3] = np.minimum(det[3]+args.margin/2, img_size[0])\\n-                                cropped = img[bb[1]:bb[3],bb[0]:bb[2],:]\\n-                                scaled = misc.imresize(cropped, (args.image_size, args.image_size), interp=\\\'bilinear\\\')\\n-                                nrof_successfully_aligned += 1\\n-                                filename_base, file_extension = os.path.splitext(output_filename)\\n-                                if args.detect_multiple_faces:\\n-                                    output_filename_n = "{}_{}{}".format(filename_base, i, file_extension)\\n-                                else:\\n-                                    output_filename_n = "{}{}".format(filename_base, file_extension)\\n-                                misc.imsave(output_filename_n, scaled)\\n-                                text_file.write(\\\'%s %d %d %d %d\\\\n\\\' % (output_filename_n, bb[0], bb[1], bb[2], bb[3]))\\n-                        else:\\n-                            print(\\\'Unable to align "%s"\\\' % image_path)\\n-                            text_file.write(\\\'%s\\\\n\\\' % (output_filename))\\n-                            \\n-    print(\\\'Total number of images: %d\\\' % nrof_images_total)\\n-    print(\\\'Number of successfully aligned images: %d\\\' % nrof_successfully_aligned)\\n-            \\n-\\n-def parse_arguments(argv):\\n-    parser = argparse.ArgumentParser()\\n-    \\n-    parser.add_argument(\\\'input_dir\\\', type=str, help=\\\'Directory with unaligned images.\\\')\\n-    parser.add_argument(\\\'output_dir\\\', type=str, help=\\\'Directory with aligned face thumbnails.\\\')\\n-    parser.add_argument(\\\'--image_size\\\', type=int,\\n-        help=\\\'Image size (height, width) in pixels.\\\', default=182)\\n-    parser.add_argument(\\\'--margin\\\', type=int,\\n-        help=\\\'Margin for the crop around the bounding box (height, width) in pixels.\\\', default=44)\\n-    parser.add_argument(\\\'--random_order\\\', \\n-        help=\\\'Shuffles the order of images to enable alignment using multiple processes.\\\', action=\\\'store_true\\\')\\n-    parser.add_argument(\\\'--gpu_memory_fraction\\\', type=float,\\n-        help=\\\'Upper bound on the amount of GPU memory that will be used by the process.\\\', default=1.0)\\n-    parser.add_argument(\\\'--detect_multiple_faces\\\', type=bool,\\n-                        help=\\\'Detect and align multiple faces per image.\\\', default=False)\\n-    return parser.parse_args(argv)\\n-\\n-if __name__ == \\\'__main__\\\':\\n-    main(parse_arguments(sys.argv[1:]))\\ndiff --git a/main/src/faceRec.py b/main/src/faceRec.py\\nindex b33af2d..b9466d5 100644\\n--- a/main/src/faceRec.py\\n+++ b/main/src/faceRec.py\\n@@ -3,6 +3,7 @@ from __future__ import division\\n from __future__ import print_function\\n \\n import tensorflow as tf\\n+import imageio\\n import argparse\\n import facenet\\n import os\\n@@ -62,6 +63,11 @@ def main():\\n             while (cap.isOpened()):\\n                 ret, frame = cap.read()\\n \\n+#                print(type(frame))\\n+#                print(frame.shape)\\n+#                imageio.imwrite("test.jpg",frame)\\n+\\n+\\n                 bounding_boxes, _ = align.detect_face.detect_face(frame, MINSIZE, pnet, rnet, onet, THRESHOLD, FACTOR)\\n \\n                 faces_found = bounding_boxes.shape[0]\'\n\\ No newline at end of file\ndiff --git a/main/Models/CSE20/CSE20.pkl b/main/Models/CSE20/CSE20.pkl\nindex 3266061..8ca6f2d 100644\nBinary files a/main/Models/CSE20/CSE20.pkl and b/main/Models/CSE20/CSE20.pkl differ\ndiff --git a/main/requirements.txt b/main/requirements.txt\nindex 167b725..558415a 100644\n--- a/main/requirements.txt\n+++ b/main/requirements.txt\n@@ -1,11 +1,50 @@\n-tensorflow==1.7\n-scipy\n-scikit-learn\n-opencv-python\n-h5py\n-matplotlib\n-Pillow\n-requests\n-psutil\n-imageio\n-scikit-image\n+absl-py==0.8.1\n+align==0.0.5\n+astor==0.8.0\n+bleach==1.5.0\n+boto==2.49.0\n+boto3==1.9.245\n+botocore==1.12.245\n+certifi==2019.9.11\n+chardet==3.0.4\n+cycler==0.10.0\n+decorator==4.4.0\n+docutils==0.15.2\n+facenet==1.0.5\n+gast==0.3.2\n+gensim==3.8.1\n+grpcio==1.24.1\n+h5py==2.10.0\n+html5lib==0.9999999\n+idna==2.8\n+imageio==2.6.1\n+jmespath==0.9.4\n+joblib==0.14.0\n+kiwisolver==1.1.0\n+Markdown==3.1.1\n+matplotlib==3.0.3\n+networkx==2.3\n+nltk==3.4.5\n+numpy==1.17.2\n+opencv-python==4.1.1.26\n+pandas==0.24.2\n+Pillow==6.2.0\n+protobuf==3.10.0\n+psutil==5.6.3\n+pyparsing==2.4.2\n+python-dateutil==2.8.0\n+pytz==2019.3\n+PyWavelets==1.0.3\n+requests==2.22.0\n+s3transfer==0.2.1\n+scikit-image==0.15.0\n+scikit-learn==0.21.3\n+scipy==1.3.1\n+six==1.12.0\n+sklearn==0.0\n+smart-open==1.8.4\n+tensorboard==1.7.0\n+tensorflow==1.7.0\n+termcolor==1.1.0\n+urllib3==1.25.6\n+Werkzeug==0.16.0\n\\ No newline at end of file\ndiff --git a/main/src/align/align_dataset_mtcnn.py b/main/src/align/align_dataset_mtcnn.py\ndeleted file mode 100644\nindex 21f1457..0000000\n--- a/main/src/align/align_dataset_mtcnn.py\n+++ /dev/null\n@@ -1,159 +0,0 @@\n-"""Performs face alignment and stores face thumbnails in the output directory."""\n-# MIT License\n-# \n-# Copyright (c) 2016 David Sandberg\n-# \n-# Permission is hereby granted, free of charge, to any person obtaining a copy\n-# of this software and associated documentation files (the "Software"), to deal\n-# in the Software without restriction, including without limitation the rights\n-# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n-# copies of the Software, and to permit persons to whom the Software is\n-# furnished to do so, subject to the following conditions:\n-# \n-# The above copyright notice and this permission notice shall be included in all\n-# copies or substantial portions of the Software.\n-# \n-# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n-# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n-# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n-# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n-# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n-# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n-# SOFTWARE.\n-\n-from __future__ import absolute_import\n-from __future__ import division\n-from __future__ import print_function\n-\n-from scipy import misc\n-import sys\n-import os\n-import argparse\n-import tensorflow as tf\n-import numpy as np\n-import facenet.src.facenet as facenet   #changed\n-import detect_face  #changed\n-import random\n-from time import sleep\n-\n-def main(args):\n-    sleep(random.random())\n-    output_dir = os.path.expanduser(args.output_dir)\n-    if not os.path.exists(output_dir):\n-        os.makedirs(output_dir)\n-    # Store some git revision info in a text file in the log directory\n-    src_path,_ = os.path.split(os.path.realpath(__file__))\n-    facenet.store_revision_info(src_path, output_dir, \' \'.join(sys.argv))\n-    dataset = facenet.get_dataset(args.input_dir)\n-    \n-    print(\'Creating networks and loading parameters\')\n-    \n-    with tf.Graph().as_default():\n-        gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=args.gpu_memory_fraction)\n-        sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options, log_device_placement=False))\n-        with sess.as_default():\n-            pnet, rnet, onet = align.detect_face.create_mtcnn(sess, None)\n-    \n-    minsize = 20 # minimum size of face\n-    threshold = [ 0.6, 0.7, 0.7 ]  # three steps\'s threshold\n-    factor = 0.709 # scale factor\n-\n-    # Add a random key to the filename to allow alignment using multiple processes\n-    random_key = np.random.randint(0, high=99999)\n-    bounding_boxes_filename = os.path.join(output_dir, \'bounding_boxes_%05d.txt\' % random_key)\n-    \n-    with open(bounding_boxes_filename, "w") as text_file:\n-        nrof_images_total = 0\n-        nrof_successfully_aligned = 0\n-        if args.random_order:\n-            random.shuffle(dataset)\n-        for cls in dataset:\n-            output_class_dir = os.path.join(output_dir, cls.name)\n-            if not os.path.exists(output_class_dir):\n-                os.makedirs(output_class_dir)\n-                if args.random_order:\n-                    random.shuffle(cls.image_paths)\n-            for image_path in cls.image_paths:\n-                nrof_images_total += 1\n-                filename = os.path.splitext(os.path.split(image_path)[1])[0]\n-                output_filename = os.path.join(output_class_dir, filename+\'.png\')\n-                print(image_path)\n-                if not os.path.exists(output_filename):\n-                    try:\n-                        img = misc.imread(image_path)\n-                    except (IOError, ValueError, IndexError) as e:\n-                        errorMessage = \'{}: {}\'.format(image_path, e)\n-                        print(errorMessage)\n-                    else:\n-                        if img.ndim<2:\n-                            print(\'Unable to align "%s"\' % image_path)\n-                            text_file.write(\'%s\\n\' % (output_filename))\n-                            continue\n-                        if img.ndim == 2:\n-                            img = facenet.to_rgb(img)\n-                        img = img[:,:,0:3]\n-    \n-                        bounding_boxes, _ = align.detect_face.detect_face(img, minsize, pnet, rnet, onet, threshold, factor)\n-                        nrof_faces = bounding_boxes.shape[0]\n-                        if nrof_faces>0:\n-                            det = bounding_boxes[:,0:4]\n-                            det_arr = []\n-                            img_size = np.asarray(img.shape)[0:2]\n-                            if nrof_faces>1:\n-                                if args.detect_multiple_faces:\n-                                    for i in range(nrof_faces):\n-                                        det_arr.append(np.squeeze(det[i]))\n-                                else:\n-                                    bounding_box_size = (det[:,2]-det[:,0])*(det[:,3]-det[:,1])\n-                                    img_center = img_size / 2\n-                                    offsets = np.vstack([ (det[:,0]+det[:,2])/2-img_center[1], (det[:,1]+det[:,3])/2-img_center[0] ])\n-                                    offset_dist_squared = np.sum(np.power(offsets,2.0),0)\n-                                    index = np.argmax(bounding_box_size-offset_dist_squared*2.0) # some extra weight on the centering\n-                                    det_arr.append(det[index,:])\n-                            else:\n-                                det_arr.append(np.squeeze(det))\n-\n-                            for i, det in enumerate(det_arr):\n-                                det = np.squeeze(det)\n-                                bb = np.zeros(4, dtype=np.int32)\n-                                bb[0] = np.maximum(det[0]-args.margin/2, 0)\n-                                bb[1] = np.maximum(det[1]-args.margin/2, 0)\n-                                bb[2] = np.minimum(det[2]+args.margin/2, img_size[1])\n-                                bb[3] = np.minimum(det[3]+args.margin/2, img_size[0])\n-                                cropped = img[bb[1]:bb[3],bb[0]:bb[2],:]\n-                                scaled = misc.imresize(cropped, (args.image_size, args.image_size), interp=\'bilinear\')\n-                                nrof_successfully_aligned += 1\n-                                filename_base, file_extension = os.path.splitext(output_filename)\n-                                if args.detect_multiple_faces:\n-                                    output_filename_n = "{}_{}{}".format(filename_base, i, file_extension)\n-                                else:\n-                                    output_filename_n = "{}{}".format(filename_base, file_extension)\n-                                misc.imsave(output_filename_n, scaled)\n-                                text_file.write(\'%s %d %d %d %d\\n\' % (output_filename_n, bb[0], bb[1], bb[2], bb[3]))\n-                        else:\n-                            print(\'Unable to align "%s"\' % image_path)\n-                            text_file.write(\'%s\\n\' % (output_filename))\n-                            \n-    print(\'Total number of images: %d\' % nrof_images_total)\n-    print(\'Number of successfully aligned images: %d\' % nrof_successfully_aligned)\n-            \n-\n-def parse_arguments(argv):\n-    parser = argparse.ArgumentParser()\n-    \n-    parser.add_argument(\'input_dir\', type=str, help=\'Directory with unaligned images.\')\n-    parser.add_argument(\'output_dir\', type=str, help=\'Directory with aligned face thumbnails.\')\n-    parser.add_argument(\'--image_size\', type=int,\n-        help=\'Image size (height, width) in pixels.\', default=182)\n-    parser.add_argument(\'--margin\', type=int,\n-        help=\'Margin for the crop around the bounding box (height, width) in pixels.\', default=44)\n-    parser.add_argument(\'--random_order\', \n-        help=\'Shuffles the order of images to enable alignment using multiple processes.\', action=\'store_true\')\n-    parser.add_argument(\'--gpu_memory_fraction\', type=float,\n-        help=\'Upper bound on the amount of GPU memory that will be used by the process.\', default=1.0)\n-    parser.add_argument(\'--detect_multiple_faces\', type=bool,\n-                        help=\'Detect and align multiple faces per image.\', default=False)\n-    return parser.parse_args(argv)\n-\n-if __name__ == \'__main__\':\n-    main(parse_arguments(sys.argv[1:]))\ndiff --git a/main/src/faceRec.py b/main/src/faceRec.py\nindex b33af2d..b9466d5 100644\n--- a/main/src/faceRec.py\n+++ b/main/src/faceRec.py\n@@ -3,6 +3,7 @@ from __future__ import division\n from __future__ import print_function\n \n import tensorflow as tf\n+import imageio\n import argparse\n import facenet\n import os\n@@ -62,6 +63,11 @@ def main():\n             while (cap.isOpened()):\n                 ret, frame = cap.read()\n \n+#                print(type(frame))\n+#                print(frame.shape)\n+#                imageio.imwrite("test.jpg",frame)\n+\n+\n                 bounding_boxes, _ = align.detect_face.detect_face(frame, MINSIZE, pnet, rnet, onet, THRESHOLD, FACTOR)\n \n                 faces_found = bounding_boxes.shape[0]'